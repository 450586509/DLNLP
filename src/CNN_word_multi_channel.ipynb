{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>CNN 多通道情感分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个有三个通道，分别是word embedding，POS 标签 embedding, 词的情感极性强度embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from  os.path import join\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Lambda,Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D,Convolution2D,Merge,merge\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag word 的方法： http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "2210\n",
      "1101\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.']]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['stsa.fine.test','stsa.fine.train','stsa.fine.dev']\n",
    "file_path = '/home/bruce/data/sentiment/citai_process'\n",
    "def read_file(fname=''):\n",
    "    with open(join(file_path,fname)) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().lower() for line in lines]\n",
    "    lables = [int(line[0:1]) for line in lines]\n",
    "    words = [line[2:].split() for line in lines]\n",
    "    return words,lables       \n",
    "train_X,train_y = read_file(fname='stsa.fine.train')\n",
    "test_X,test_y = read_file(fname='stsa.fine.test')\n",
    "dev_X,dev_y = read_file(fname='stsa.fine.dev')\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(dev_X))\n",
    "print(train_X[0:2])\n",
    "print(train_y[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film']\n",
      "['DET', 'NOUN', '.', 'ADJ', 'CONJ', 'ADV', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'DET', 'NOUN', 'CONJ', 'NUM', 'NOUN', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "def tag_sentence(X=[]):\n",
    "    tag_X=[]\n",
    "    for line in X:\n",
    "        word_tag = pos_tag(line,tagset='universal')\n",
    "        tag = [i[1] for i in word_tag]\n",
    "        tag_X.append(tag)\n",
    "    return tag_X\n",
    "train_tag_X = tag_sentence(X=train_X)\n",
    "dev_tag_X = tag_sentence(X=dev_X)\n",
    "print(train_X[0])\n",
    "print(train_tag_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感极性当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 读取情感强度文件，构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment number = 18540\n"
     ]
    }
   ],
   "source": [
    "senti_file = '/home/bruce/data/sentiment/sentiment_diction/wordwithStrength.txt'\n",
    "def construct_senti_dict(senti_file=''):\n",
    "    with open(senti_file) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().split() for line in lines]\n",
    "    lines = [(i[0],float(i[1])) for i in lines]\n",
    "    return dict(lines)\n",
    "sentiment_dict=construct_senti_dict(senti_file)\n",
    "print('sentiment number =',len(sentiment_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建情感极性强度通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '+4', '0', '0', '0', '0', '0', '0', '0', '+2', '0', '0', '-5', '0', '0', '-2', '0'], ['+5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '-5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '+6', '-2', '0', '+2', '0', '0', '-3', '0', '0', '0', '-5', '0', '0', '0', '0', '0', '0', '0', '-2', '0', '0'], ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '0', '0', '+5', '-2', '0', '+2', '+3', '0', '0', '0', '0', '0', '0', '-3', '0', '+2', '0', '0', '0']]\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.'], ['they', 'presume', 'their', 'audience', 'wo', \"n't\", 'sit', 'still', 'for', 'a', 'sociology', 'lesson', ',', 'however', 'entertainingly', 'present', ',', 'so', 'they', 'trot', 'out', 'the', 'conventional', 'science-fiction', 'element', 'of', 'bug-eyed', 'monster', 'and', 'futuristic', 'woman', 'in', 'skimpy', 'clothes', '.'], ['the', 'entire', 'movie', 'be', 'fill', 'with', 'deja', 'vu', 'moment', '.'], ['this', 'be', 'a', 'visually', 'stunning', 'rumination', 'on', 'love', ',', 'memory', ',', 'history', 'and', 'the', 'war', 'between', 'art', 'and', 'commerce', '.']]\n",
      "[4, 1, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def sentiment_strength(X=[],sentiment_dict=sentiment_dict):\n",
    "    sentiment_X = [[sentiment_dict[w] if w in sentiment_dict else 0 for w in line ]for line in X]\n",
    "    sentiment_X = [[ str(int(val*10)) if val <=0 else  '+'+str(int(val*10)) for val in line] for line in sentiment_X]\n",
    "    return sentiment_X\n",
    "train_sentiment_X = sentiment_strength(X=train_X,sentiment_dict=sentiment_dict)\n",
    "dev_sentiment_X = sentiment_strength(X=dev_X,sentiment_dict=sentiment_dict)\n",
    "\n",
    "assert len(train_sentiment_X) == len(train_X) \n",
    "print(train_sentiment_X[0:5])\n",
    "print(train_X[0:5])    \n",
    "print(train_y[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 否定词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.资料：http://web.stanford.edu/~cgpotts/papers/potts-salt20-negation.pdf\n",
    "\n",
    "2.Negation handing in NLP  http://stackoverflow.com/questions/28720174/negation-handling-in-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leng of word_index = 14525\n",
      "length of dict_index =  14525\n"
     ]
    }
   ],
   "source": [
    "def token_to_index(datas=[]):\n",
    "    word_index={}\n",
    "    count=1\n",
    "    for data in datas:\n",
    "        for list_ in data:\n",
    "            for w in list_:\n",
    "                if w not in word_index:\n",
    "                    word_index[w] = count\n",
    "                    count = count + 1\n",
    "    print('leng of word_index =',len(word_index))\n",
    "    for i in range(len(datas)):\n",
    "        datas[i] = [[ word_index[w] for w in line ] for line in datas[i]] \n",
    "    return datas,word_index\n",
    "X,word_index = token_to_index(datas=[train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X])\n",
    "train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X = X\n",
    "\n",
    "print('length of dict_index = ',len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14498, 14499, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14500, 14498, 14498, 14501, 14498, 14498, 14502, 14498], [14503, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498]]\n",
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 11, 12, 5, 13, 14, 15], [16, 17, 18, 11, 19, 20, 9, 21, 22, 23, 24, 25]]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentiment_X[0:2])\n",
    "print(train_X[0:2])    \n",
    "print(train_y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove训练好的词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用glove基于twitter训练公开的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总word的数目=  14525\n",
      "总word embedding 的数目 =  11850\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "we_file = '/home/bruce/data/glove/twitter/glove.twitter.27B.{0}d.txt'.format(embedding_dim)\n",
    "def get_index_wordembedding(we_file='',word_index={}):\n",
    "    index_wordembedding ={}\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    for line in open(we_file):\n",
    "        elements = line.strip().split()\n",
    "        if elements[0] in  word_index:\n",
    "            index = word_index[elements[0]]\n",
    "            wordembedding = [float(i) for i in elements[1:]]\n",
    "            index_wordembedding[index] = wordembedding\n",
    "    print('总word的数目= ',len(word_index))\n",
    "    print('总word embedding 的数目 = ',len(index_wordembedding))\n",
    "    \n",
    "    for word,index in word_index.items():\n",
    "        if index not in index_wordembedding:\n",
    "            index_wordembedding[index] = zeros\n",
    "    assert len(index_wordembedding) == len(word_index)\n",
    "    return index_wordembedding\n",
    "index_wordembedding = get_index_wordembedding(we_file=we_file,word_index=word_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将一个batch大小的index数据，利用index_wordembedding进行embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_indexData_embedding(X=None,index_wordembedding={}):\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    return [ [ index_wordembedding[w] if w in index_wordembedding else zeros  for w in line ] for line in X ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 36\n",
    "batch_size=32\n",
    "\n",
    "max_features= 14526\n",
    "#embedding_dims=50\n",
    "\n",
    "nb_filter = 200\n",
    "filter_length = 2\n",
    "dense1_hindden = 150*2\n",
    "nb_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.输入的变量和后面同名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input1 = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "input2 = Input(shape=(max_len,embedding_dim), name='main_input2')\n",
    "#input3 = Input(shape=(max_len,), dtype='int32', name='main_input3')\n",
    "\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)\n",
    "embedding1 = embedding(input1)\n",
    "#embedding2 = embedding(input2)\n",
    "#embedding3 = embedding(input3)\n",
    "#---------------------------------------------------------------------------\n",
    "#卷积方法一：每个通道，用不同的卷积核\n",
    "'''\n",
    "cov1_out1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )(embedding1)\n",
    "cov1_out2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )(embedding2)\n",
    "cov1_out3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )(embedding3)\n",
    "'''\n",
    "# 卷积方法二：每个通道用相同的卷积核\n",
    "conv = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )\n",
    "#第一个通道\n",
    "cov1_out1  = conv(embedding1)\n",
    "#第二个通道\n",
    "cov1_out2 = conv(input2)\n",
    "#cov1_out2 = conv(embedding2)\n",
    "#cov1_out3 = conv(embedding3)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "conv11 = GlobalMaxPooling1D()(cov1_out1)\n",
    "conv12 = GlobalMaxPooling1D()(cov1_out2)\n",
    "#conv13 = GlobalMaxPooling1D()(cov1_out3)\n",
    "#merged_vector = merge([conv11,conv12,conv13], mode='concat')\n",
    "merged_vector = merge([conv11,conv12], mode='concat')\n",
    "\n",
    "\n",
    "dens1 = Dense(dense1_hindden)(merged_vector)\n",
    "dens1 = Dropout(0.2)(dens1)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output = Activation('softmax')(dens2)\n",
    "model = Model(input=[input1,input2],output=output)\n",
    "\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 710.00 702.00\" width=\"710pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-698 706,-698 706,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139945126734480 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139945126734480</title>\n",
       "<polygon fill=\"none\" points=\"139.5,-657.5 139.5,-693.5 340.5,-693.5 340.5,-657.5 139.5,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-671.8\">main_input1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139945126735096 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139945126735096</title>\n",
       "<polygon fill=\"none\" points=\"135.5,-584.5 135.5,-620.5 344.5,-620.5 344.5,-584.5 135.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-598.8\">embedding_4 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 139945126734480&#45;&gt;139945126735096 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139945126734480-&gt;139945126735096</title>\n",
       "<path d=\"M240,-657.313C240,-649.289 240,-639.547 240,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"243.5,-630.529 240,-620.529 236.5,-630.529 243.5,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126735656 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139945126735656</title>\n",
       "<polygon fill=\"none\" points=\"223,-511.5 223,-547.5 479,-547.5 479,-511.5 223,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-525.8\">convolution1d_4 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 139945126735096&#45;&gt;139945126735656 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139945126735096-&gt;139945126735656</title>\n",
       "<path d=\"M266.587,-584.494C281.307,-575.079 299.791,-563.255 315.707,-553.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"317.707,-555.95 324.245,-547.614 313.935,-550.054 317.707,-555.95\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126734592 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139945126734592</title>\n",
       "<polygon fill=\"none\" points=\"362.5,-584.5 362.5,-620.5 563.5,-620.5 563.5,-584.5 362.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"463\" y=\"-598.8\">main_input2 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139945126734592&#45;&gt;139945126735656 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139945126734592-&gt;139945126735656</title>\n",
       "<path d=\"M436.173,-584.494C421.321,-575.079 402.671,-563.255 386.611,-553.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"388.316,-550.012 377.996,-547.614 384.568,-555.924 388.316,-550.012\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126288464 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139945126288464</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 342,-474.5 342,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"171\" y=\"-452.8\">globalmaxpooling1d_5 (GlobalMaxPooling1D)</text>\n",
       "</g>\n",
       "<!-- 139945126735656&#45;&gt;139945126288464 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139945126735656-&gt;139945126288464</title>\n",
       "<path d=\"M307.886,-511.494C282.69,-501.555 250.693,-488.934 223.97,-478.394\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"224.973,-475.027 214.387,-474.614 222.405,-481.539 224.973,-475.027\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126349008 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139945126349008</title>\n",
       "<polygon fill=\"none\" points=\"360,-438.5 360,-474.5 702,-474.5 702,-438.5 360,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"531\" y=\"-452.8\">globalmaxpooling1d_6 (GlobalMaxPooling1D)</text>\n",
       "</g>\n",
       "<!-- 139945126735656&#45;&gt;139945126349008 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139945126735656-&gt;139945126349008</title>\n",
       "<path d=\"M394.114,-511.494C419.31,-501.555 451.307,-488.934 478.03,-478.394\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"479.595,-481.539 487.613,-474.614 477.027,-475.027 479.595,-481.539\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126349736 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139945126349736</title>\n",
       "<polygon fill=\"none\" points=\"280.5,-365.5 280.5,-401.5 421.5,-401.5 421.5,-365.5 280.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-379.8\">merge_3 (Merge)</text>\n",
       "</g>\n",
       "<!-- 139945126288464&#45;&gt;139945126349736 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139945126288464-&gt;139945126349736</title>\n",
       "<path d=\"M214.114,-438.494C239.31,-428.555 271.307,-415.934 298.03,-405.394\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"299.595,-408.539 307.613,-401.614 297.027,-402.027 299.595,-408.539\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126349008&#45;&gt;139945126349736 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139945126349008-&gt;139945126349736</title>\n",
       "<path d=\"M487.886,-438.494C462.69,-428.555 430.693,-415.934 403.97,-405.394\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"404.973,-402.027 394.387,-401.614 402.405,-408.539 404.973,-402.027\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126350408 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139945126350408</title>\n",
       "<polygon fill=\"none\" points=\"284,-292.5 284,-328.5 418,-328.5 418,-292.5 284,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-306.8\">dense_4 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139945126349736&#45;&gt;139945126350408 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139945126349736-&gt;139945126350408</title>\n",
       "<path d=\"M351,-365.313C351,-357.289 351,-347.547 351,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"354.5,-338.529 351,-328.529 347.5,-338.529 354.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126349680 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139945126349680</title>\n",
       "<polygon fill=\"none\" points=\"269.5,-219.5 269.5,-255.5 432.5,-255.5 432.5,-219.5 269.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-233.8\">dropout_2 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 139945126350408&#45;&gt;139945126349680 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139945126350408-&gt;139945126349680</title>\n",
       "<path d=\"M351,-292.313C351,-284.289 351,-274.547 351,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"354.5,-265.529 351,-255.529 347.5,-265.529 354.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126361800 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139945126361800</title>\n",
       "<polygon fill=\"none\" points=\"254.5,-146.5 254.5,-182.5 447.5,-182.5 447.5,-146.5 254.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-160.8\">activation_3 (Activation)</text>\n",
       "</g>\n",
       "<!-- 139945126349680&#45;&gt;139945126361800 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139945126349680-&gt;139945126361800</title>\n",
       "<path d=\"M351,-219.313C351,-211.289 351,-201.547 351,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"354.5,-192.529 351,-182.529 347.5,-192.529 354.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126381440 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139945126381440</title>\n",
       "<polygon fill=\"none\" points=\"284,-73.5 284,-109.5 418,-109.5 418,-73.5 284,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-87.8\">dense_5 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139945126361800&#45;&gt;139945126381440 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139945126361800-&gt;139945126381440</title>\n",
       "<path d=\"M351,-146.313C351,-138.289 351,-128.547 351,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"354.5,-119.529 351,-109.529 347.5,-119.529 354.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945126393504 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139945126393504</title>\n",
       "<polygon fill=\"none\" points=\"254.5,-0.5 254.5,-36.5 447.5,-36.5 447.5,-0.5 254.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-14.8\">activation_4 (Activation)</text>\n",
       "</g>\n",
       "<!-- 139945126381440&#45;&gt;139945126393504 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>139945126381440-&gt;139945126393504</title>\n",
       "<path d=\"M351,-73.3129C351,-65.2895 351,-55.5475 351,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"354.5,-46.5288 351,-36.5288 347.5,-46.5289 354.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_y[0]))\n",
    "train_y_model = np_utils.to_categorical(train_y, nb_classes)\n",
    "dev_y_model = np_utils.to_categorical(dev_y, nb_classes)\n",
    "train_X_model = sequence.pad_sequences(train_X, maxlen=max_len)\n",
    "dev_X_model = sequence.pad_sequences(dev_X, maxlen=max_len)\n",
    "train_sentiment_X_model = sequence.pad_sequences(train_sentiment_X,maxlen=max_len)\n",
    "train_tag_X_model= sequence.pad_sequences(train_tag_X,maxlen=max_len)\n",
    "dev_sentiment_X_model = sequence.pad_sequences(dev_sentiment_X,maxlen=max_len)\n",
    "dev_tag_X_model = sequence.pad_sequences(dev_tag_X,maxlen=max_len)\n",
    "#train_embedding_X_model = batch_indexData_embedding(X=train_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = batch_indexData_embedding(X=dev_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = np.array(dev_embedding_X_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_generator3(X1=None,X2=None,X3=None,x4=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = X2[i*batch_size:(i+1)*batch_size]\n",
    "        x3_batch = X3[i*batch_size:(i+1)*batch_size]\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch,x3_batch],y_batch)\n",
    "        \n",
    "        i = i + 1\n",
    "def my_generator2(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = batch_indexData_embedding(X=x1_batch,index_wordembedding=index_wordembedding)\n",
    "        x2_batch = np.array(x2_batch)\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch],y_batch)\n",
    "        i = i + 1\n",
    "def my_generator1(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x1_batch,y_batch)\n",
    "        i = i + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.5705 - acc: 0.2712 - val_loss: 1.5302 - val_acc: 0.2734\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.4982 - acc: 0.3369 - val_loss: 1.4493 - val_acc: 0.3470\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.4139 - acc: 0.3853 - val_loss: 1.3984 - val_acc: 0.3824\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.3635 - acc: 0.3825 - val_loss: 1.3739 - val_acc: 0.3751\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.3263 - acc: 0.4241 - val_loss: 1.3458 - val_acc: 0.4096\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.2833 - acc: 0.4234 - val_loss: 1.3311 - val_acc: 0.4087\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.2688 - acc: 0.4487 - val_loss: 1.3398 - val_acc: 0.4033\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.2466 - acc: 0.4631 - val_loss: 1.3174 - val_acc: 0.4196\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.1870 - acc: 0.4787 - val_loss: 1.3320 - val_acc: 0.4060\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.1819 - acc: 0.4997 - val_loss: 1.3450 - val_acc: 0.4105\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.1330 - acc: 0.5253 - val_loss: 1.3240 - val_acc: 0.4178\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.1077 - acc: 0.5184 - val_loss: 1.3245 - val_acc: 0.4124\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 117s - loss: 1.0772 - acc: 0.5578 - val_loss: 1.3201 - val_acc: 0.4269\n",
      "Epoch 14/100\n",
      " 192/3200 [>.............................] - ETA: 96s - loss: 1.1038 - acc: 0.5677"
     ]
    }
   ],
   "source": [
    "model.fit_generator(my_generator2(train_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=([dev_X_model,dev_embedding_X_model],dev_y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5742 - acc: 0.2650 - val_loss: 1.5627 - val_acc: 0.2598\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5498 - acc: 0.2972 - val_loss: 1.5499 - val_acc: 0.3124\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5352 - acc: 0.3137 - val_loss: 1.5339 - val_acc: 0.3152\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5132 - acc: 0.3184 - val_loss: 1.5171 - val_acc: 0.3233\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4971 - acc: 0.3325 - val_loss: 1.5003 - val_acc: 0.3261\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4634 - acc: 0.3466 - val_loss: 1.4700 - val_acc: 0.3397\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 333s - loss: 1.4384 - acc: 0.3625 - val_loss: 1.4501 - val_acc: 0.3433\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4194 - acc: 0.3750 - val_loss: 1.4297 - val_acc: 0.3724\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3717 - acc: 0.4003 - val_loss: 1.4161 - val_acc: 0.3824\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3493 - acc: 0.4156 - val_loss: 1.4090 - val_acc: 0.3778\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3084 - acc: 0.4322 - val_loss: 1.3852 - val_acc: 0.3933\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.2695 - acc: 0.4575 - val_loss: 1.3687 - val_acc: 0.4078\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 333s - loss: 1.2212 - acc: 0.4756 - val_loss: 1.3693 - val_acc: 0.4033\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1907 - acc: 0.4997 - val_loss: 1.3653 - val_acc: 0.4051\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1544 - acc: 0.5112 - val_loss: 1.3740 - val_acc: 0.4024\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1122 - acc: 0.5319 - val_loss: 1.3699 - val_acc: 0.3933\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.0589 - acc: 0.5634 - val_loss: 1.3651 - val_acc: 0.4096\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 355s - loss: 1.0406 - acc: 0.5616 - val_loss: 1.3860 - val_acc: 0.4096\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.9869 - acc: 0.5944 - val_loss: 1.3892 - val_acc: 0.4078\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 361s - loss: 0.9381 - acc: 0.6294 - val_loss: 1.4016 - val_acc: 0.4078\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.8978 - acc: 0.6384 - val_loss: 1.3973 - val_acc: 0.4142\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 361s - loss: 0.8590 - acc: 0.6684 - val_loss: 1.4242 - val_acc: 0.4114\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.8235 - acc: 0.6912 - val_loss: 1.4325 - val_acc: 0.4096\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 355s - loss: 0.7772 - acc: 0.7069 - val_loss: 1.4488 - val_acc: 0.3942\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.7088 - acc: 0.7497 - val_loss: 1.5132 - val_acc: 0.3924\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.6923 - acc: 0.7562 - val_loss: 1.5027 - val_acc: 0.4078\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.6366 - acc: 0.7819 - val_loss: 1.5491 - val_acc: 0.4005\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.5884 - acc: 0.8041 - val_loss: 1.6189 - val_acc: 0.3869\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.5473 - acc: 0.8178 - val_loss: 1.6239 - val_acc: 0.4015\n",
      "Epoch 30/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4964 - acc: 0.8531 - val_loss: 1.6480 - val_acc: 0.4105\n",
      "Epoch 31/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4754 - acc: 0.8559 - val_loss: 1.7564 - val_acc: 0.3833\n",
      "Epoch 32/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4300 - acc: 0.8666 - val_loss: 1.7143 - val_acc: 0.3906\n",
      "Epoch 33/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3721 - acc: 0.8991 - val_loss: 1.7923 - val_acc: 0.3887\n",
      "Epoch 34/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3556 - acc: 0.9056 - val_loss: 1.8931 - val_acc: 0.3887\n",
      "Epoch 35/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3123 - acc: 0.9237 - val_loss: 1.8345 - val_acc: 0.3833\n",
      "Epoch 36/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2782 - acc: 0.9325 - val_loss: 2.1587 - val_acc: 0.3815\n",
      "Epoch 37/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2434 - acc: 0.9428 - val_loss: 1.9437 - val_acc: 0.3660\n",
      "Epoch 38/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2108 - acc: 0.9531 - val_loss: 2.0303 - val_acc: 0.3942\n",
      "Epoch 39/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1989 - acc: 0.9594 - val_loss: 2.1072 - val_acc: 0.4015\n",
      "Epoch 40/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1743 - acc: 0.9641 - val_loss: 2.1421 - val_acc: 0.3987\n",
      "Epoch 41/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1458 - acc: 0.9750 - val_loss: 2.2109 - val_acc: 0.3842\n",
      "Epoch 42/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1319 - acc: 0.9788 - val_loss: 2.3470 - val_acc: 0.4005\n",
      "Epoch 43/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1117 - acc: 0.9813 - val_loss: 2.2882 - val_acc: 0.3824\n",
      "Epoch 44/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1006 - acc: 0.9825 - val_loss: 2.4145 - val_acc: 0.3878\n",
      "Epoch 45/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0807 - acc: 0.9906 - val_loss: 2.4151 - val_acc: 0.3724\n",
      "Epoch 46/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0696 - acc: 0.9878 - val_loss: 2.6104 - val_acc: 0.3878\n",
      "Epoch 47/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0651 - acc: 0.9903 - val_loss: 2.6191 - val_acc: 0.4033\n",
      "Epoch 48/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0549 - acc: 0.9916 - val_loss: 2.6325 - val_acc: 0.3951\n",
      "Epoch 49/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0436 - acc: 0.9950 - val_loss: 2.6991 - val_acc: 0.4033\n",
      "Epoch 50/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0360 - acc: 0.9963 - val_loss: 2.7265 - val_acc: 0.4024\n",
      "Epoch 51/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0320 - acc: 0.9959 - val_loss: 2.7209 - val_acc: 0.3915\n",
      "Epoch 52/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0276 - acc: 0.9988 - val_loss: 2.8044 - val_acc: 0.3969\n",
      "Epoch 53/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0228 - acc: 0.9978 - val_loss: 2.8656 - val_acc: 0.3833\n",
      "Epoch 54/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0197 - acc: 0.9988 - val_loss: 3.0113 - val_acc: 0.3978\n",
      "Epoch 55/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0178 - acc: 0.9988 - val_loss: 3.1037 - val_acc: 0.3942\n",
      "Epoch 56/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0155 - acc: 0.9991 - val_loss: 3.0073 - val_acc: 0.3978\n",
      "Epoch 57/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0133 - acc: 0.9991 - val_loss: 3.0668 - val_acc: 0.4042\n",
      "Epoch 58/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0090 - acc: 1.0000 - val_loss: 3.1204 - val_acc: 0.4069\n",
      "Epoch 59/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0098 - acc: 0.9991 - val_loss: 3.1919 - val_acc: 0.3978\n",
      "Epoch 60/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0094 - acc: 0.9994 - val_loss: 3.2241 - val_acc: 0.3969\n",
      "Epoch 61/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0067 - acc: 0.9997 - val_loss: 3.2815 - val_acc: 0.3951\n",
      "Epoch 62/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0067 - acc: 0.9994 - val_loss: 3.3798 - val_acc: 0.4033\n",
      "Epoch 63/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0052 - acc: 0.9997 - val_loss: 3.4693 - val_acc: 0.3860\n",
      "Epoch 64/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0049 - acc: 0.9994 - val_loss: 3.4607 - val_acc: 0.4069\n",
      "Epoch 65/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0054 - acc: 0.9994 - val_loss: 3.4302 - val_acc: 0.4060\n",
      "Epoch 66/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0026 - acc: 1.0000 - val_loss: 3.4694 - val_acc: 0.4033\n",
      "Epoch 67/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0028 - acc: 0.9997 - val_loss: 3.5276 - val_acc: 0.4005\n",
      "Epoch 68/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0043 - acc: 0.9997 - val_loss: 3.5841 - val_acc: 0.4060\n",
      "Epoch 69/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0022 - acc: 0.9997 - val_loss: 3.6341 - val_acc: 0.4042\n",
      "Epoch 70/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0041 - acc: 0.9997 - val_loss: 3.6940 - val_acc: 0.3951\n",
      "Epoch 71/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0015 - acc: 1.0000 - val_loss: 3.7466 - val_acc: 0.3860\n",
      "Epoch 72/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0022 - acc: 0.9994 - val_loss: 3.7167 - val_acc: 0.3996\n",
      "Epoch 73/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0038 - acc: 0.9997 - val_loss: 3.7340 - val_acc: 0.3969\n",
      "Epoch 74/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.7821 - val_acc: 0.3960\n",
      "Epoch 75/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0017 - acc: 0.9997 - val_loss: 3.7606 - val_acc: 0.4015\n",
      "Epoch 76/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0027 - acc: 0.9997 - val_loss: 3.7919 - val_acc: 0.3996\n",
      "Epoch 77/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0011 - acc: 0.9997 - val_loss: 3.8756 - val_acc: 0.3987\n",
      "Epoch 78/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0034 - acc: 0.9997 - val_loss: 3.8536 - val_acc: 0.3987\n",
      "Epoch 79/100\n",
      "3200/3200 [==============================] - 334s - loss: 6.8420e-04 - acc: 1.0000 - val_loss: 3.9308 - val_acc: 0.3924\n",
      "Epoch 80/100\n",
      "3200/3200 [==============================] - 334s - loss: 9.4822e-04 - acc: 1.0000 - val_loss: 3.9247 - val_acc: 0.3978\n",
      "Epoch 81/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0031 - acc: 0.9997 - val_loss: 3.9384 - val_acc: 0.3987\n",
      "Epoch 82/100\n",
      "3200/3200 [==============================] - 334s - loss: 5.9501e-04 - acc: 1.0000 - val_loss: 3.9892 - val_acc: 0.4024\n",
      "Epoch 83/100\n",
      "3200/3200 [==============================] - 334s - loss: 7.8704e-04 - acc: 1.0000 - val_loss: 3.9495 - val_acc: 0.3969\n",
      "Epoch 84/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0029 - acc: 0.9997 - val_loss: 3.9762 - val_acc: 0.3996\n",
      "Epoch 85/100\n",
      "3200/3200 [==============================] - 334s - loss: 5.0231e-04 - acc: 1.0000 - val_loss: 4.0102 - val_acc: 0.3960\n",
      "Epoch 86/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0021 - acc: 0.9997 - val_loss: 4.0126 - val_acc: 0.4015\n",
      "Epoch 87/100\n",
      "3200/3200 [==============================] - 334s - loss: 4.8490e-04 - acc: 1.0000 - val_loss: 4.0832 - val_acc: 0.3969\n",
      "Epoch 88/100\n",
      "3200/3200 [==============================] - 334s - loss: 6.0297e-04 - acc: 1.0000 - val_loss: 4.0647 - val_acc: 0.3951\n",
      "Epoch 89/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0017 - acc: 0.9997 - val_loss: 4.1057 - val_acc: 0.3996\n",
      "Epoch 90/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.9432e-04 - acc: 1.0000 - val_loss: 4.1044 - val_acc: 0.3969\n",
      "Epoch 91/100\n",
      "3200/3200 [==============================] - 334s - loss: 7.9876e-04 - acc: 0.9997 - val_loss: 4.1034 - val_acc: 0.3951\n",
      "Epoch 92/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0021 - acc: 0.9997 - val_loss: 4.1198 - val_acc: 0.3987\n",
      "Epoch 93/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0010 - acc: 0.9997 - val_loss: 4.1375 - val_acc: 0.4005\n",
      "Epoch 94/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0019 - acc: 0.9997 - val_loss: 4.1234 - val_acc: 0.3969\n",
      "Epoch 95/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.2084e-04 - acc: 1.0000 - val_loss: 4.1963 - val_acc: 0.3924\n",
      "Epoch 96/100\n",
      "3200/3200 [==============================] - 334s - loss: 9.5798e-04 - acc: 0.9997 - val_loss: 4.1820 - val_acc: 0.3951\n",
      "Epoch 97/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0020 - acc: 0.9997 - val_loss: 4.2095 - val_acc: 0.3987\n",
      "Epoch 98/100\n",
      "3200/3200 [==============================] - 334s - loss: 2.7613e-04 - acc: 1.0000 - val_loss: 4.1888 - val_acc: 0.3960\n",
      "Epoch 99/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.6846e-04 - acc: 1.0000 - val_loss: 4.2307 - val_acc: 0.3951\n",
      "Epoch 100/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0015 - acc: 0.9997 - val_loss: 4.1971 - val_acc: 0.3942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f318951d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator(train_X_model,train_sentiment_X_model,train_tag_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=([dev_X_model,dev_sentiment_X_model,dev_tag_X_model],dev_y_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 实验结果 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-23 14：20  |36          |32         | 14526       |   200      |  50    |     2    |       300   | 0.4015|\n",
    "| 2016-11-24 11：16  |36          |32         | 14526       |  200        | 150     |   2      |      300   | 0.4142 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
