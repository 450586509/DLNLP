{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>CNN 多通道情感分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个有三个通道，分别是word embedding，POS 标签 embedding, 词的情感极性强度embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 630 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from  os.path import join\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Lambda,Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D,Convolution2D,Merge,merge\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag word 的方法： http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "2210\n",
      "1101\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.']]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['stsa.fine.test','stsa.fine.train','stsa.fine.dev']\n",
    "file_path = '/home/bruce/data/sentiment/citai_process'\n",
    "def read_file(fname=''):\n",
    "    with open(join(file_path,fname)) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().lower() for line in lines]\n",
    "    lables = [int(line[0:1]) for line in lines]\n",
    "    words = [line[2:].split() for line in lines]\n",
    "    return words,lables       \n",
    "train_X,train_y = read_file(fname='stsa.fine.train')\n",
    "test_X,test_y = read_file(fname='stsa.fine.test')\n",
    "dev_X,dev_y = read_file(fname='stsa.fine.dev')\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(dev_X))\n",
    "print(train_X[0:2])\n",
    "print(train_y[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film']\n",
      "['DET', 'NOUN', '.', 'ADJ', 'CONJ', 'ADV', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'DET', 'NOUN', 'CONJ', 'NUM', 'NOUN', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "def tag_sentence(X=[]):\n",
    "    tag_X=[]\n",
    "    for line in X:\n",
    "        word_tag = pos_tag(line,tagset='universal')\n",
    "        tag = [i[1] for i in word_tag]\n",
    "        tag_X.append(tag)\n",
    "    return tag_X\n",
    "train_tag_X = tag_sentence(X=train_X)\n",
    "dev_tag_X = tag_sentence(X=dev_X)\n",
    "test_tag_X = tag_sentence(X=test_X)\n",
    "print(train_X[0])\n",
    "print(train_tag_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感极性当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 读取情感强度文件，构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment number = 18540\n"
     ]
    }
   ],
   "source": [
    "senti_file = '/home/bruce/data/sentiment/sentiment_diction/wordwithStrength.txt'\n",
    "def construct_senti_dict(senti_file=''):\n",
    "    with open(senti_file) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().split() for line in lines]\n",
    "    lines = [(i[0],float(i[1])) for i in lines]\n",
    "    return dict(lines)\n",
    "sentiment_dict=construct_senti_dict(senti_file)\n",
    "print('sentiment number =',len(sentiment_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建情感极性强度通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '+4', '0', '0', '0', '0', '0', '0', '0', '+2', '0', '0', '-5', '0', '0', '-2', '0'], ['+5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '-5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '+6', '-2', '0', '+2', '0', '0', '-3', '0', '0', '0', '-5', '0', '0', '0', '0', '0', '0', '0', '-2', '0', '0'], ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '0', '0', '+5', '-2', '0', '+2', '+3', '0', '0', '0', '0', '0', '0', '-3', '0', '+2', '0', '0', '0']]\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.'], ['they', 'presume', 'their', 'audience', 'wo', \"n't\", 'sit', 'still', 'for', 'a', 'sociology', 'lesson', ',', 'however', 'entertainingly', 'present', ',', 'so', 'they', 'trot', 'out', 'the', 'conventional', 'science-fiction', 'element', 'of', 'bug-eyed', 'monster', 'and', 'futuristic', 'woman', 'in', 'skimpy', 'clothes', '.'], ['the', 'entire', 'movie', 'be', 'fill', 'with', 'deja', 'vu', 'moment', '.'], ['this', 'be', 'a', 'visually', 'stunning', 'rumination', 'on', 'love', ',', 'memory', ',', 'history', 'and', 'the', 'war', 'between', 'art', 'and', 'commerce', '.']]\n",
      "[4, 1, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def sentiment_strength(X=[],sentiment_dict=sentiment_dict):\n",
    "    sentiment_X = [[sentiment_dict[w] if w in sentiment_dict else 0 for w in line ]for line in X]\n",
    "    sentiment_X = [[ str(int(val*10)) if val <=0 else  '+'+str(int(val*10)) for val in line] for line in sentiment_X]\n",
    "    return sentiment_X\n",
    "train_sentiment_X = sentiment_strength(X=train_X,sentiment_dict=sentiment_dict)\n",
    "dev_sentiment_X = sentiment_strength(X=dev_X,sentiment_dict=sentiment_dict)\n",
    "test_sentiment_X = sentiment_strength(X=test_X,sentiment_dict=sentiment_dict)\n",
    "\n",
    "assert len(train_sentiment_X) == len(train_X) \n",
    "print(train_sentiment_X[0:5])\n",
    "print(train_X[0:5])    \n",
    "print(train_y[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 否定词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.资料：http://web.stanford.edu/~cgpotts/papers/potts-salt20-negation.pdf\n",
    "\n",
    "2.Negation handing in NLP  http://stackoverflow.com/questions/28720174/negation-handling-in-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leng of word_index = 14525\n",
      "length of dict_index =  14525\n"
     ]
    }
   ],
   "source": [
    "def token_to_index(datas=[]):\n",
    "    word_index={}\n",
    "    count=1\n",
    "    for data in datas:\n",
    "        for list_ in data:\n",
    "            for w in list_:\n",
    "                if w not in word_index:\n",
    "                    word_index[w] = count\n",
    "                    count = count + 1\n",
    "    print('leng of word_index =',len(word_index))\n",
    "    for i in range(len(datas)):\n",
    "        datas[i] = [[ word_index[w] for w in line ] for line in datas[i]] \n",
    "    return datas,word_index\n",
    "X,word_index = token_to_index(datas=[train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X])\n",
    "train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X = X\n",
    "\n",
    "print('length of dict_index = ',len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14498, 14499, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14500, 14498, 14498, 14501, 14498, 14498, 14502, 14498], [14503, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498]]\n",
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 11, 12, 5, 13, 14, 15], [16, 17, 18, 11, 19, 20, 9, 21, 22, 23, 24, 25]]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentiment_X[0:2])\n",
    "print(train_X[0:2])    \n",
    "print(train_y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove训练好的词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用glove基于twitter训练公开的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总word的数目=  14525\n",
      "总word embedding 的数目 =  11850\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "we_file = '/home/bruce/data/glove/twitter/glove.twitter.27B.{0}d.txt'.format(embedding_dim)\n",
    "def get_index_wordembedding(we_file='',word_index={}):\n",
    "    index_wordembedding ={}\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    for line in open(we_file):\n",
    "        elements = line.strip().split()\n",
    "        if elements[0] in  word_index:\n",
    "            index = word_index[elements[0]]\n",
    "            wordembedding = [float(i) for i in elements[1:]]\n",
    "            index_wordembedding[index] = wordembedding\n",
    "    print('总word的数目= ',len(word_index))\n",
    "    print('总word embedding 的数目 = ',len(index_wordembedding))\n",
    "    \n",
    "    for word,index in word_index.items():\n",
    "        if index not in index_wordembedding:\n",
    "            index_wordembedding[index] = zeros\n",
    "    assert len(index_wordembedding) == len(word_index)\n",
    "    return index_wordembedding\n",
    "index_wordembedding = get_index_wordembedding(we_file=we_file,word_index=word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取训练好的word embedding 数组，用来初始化 Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trained_embedding(index_wordembedding=None):\n",
    "    index_we = sorted(index_wordembedding.items())\n",
    "    print('index_we[0] =',index_we[0])\n",
    "    trained_embedding = [t[1] for t in index_we]\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    trained_embedding = np.vstack((zeros,trained_embedding))\n",
    "    return np.array(trained_embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将一个batch大小的index数据，利用index_wordembedding进行embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_indexData_embedding(X=None,index_wordembedding={}):\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    return [ [ index_wordembedding[w] if w in index_wordembedding else zeros  for w in line ] for line in X ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 36\n",
    "batch_size=50\n",
    "\n",
    "max_features= 14526\n",
    "#embedding_dims=50\n",
    "\n",
    "nb_filter = 100\n",
    "filter_length1 = 3\n",
    "filter_length2 = 4\n",
    "filter_length3 = 5\n",
    "dense1_hindden = 150*2\n",
    "nb_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.输入的变量和后面同名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN -Rand 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "(None, 100)\n",
      "dense_layer input_shape should == (300,)\n",
      "(None, 300)\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input_random = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)(input_random)\n",
    "# 卷积层\n",
    "conv1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "conv2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "\n",
    "conv3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "conv1 =GlobalMaxPooling1D(conv1)\n",
    "conv2 =GlobalMaxPooling1D()(conv2)\n",
    "conv3 =GlobalMaxPooling1D()(conv3)\n",
    "merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "# 全连接层\n",
    "dense_layer = Dense(dense1_hindden)\n",
    "dens1 = dense_layer(merged_vector)\n",
    "print('dense_layer input_shape should == (300,)')\n",
    "print(dense_layer.input_shape)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "# softmax层\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output_random = Activation('softmax')(dens2)\n",
    "\n",
    "model = Model(input=input_random,output=output_random)\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "input_static = Input(shape=(max_len,embedding_dim), name='main_input2')\n",
    "# 卷积层\n",
    "conv1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(input_static)\n",
    "\n",
    "conv2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(input_static)\n",
    "\n",
    "conv3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(input_static)\n",
    "conv1 =GlobalMaxPooling1D()(conv1)\n",
    "conv2 =GlobalMaxPooling1D()(conv2)\n",
    "conv3 =GlobalMaxPooling1D()(conv3)\n",
    "merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "\n",
    "# 全连接层\n",
    "dens1 = Dense(dense1_hindden)(merged_vector)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "# softmax层\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output_static = Activation('softmax')(dens2)\n",
    "\n",
    "model = Model(input=input_static,output=output_static)\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-non-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "index_we[0] = (1, [0.86323, 0.031356, 0.10169, 0.26639, 0.19313, -0.076727, -0.22647, -0.69596, -0.63946, -0.8632, -0.29465, -0.31175, -4.4257, -0.16769, 0.23197, -0.0085179, -0.063032, -0.044064, -0.23138, 0.59465, -0.1334, -0.61637, -0.019008, -0.31235, -0.2403, -3.112, 0.22267, -0.046524, -0.046095, 1.1434, 0.60818, 0.34767, 0.36155, 0.35258, -0.16617, 0.82837, 0.35088, -0.23608, -0.25425, 0.55587, -1.4276, 0.06918, 0.015027, -0.45487, 0.63978, -0.16407, 0.14985, 0.94771, 0.23274, -0.51445, 0.70982, 0.60018, 0.047234, -0.39084, -0.14794, 0.68263, -0.12995, -0.22846, 0.43185, -0.10681, 0.06544, 0.34506, 0.089428, 0.19983, 1.1775, -0.33236, -0.60181, 0.38324, -0.090755, -0.15759, -0.23093, -0.88441, 0.07837, 0.19774, -0.10609, 0.28091, 0.14899, -0.224, 0.20039, -0.23564, 1.5186, 0.3518, -0.10327, -0.14035, 0.084164, 0.76701, -0.54544, 0.17372, -0.02784, 0.4905, 0.45353, 0.13881, 0.091135, 0.31961, -0.077948, 0.045671, -0.55133, -0.28853, -0.50833, -0.31382])\n",
      "dense_layer input shpae =  (None, 300)\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input_non_static = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "#初始化Embedding层\n",
    "trained_embedding = get_trained_embedding(index_wordembedding=index_wordembedding)\n",
    "\n",
    "embedding_layer = Embedding(max_features,\n",
    "                            embedding_dim,\n",
    "                            weights=[trained_embedding]\n",
    "                            )\n",
    "\n",
    "embedding = embedding_layer(input_non_static)\n",
    "\n",
    "conv1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "\n",
    "conv2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "\n",
    "conv3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "dropout = Dropout(0.5)\n",
    "\n",
    "conv1 =GlobalMaxPooling1D()(conv1)\n",
    "conv2 =GlobalMaxPooling1D()(conv2)\n",
    "conv3 =GlobalMaxPooling1D()(conv3)\n",
    "#conv1 = dropout(conv1)\n",
    "#conv2 = dropout(conv2)\n",
    "#conv3 = dropout(conv3)\n",
    "\n",
    "merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "# 全连接层\n",
    "dense_layer = Dense(dense1_hindden)\n",
    "dens1 = dense_layer(merged_vector)\n",
    "print('dense_layer input shpae = ',dense_layer.input_shape)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "dens1 = dropout(dens1)\n",
    "\n",
    "# softmax层\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output_non_static = Activation('softmax')(dens2)\n",
    "\n",
    "model = Model(input=input_non_static,output=output_non_static)\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-multichannel 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "input1 = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "input2 = Input(shape=(max_len,embedding_dim), name='main_input2')\n",
    "#input3 = Input(shape=(max_len,), dtype='int32', name='main_input3')\n",
    "\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)\n",
    "embedding1 = embedding(input1)\n",
    "#embedding2 = embedding(input2)\n",
    "#embedding3 = embedding(input3)\n",
    "#---------------------------------------------------------------------------\n",
    "#卷积方法一：每个通道，用不同的卷积核\n",
    "'''\n",
    "cov1_out1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding1)\n",
    "cov1_out2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding2)\n",
    "cov1_out3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding3)\n",
    "'''\n",
    "# 卷积方法二：每个通道用相同的卷积核\n",
    "conv11 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        W_regularizer=l2(3)\n",
    "                       )\n",
    "conv12 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length2,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        W_regularizer=l2(3)\n",
    "                       )\n",
    "conv13 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length3,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        W_regularizer=l2(3)\n",
    "                       )\n",
    "dropout = Dropout(0.5)\n",
    "#第一个通道\n",
    "cov1_out11  = conv11(embedding1)\n",
    "cov1_out12  = conv12(embedding1)\n",
    "cov1_out13  = conv13(embedding1)\n",
    "cov1_out11 = dropout(cov1_out11)\n",
    "cov1_out12 = dropout(cov1_out12)\n",
    "cov1_out13 = dropout(cov1_out13)\n",
    "\n",
    "#第二个通道\n",
    "cov1_out14 = conv11(input2)\n",
    "cov1_out15 = conv12(input2)\n",
    "cov1_out16 = conv13(input2)\n",
    "cov1_out14 = dropout(cov1_out14)\n",
    "cov1_out15 = dropout(cov1_out15)\n",
    "cov1_out16 = dropout(cov1_out16)\n",
    "#cov1_out2 = conv(embedding2)\n",
    "#cov1_out3 = conv(embedding3)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "maxpooling = GlobalMaxPooling1D()\n",
    "conv11 = maxpooling(cov1_out11)\n",
    "conv12 = maxpooling(cov1_out12)\n",
    "conv13 = maxpooling(cov1_out13)\n",
    "conv14 = maxpooling(cov1_out14)\n",
    "conv15 = maxpooling(cov1_out15)\n",
    "conv16 = maxpooling(cov1_out16)\n",
    "\n",
    "merged_vector = merge([conv11,conv12,conv13,conv14,conv15,conv16], mode='concat')\n",
    "\n",
    "#dropout = Dropout(0.5)\n",
    "#merged_vector = dropout(merged_vector)\n",
    "\n",
    "dens1 = Dense(dense1_hindden)(merged_vector)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output = Activation('softmax')(dens2)\n",
    "model = Model(input=[input1,input2],output=output)\n",
    "\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 1097.00 702.00\" width=\"1097pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-698 1093,-698 1093,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140400143125080 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140400143125080</title>\n",
       "<polygon fill=\"none\" points=\"444,-657.5 444,-693.5 645,-693.5 645,-657.5 444,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-671.8\">main_input1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140400154600784 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140400154600784</title>\n",
       "<polygon fill=\"none\" points=\"440,-584.5 440,-620.5 649,-620.5 649,-584.5 440,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-598.8\">embedding_9 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140400143125080&#45;&gt;140400154600784 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140400143125080-&gt;140400154600784</title>\n",
       "<path d=\"M544.5,-657.313C544.5,-649.289 544.5,-639.547 544.5,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-630.529 544.5,-620.529 541,-630.529 548,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400143125416 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140400143125416</title>\n",
       "<polygon fill=\"none\" points=\"86,-511.5 86,-547.5 351,-547.5 351,-511.5 86,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-525.8\">convolution1d_25 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 140400154600784&#45;&gt;140400143125416 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140400154600784-&gt;140400143125416</title>\n",
       "<path d=\"M466.415,-584.494C418.293,-574.013 356.471,-560.549 306.602,-549.688\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"307.311,-546.26 296.795,-547.552 305.821,-553.1 307.311,-546.26\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142248648 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140400142248648</title>\n",
       "<polygon fill=\"none\" points=\"412,-511.5 412,-547.5 677,-547.5 677,-511.5 412,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-525.8\">convolution1d_26 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 140400154600784&#45;&gt;140400142248648 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140400154600784-&gt;140400142248648</title>\n",
       "<path d=\"M544.5,-584.313C544.5,-576.289 544.5,-566.547 544.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-557.529 544.5,-547.529 541,-557.529 548,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400143091584 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140400143091584</title>\n",
       "<polygon fill=\"none\" points=\"738,-511.5 738,-547.5 1003,-547.5 1003,-511.5 738,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"870.5\" y=\"-525.8\">convolution1d_27 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 140400154600784&#45;&gt;140400143091584 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140400154600784-&gt;140400143091584</title>\n",
       "<path d=\"M622.585,-584.494C670.707,-574.013 732.529,-560.549 782.398,-549.688\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"783.179,-553.1 792.205,-547.552 781.689,-546.26 783.179,-553.1\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142790104 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140400142790104</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 351,-474.5 351,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-452.8\">globalmaxpooling1d_25 (GlobalMaxPooling1D)</text>\n",
       "</g>\n",
       "<!-- 140400143125416&#45;&gt;140400142790104 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140400143125416-&gt;140400142790104</title>\n",
       "<path d=\"M208.091,-511.313C202.968,-502.853 196.687,-492.484 191.012,-483.112\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"193.987,-481.269 185.813,-474.529 188,-484.896 193.987,-481.269\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142790216 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140400142790216</title>\n",
       "<polygon fill=\"none\" points=\"369,-438.5 369,-474.5 720,-474.5 720,-438.5 369,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-452.8\">globalmaxpooling1d_26 (GlobalMaxPooling1D)</text>\n",
       "</g>\n",
       "<!-- 140400142248648&#45;&gt;140400142790216 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140400142248648-&gt;140400142790216</title>\n",
       "<path d=\"M544.5,-511.313C544.5,-503.289 544.5,-493.547 544.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-484.529 544.5,-474.529 541,-484.529 548,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142787976 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140400142787976</title>\n",
       "<polygon fill=\"none\" points=\"738,-438.5 738,-474.5 1089,-474.5 1089,-438.5 738,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-452.8\">globalmaxpooling1d_27 (GlobalMaxPooling1D)</text>\n",
       "</g>\n",
       "<!-- 140400143091584&#45;&gt;140400142787976 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140400143091584-&gt;140400142787976</title>\n",
       "<path d=\"M880.909,-511.313C886.032,-502.853 892.313,-492.484 897.988,-483.112\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"901,-484.896 903.187,-474.529 895.013,-481.269 901,-484.896\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142788144 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140400142788144</title>\n",
       "<polygon fill=\"none\" points=\"474,-365.5 474,-401.5 615,-401.5 615,-365.5 474,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-379.8\">merge_9 (Merge)</text>\n",
       "</g>\n",
       "<!-- 140400142790104&#45;&gt;140400142788144 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140400142790104-&gt;140400142788144</title>\n",
       "<path d=\"M263.885,-438.494C324.653,-426.801 404.722,-411.395 463.773,-400.033\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"464.644,-403.43 473.802,-398.103 463.321,-396.556 464.644,-403.43\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142790216&#45;&gt;140400142788144 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140400142790216-&gt;140400142788144</title>\n",
       "<path d=\"M544.5,-438.313C544.5,-430.289 544.5,-420.547 544.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-411.529 544.5,-401.529 541,-411.529 548,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142787976&#45;&gt;140400142788144 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140400142787976-&gt;140400142788144</title>\n",
       "<path d=\"M825.115,-438.494C764.347,-426.801 684.278,-411.395 625.227,-400.033\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"625.679,-396.556 615.198,-398.103 624.356,-403.43 625.679,-396.556\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142786688 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140400142786688</title>\n",
       "<polygon fill=\"none\" points=\"473,-292.5 473,-328.5 616,-328.5 616,-292.5 473,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-306.8\">dense_14 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140400142788144&#45;&gt;140400142786688 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140400142788144-&gt;140400142786688</title>\n",
       "<path d=\"M544.5,-365.313C544.5,-357.289 544.5,-347.547 544.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-338.529 544.5,-328.529 541,-338.529 548,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400143248072 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140400143248072</title>\n",
       "<polygon fill=\"none\" points=\"443.5,-219.5 443.5,-255.5 645.5,-255.5 645.5,-219.5 443.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-233.8\">activation_13 (Activation)</text>\n",
       "</g>\n",
       "<!-- 140400142786688&#45;&gt;140400143248072 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140400142786688-&gt;140400143248072</title>\n",
       "<path d=\"M544.5,-292.313C544.5,-284.289 544.5,-274.547 544.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-265.529 544.5,-255.529 541,-265.529 548,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400143221424 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140400143221424</title>\n",
       "<polygon fill=\"none\" points=\"463,-146.5 463,-182.5 626,-182.5 626,-146.5 463,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-160.8\">dropout_7 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140400143248072&#45;&gt;140400143221424 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140400143248072-&gt;140400143221424</title>\n",
       "<path d=\"M544.5,-219.313C544.5,-211.289 544.5,-201.547 544.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-192.529 544.5,-182.529 541,-192.529 548,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142819512 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140400142819512</title>\n",
       "<polygon fill=\"none\" points=\"473,-73.5 473,-109.5 616,-109.5 616,-73.5 473,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-87.8\">dense_15 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140400143221424&#45;&gt;140400142819512 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>140400143221424-&gt;140400142819512</title>\n",
       "<path d=\"M544.5,-146.313C544.5,-138.289 544.5,-128.547 544.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-119.529 544.5,-109.529 541,-119.529 548,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140400142846328 -->\n",
       "<g class=\"node\" id=\"node14\"><title>140400142846328</title>\n",
       "<polygon fill=\"none\" points=\"443.5,-0.5 443.5,-36.5 645.5,-36.5 645.5,-0.5 443.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"544.5\" y=\"-14.8\">activation_14 (Activation)</text>\n",
       "</g>\n",
       "<!-- 140400142819512&#45;&gt;140400142846328 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>140400142819512-&gt;140400142846328</title>\n",
       "<path d=\"M544.5,-73.3129C544.5,-65.2895 544.5,-55.5475 544.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548,-46.5288 544.5,-36.5288 541,-46.5289 548,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_y[0]))\n",
    "train_y_model = np_utils.to_categorical(train_y, nb_classes)\n",
    "dev_y_model = np_utils.to_categorical(dev_y, nb_classes)\n",
    "train_X_model = sequence.pad_sequences(train_X, maxlen=max_len)\n",
    "dev_X_model = sequence.pad_sequences(dev_X, maxlen=max_len)\n",
    "train_sentiment_X_model = sequence.pad_sequences(train_sentiment_X,maxlen=max_len)\n",
    "train_tag_X_model= sequence.pad_sequences(train_tag_X,maxlen=max_len)\n",
    "dev_sentiment_X_model = sequence.pad_sequences(dev_sentiment_X,maxlen=max_len)\n",
    "dev_tag_X_model = sequence.pad_sequences(dev_tag_X,maxlen=max_len)\n",
    "#train_embedding_X_model = batch_indexData_embedding(X=train_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = batch_indexData_embedding(X=dev_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = np.array(dev_embedding_X_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#转为index \n",
    "def to_index(word_index={},data=[]):\n",
    "    return [[word_index[w] if w in word_index else 0  for w in sentence] for sentence in data]\n",
    "test_index_X = to_index(word_index,test_X)\n",
    "#删补\n",
    "test_index_X = sequence.pad_sequences(test_index_X, maxlen=max_len)\n",
    "#embedding\n",
    "test_embedding_X = batch_indexData_embedding(X=test_index_X,index_wordembedding=index_wordembedding)\n",
    "test_y = np_utils.to_categorical(test_y, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_generator4(X1=None,X2=None,X3=None,x4=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = X2[i*batch_size:(i+1)*batch_size]\n",
    "        x3_batch = X3[i*batch_size:(i+1)*batch_size]\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch,x3_batch],y_batch)\n",
    "        i = i + 1\n",
    "def my_generator3(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = batch_indexData_embedding(X=x1_batch,index_wordembedding=index_wordembedding)\n",
    "        x2_batch = np.array(x2_batch)\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch],y_batch)\n",
    "        i = i + 1\n",
    "def my_generator1(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x1_batch,y_batch)\n",
    "        i = i + 1\n",
    "def my_generator2(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x1_batch = batch_indexData_embedding(X=x1_batch,index_wordembedding=index_wordembedding)\n",
    "        x1_batch = np.array(x1_batch)\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x1_batch,y_batch)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn random 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5767 - acc: 0.2703 - val_loss: 1.5712 - val_acc: 0.2525\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5596 - acc: 0.2778 - val_loss: 1.5728 - val_acc: 0.2598\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5658 - acc: 0.2894 - val_loss: 1.5655 - val_acc: 0.3061\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5466 - acc: 0.2975 - val_loss: 1.5611 - val_acc: 0.3025\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5434 - acc: 0.3028 - val_loss: 1.5446 - val_acc: 0.3052\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5209 - acc: 0.3100 - val_loss: 1.5319 - val_acc: 0.3252\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5031 - acc: 0.3316 - val_loss: 1.5104 - val_acc: 0.3442\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.4846 - acc: 0.3466 - val_loss: 1.4928 - val_acc: 0.3415\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.4453 - acc: 0.3744 - val_loss: 1.4612 - val_acc: 0.3597\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.4050 - acc: 0.3887 - val_loss: 1.4622 - val_acc: 0.3470\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.3714 - acc: 0.4122 - val_loss: 1.4054 - val_acc: 0.3787\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.3243 - acc: 0.4419 - val_loss: 1.3851 - val_acc: 0.3896\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.2690 - acc: 0.4550 - val_loss: 1.3682 - val_acc: 0.3960\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.2332 - acc: 0.4875 - val_loss: 1.3567 - val_acc: 0.4069\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.1868 - acc: 0.4997 - val_loss: 1.3515 - val_acc: 0.3969\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.1480 - acc: 0.5141 - val_loss: 1.3631 - val_acc: 0.4015\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.0822 - acc: 0.5591 - val_loss: 1.3894 - val_acc: 0.3851\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.0563 - acc: 0.5625 - val_loss: 1.3679 - val_acc: 0.4105\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.0052 - acc: 0.6003 - val_loss: 1.3666 - val_acc: 0.4060\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.9510 - acc: 0.6266 - val_loss: 1.3650 - val_acc: 0.4051\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.9126 - acc: 0.6431 - val_loss: 1.3916 - val_acc: 0.3942\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.8600 - acc: 0.6825 - val_loss: 1.3978 - val_acc: 0.4169\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.8188 - acc: 0.6981 - val_loss: 1.4001 - val_acc: 0.4142\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.7773 - acc: 0.7191 - val_loss: 1.4086 - val_acc: 0.4033\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.7109 - acc: 0.7609 - val_loss: 1.4367 - val_acc: 0.3806\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.6782 - acc: 0.7694 - val_loss: 1.4602 - val_acc: 0.4051\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.6215 - acc: 0.8016 - val_loss: 1.4900 - val_acc: 0.3760\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.5772 - acc: 0.8241 - val_loss: 1.5510 - val_acc: 0.3951\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.5304 - acc: 0.8406 - val_loss: 1.5368 - val_acc: 0.3942\n",
      "Epoch 30/100\n",
      "2950/3200 [==========================>...] - ETA: 9s - loss: 0.4810 - acc: 0.8664 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1deed1343cda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_generator1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1444\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(my_generator1(train_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=(dev_X_model,dev_y_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn random 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4169|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.5584 - acc: 0.2828 - val_loss: 1.5444 - val_acc: 0.2643\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.4847 - acc: 0.3403 - val_loss: 1.4650 - val_acc: 0.3371\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.4243 - acc: 0.3666 - val_loss: 1.3837 - val_acc: 0.3986\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.3394 - acc: 0.4072 - val_loss: 1.3730 - val_acc: 0.4000\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.3169 - acc: 0.4359 - val_loss: 1.3482 - val_acc: 0.3896\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.2558 - acc: 0.4484 - val_loss: 1.3557 - val_acc: 0.3792\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.2113 - acc: 0.4834 - val_loss: 1.3742 - val_acc: 0.3471\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.2069 - acc: 0.4903 - val_loss: 1.5117 - val_acc: 0.3394\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.1149 - acc: 0.5384 - val_loss: 1.3993 - val_acc: 0.3787\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.0970 - acc: 0.5488 - val_loss: 1.3774 - val_acc: 0.3900\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 7s - loss: 1.0631 - acc: 0.5684 - val_loss: 1.3594 - val_acc: 0.3787\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.9805 - acc: 0.6175 - val_loss: 1.3565 - val_acc: 0.4253\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.9682 - acc: 0.6194 - val_loss: 1.3978 - val_acc: 0.3665\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.9007 - acc: 0.6450 - val_loss: 1.3462 - val_acc: 0.4249\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.8420 - acc: 0.6863 - val_loss: 1.3573 - val_acc: 0.4244\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.8240 - acc: 0.6922 - val_loss: 1.5582 - val_acc: 0.3471\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.7362 - acc: 0.7537 - val_loss: 1.6107 - val_acc: 0.3579\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.7029 - acc: 0.7566 - val_loss: 1.6109 - val_acc: 0.3529\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.6702 - acc: 0.7709 - val_loss: 1.4396 - val_acc: 0.4195\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.5816 - acc: 0.8253 - val_loss: 1.5092 - val_acc: 0.4045\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.5794 - acc: 0.8078 - val_loss: 1.6137 - val_acc: 0.4014\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.4893 - acc: 0.8612 - val_loss: 1.5950 - val_acc: 0.3751\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.4498 - acc: 0.8812 - val_loss: 1.6020 - val_acc: 0.4231\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.4459 - acc: 0.8769 - val_loss: 1.5865 - val_acc: 0.4172\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.3555 - acc: 0.9181 - val_loss: 1.6858 - val_acc: 0.3869\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.3580 - acc: 0.9050 - val_loss: 1.6441 - val_acc: 0.4032\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.3220 - acc: 0.9225 - val_loss: 1.7096 - val_acc: 0.3842\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.2680 - acc: 0.9494 - val_loss: 1.8914 - val_acc: 0.3656\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.2819 - acc: 0.9331 - val_loss: 1.7921 - val_acc: 0.4050\n",
      "Epoch 30/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.2098 - acc: 0.9706 - val_loss: 1.8323 - val_acc: 0.3869\n",
      "Epoch 31/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1901 - acc: 0.9741 - val_loss: 1.9775 - val_acc: 0.3751\n",
      "Epoch 32/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.2023 - acc: 0.9628 - val_loss: 1.9483 - val_acc: 0.3733\n",
      "Epoch 33/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1446 - acc: 0.9872 - val_loss: 1.9446 - val_acc: 0.3878\n",
      "Epoch 34/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1630 - acc: 0.9709 - val_loss: 1.9490 - val_acc: 0.4027\n",
      "Epoch 35/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1191 - acc: 0.9906 - val_loss: 1.9762 - val_acc: 0.3851\n",
      "Epoch 36/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1015 - acc: 0.9925 - val_loss: 2.0109 - val_acc: 0.3995\n",
      "Epoch 37/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1595 - acc: 0.9669 - val_loss: 2.0891 - val_acc: 0.3896\n",
      "Epoch 38/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0829 - acc: 0.9944 - val_loss: 2.2068 - val_acc: 0.3796\n",
      "Epoch 39/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0943 - acc: 0.9838 - val_loss: 2.1990 - val_acc: 0.3982\n",
      "Epoch 40/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0690 - acc: 0.9953 - val_loss: 2.2403 - val_acc: 0.3760\n",
      "Epoch 41/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0705 - acc: 0.9922 - val_loss: 2.2084 - val_acc: 0.3819\n",
      "Epoch 42/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0502 - acc: 0.9969 - val_loss: 2.2662 - val_acc: 0.3751\n",
      "Epoch 43/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0976 - acc: 0.9809 - val_loss: 2.4123 - val_acc: 0.3683\n",
      "Epoch 44/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0428 - acc: 0.9975 - val_loss: 2.3838 - val_acc: 0.3792\n",
      "Epoch 45/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0403 - acc: 0.9984 - val_loss: 2.4797 - val_acc: 0.3751\n",
      "Epoch 46/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0328 - acc: 0.9988 - val_loss: 2.4417 - val_acc: 0.3851\n",
      "Epoch 47/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1214 - acc: 0.9656 - val_loss: 2.4314 - val_acc: 0.3937\n",
      "Epoch 48/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0284 - acc: 0.9994 - val_loss: 2.5106 - val_acc: 0.3715\n",
      "Epoch 49/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0294 - acc: 0.9975 - val_loss: 3.4529 - val_acc: 0.4104\n",
      "Epoch 50/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1825 - acc: 0.9653 - val_loss: 2.4843 - val_acc: 0.3765\n",
      "Epoch 51/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0213 - acc: 0.9997 - val_loss: 2.5460 - val_acc: 0.3742\n",
      "Epoch 52/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0236 - acc: 0.9988 - val_loss: 2.6172 - val_acc: 0.3833\n",
      "Epoch 53/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0893 - acc: 0.9787 - val_loss: 2.6454 - val_acc: 0.3738\n",
      "Epoch 54/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0186 - acc: 0.9994 - val_loss: 2.6241 - val_acc: 0.3851\n",
      "Epoch 55/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0150 - acc: 0.9991 - val_loss: 2.7681 - val_acc: 0.3937\n",
      "Epoch 56/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0655 - acc: 0.9800 - val_loss: 2.6864 - val_acc: 0.3824\n",
      "Epoch 57/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0149 - acc: 0.9994 - val_loss: 2.7132 - val_acc: 0.3774\n",
      "Epoch 58/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0254 - acc: 0.9931 - val_loss: 3.9512 - val_acc: 0.3706\n",
      "Epoch 59/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0295 - acc: 0.9953 - val_loss: 2.7956 - val_acc: 0.3851\n",
      "Epoch 60/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0095 - acc: 0.9997 - val_loss: 2.8772 - val_acc: 0.3787\n",
      "Epoch 61/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.4310 - acc: 0.9150 - val_loss: 4.1280 - val_acc: 0.3240\n",
      "Epoch 62/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0692 - acc: 0.9903 - val_loss: 2.8018 - val_acc: 0.3914\n",
      "Epoch 63/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0144 - acc: 0.9991 - val_loss: 2.8189 - val_acc: 0.3946\n",
      "Epoch 64/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1646 - acc: 0.9572 - val_loss: 2.8573 - val_acc: 0.3919\n",
      "Epoch 65/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0177 - acc: 0.9994 - val_loss: 2.8017 - val_acc: 0.3891\n",
      "Epoch 66/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0104 - acc: 0.9994 - val_loss: 2.8127 - val_acc: 0.3805\n",
      "Epoch 67/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1102 - acc: 0.9744 - val_loss: 3.0060 - val_acc: 0.3814\n",
      "Epoch 68/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0127 - acc: 0.9997 - val_loss: 2.9351 - val_acc: 0.3851\n",
      "Epoch 69/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0080 - acc: 0.9994 - val_loss: 2.8897 - val_acc: 0.3842\n",
      "Epoch 70/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1338 - acc: 0.9694 - val_loss: 2.9361 - val_acc: 0.3792\n",
      "Epoch 71/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0121 - acc: 0.9991 - val_loss: 2.9441 - val_acc: 0.3914\n",
      "Epoch 72/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0057 - acc: 1.0000 - val_loss: 3.0731 - val_acc: 0.3742\n",
      "Epoch 73/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.1114 - acc: 0.9709 - val_loss: 2.9618 - val_acc: 0.3860\n",
      "Epoch 74/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0096 - acc: 0.9991 - val_loss: 2.9474 - val_acc: 0.3783\n",
      "Epoch 75/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0049 - acc: 0.9997 - val_loss: 3.0044 - val_acc: 0.3896\n",
      "Epoch 76/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0087 - acc: 0.9997 - val_loss: 3.1179 - val_acc: 0.3787\n",
      "Epoch 77/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0633 - acc: 0.9847 - val_loss: 3.0595 - val_acc: 0.3805\n",
      "Epoch 78/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0060 - acc: 0.9994 - val_loss: 3.0769 - val_acc: 0.3719\n",
      "Epoch 79/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0069 - acc: 0.9991 - val_loss: 3.1592 - val_acc: 0.3941\n",
      "Epoch 80/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0036 - acc: 1.0000 - val_loss: 3.2115 - val_acc: 0.3923\n",
      "Epoch 81/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.2330 - acc: 0.9537 - val_loss: 3.2622 - val_acc: 0.3751\n",
      "Epoch 82/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0081 - acc: 0.9988 - val_loss: 3.1765 - val_acc: 0.3756\n",
      "Epoch 83/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0040 - acc: 0.9997 - val_loss: 3.2127 - val_acc: 0.3810\n",
      "Epoch 84/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0050 - acc: 0.9997 - val_loss: 3.2501 - val_acc: 0.3697\n",
      "Epoch 85/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0058 - acc: 0.9991 - val_loss: 3.2639 - val_acc: 0.3819\n",
      "Epoch 86/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0074 - acc: 0.9975 - val_loss: 4.9147 - val_acc: 0.3498\n",
      "Epoch 87/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0766 - acc: 0.9831 - val_loss: 3.3420 - val_acc: 0.3846\n",
      "Epoch 88/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0023 - acc: 1.0000 - val_loss: 3.3558 - val_acc: 0.3851\n",
      "Epoch 89/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0033 - acc: 0.9994 - val_loss: 3.3681 - val_acc: 0.3796\n",
      "Epoch 90/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0053 - acc: 0.9991 - val_loss: 3.3069 - val_acc: 0.3828\n",
      "Epoch 91/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0029 - acc: 0.9997 - val_loss: 3.3691 - val_acc: 0.3778\n",
      "Epoch 92/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0022 - acc: 0.9997 - val_loss: 3.4003 - val_acc: 0.3769\n",
      "Epoch 93/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0042 - acc: 0.9991 - val_loss: 3.4217 - val_acc: 0.3905\n",
      "Epoch 94/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0027 - acc: 0.9997 - val_loss: 3.4271 - val_acc: 0.3878\n",
      "Epoch 95/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0046 - acc: 0.9988 - val_loss: 3.5735 - val_acc: 0.3878\n",
      "Epoch 96/100\n",
      "3200/3200 [==============================] - 7s - loss: 8.3503e-04 - acc: 1.0000 - val_loss: 3.5545 - val_acc: 0.3760\n",
      "Epoch 97/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0035 - acc: 0.9994 - val_loss: 3.5897 - val_acc: 0.3900\n",
      "Epoch 98/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0035 - acc: 0.9991 - val_loss: 3.5030 - val_acc: 0.3787\n",
      "Epoch 99/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0027 - acc: 0.9997 - val_loss: 3.5869 - val_acc: 0.3738\n",
      "Epoch 100/100\n",
      "3200/3200 [==============================] - 7s - loss: 0.0014 - acc: 0.9997 - val_loss: 3.5620 - val_acc: 0.3805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3af9a4ac18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator2(train_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=(test_embedding_X,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn static 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4253|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn non-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.6160 - acc: 0.2560 - val_loss: 1.5496 - val_acc: 0.3081\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.5724 - acc: 0.2760 - val_loss: 1.5286 - val_acc: 0.3308\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.5372 - acc: 0.3175 - val_loss: 1.5180 - val_acc: 0.3290\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.5177 - acc: 0.3265 - val_loss: 1.4710 - val_acc: 0.3719\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4547 - acc: 0.3760 - val_loss: 1.4388 - val_acc: 0.3661\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4269 - acc: 0.3660 - val_loss: 1.4374 - val_acc: 0.3665\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4063 - acc: 0.3870 - val_loss: 1.3889 - val_acc: 0.3977\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4010 - acc: 0.3950 - val_loss: 1.3765 - val_acc: 0.3950\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3477 - acc: 0.4130 - val_loss: 1.3484 - val_acc: 0.4041\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3121 - acc: 0.4275 - val_loss: 1.3391 - val_acc: 0.4068\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3002 - acc: 0.4345 - val_loss: 1.3507 - val_acc: 0.3977\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3089 - acc: 0.4450 - val_loss: 1.4051 - val_acc: 0.3805\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2846 - acc: 0.4400 - val_loss: 1.3321 - val_acc: 0.4118\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2232 - acc: 0.4680 - val_loss: 1.3185 - val_acc: 0.4172\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2368 - acc: 0.4765 - val_loss: 1.3243 - val_acc: 0.4158\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2328 - acc: 0.4780 - val_loss: 1.3783 - val_acc: 0.3855\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2029 - acc: 0.4845 - val_loss: 1.3194 - val_acc: 0.3991\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1488 - acc: 0.5125 - val_loss: 1.3011 - val_acc: 0.4276\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1566 - acc: 0.5080 - val_loss: 1.2884 - val_acc: 0.4357\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1235 - acc: 0.5365 - val_loss: 1.3692 - val_acc: 0.3905\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1291 - acc: 0.5290 - val_loss: 1.3522 - val_acc: 0.3932\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0810 - acc: 0.5560 - val_loss: 1.3144 - val_acc: 0.4276\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0517 - acc: 0.5695 - val_loss: 1.3446 - val_acc: 0.3778\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0346 - acc: 0.5720 - val_loss: 1.3070 - val_acc: 0.4226\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0425 - acc: 0.5700 - val_loss: 1.3134 - val_acc: 0.4190\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9791 - acc: 0.6095 - val_loss: 1.3013 - val_acc: 0.4339\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9489 - acc: 0.6155 - val_loss: 1.3093 - val_acc: 0.4222\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9355 - acc: 0.6250 - val_loss: 1.3139 - val_acc: 0.4154\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9361 - acc: 0.6315 - val_loss: 1.3453 - val_acc: 0.4113\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8961 - acc: 0.6515 - val_loss: 1.3303 - val_acc: 0.4412\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8399 - acc: 0.6670 - val_loss: 1.3601 - val_acc: 0.4072\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8414 - acc: 0.6825 - val_loss: 1.3738 - val_acc: 0.3991\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8132 - acc: 0.6940 - val_loss: 1.4456 - val_acc: 0.3910\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7940 - acc: 0.6985 - val_loss: 1.3834 - val_acc: 0.3959\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7563 - acc: 0.7185 - val_loss: 1.3462 - val_acc: 0.4276\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7444 - acc: 0.7340 - val_loss: 1.3610 - val_acc: 0.4385\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7078 - acc: 0.7430 - val_loss: 1.6853 - val_acc: 0.3593\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6917 - acc: 0.7475 - val_loss: 1.4416 - val_acc: 0.4081\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6626 - acc: 0.7585 - val_loss: 1.4033 - val_acc: 0.3977\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6496 - acc: 0.7735 - val_loss: 1.4453 - val_acc: 0.3864\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5906 - acc: 0.7945 - val_loss: 1.4176 - val_acc: 0.4186\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6232 - acc: 0.7830 - val_loss: 1.4290 - val_acc: 0.4045\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5554 - acc: 0.8055 - val_loss: 1.4497 - val_acc: 0.4330\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5190 - acc: 0.8340 - val_loss: 1.5117 - val_acc: 0.4131\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5182 - acc: 0.8345 - val_loss: 1.5194 - val_acc: 0.3955\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5071 - acc: 0.8355 - val_loss: 1.5069 - val_acc: 0.4118\n",
      "Epoch 47/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4760 - acc: 0.8475 - val_loss: 1.4981 - val_acc: 0.4244\n",
      "Epoch 48/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4436 - acc: 0.8605 - val_loss: 1.5615 - val_acc: 0.4054\n",
      "Epoch 49/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4344 - acc: 0.8650 - val_loss: 1.5817 - val_acc: 0.3946\n",
      "Epoch 50/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3917 - acc: 0.8830 - val_loss: 1.6029 - val_acc: 0.3946\n",
      "Epoch 51/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4021 - acc: 0.8930 - val_loss: 1.6452 - val_acc: 0.3946\n",
      "Epoch 52/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3534 - acc: 0.9035 - val_loss: 1.5586 - val_acc: 0.4167\n",
      "Epoch 53/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3576 - acc: 0.9025 - val_loss: 1.5914 - val_acc: 0.4204\n",
      "Epoch 54/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3269 - acc: 0.9115 - val_loss: 1.7235 - val_acc: 0.3950\n",
      "Epoch 55/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3380 - acc: 0.9020 - val_loss: 1.6489 - val_acc: 0.4109\n",
      "Epoch 56/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2863 - acc: 0.9190 - val_loss: 1.6465 - val_acc: 0.4072\n",
      "Epoch 57/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2889 - acc: 0.9130 - val_loss: 1.6938 - val_acc: 0.3964\n",
      "Epoch 58/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2614 - acc: 0.9335 - val_loss: 1.7725 - val_acc: 0.3977\n",
      "Epoch 59/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2846 - acc: 0.9225 - val_loss: 1.7438 - val_acc: 0.3995\n",
      "Epoch 60/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2358 - acc: 0.9485 - val_loss: 1.7186 - val_acc: 0.4050\n",
      "Epoch 61/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2206 - acc: 0.9475 - val_loss: 2.1195 - val_acc: 0.3593\n",
      "Epoch 62/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2217 - acc: 0.9430 - val_loss: 1.7741 - val_acc: 0.4068\n",
      "Epoch 63/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2107 - acc: 0.9430 - val_loss: 1.8059 - val_acc: 0.4032\n",
      "Epoch 64/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1926 - acc: 0.9600 - val_loss: 1.8838 - val_acc: 0.4009\n",
      "Epoch 65/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1781 - acc: 0.9605 - val_loss: 1.9377 - val_acc: 0.3959\n",
      "Epoch 66/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1674 - acc: 0.9650 - val_loss: 1.9232 - val_acc: 0.3991\n",
      "Epoch 67/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1565 - acc: 0.9675 - val_loss: 2.1491 - val_acc: 0.3842\n",
      "Epoch 68/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1583 - acc: 0.9645 - val_loss: 2.1257 - val_acc: 0.3688\n",
      "Epoch 69/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1532 - acc: 0.9650 - val_loss: 2.1459 - val_acc: 0.4154\n",
      "Epoch 70/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1440 - acc: 0.9690 - val_loss: 1.9177 - val_acc: 0.4036\n",
      "Epoch 71/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1255 - acc: 0.9750 - val_loss: 2.0047 - val_acc: 0.4068\n",
      "Epoch 72/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1297 - acc: 0.9725 - val_loss: 2.0971 - val_acc: 0.3937\n",
      "Epoch 73/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1192 - acc: 0.9760 - val_loss: 2.0166 - val_acc: 0.3932\n",
      "Epoch 74/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1268 - acc: 0.9695 - val_loss: 2.0828 - val_acc: 0.3977\n",
      "Epoch 75/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1052 - acc: 0.9825 - val_loss: 2.1015 - val_acc: 0.4014\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1085 - acc: 0.9775 - val_loss: 2.2390 - val_acc: 0.3932\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0996 - acc: 0.9815 - val_loss: 2.0726 - val_acc: 0.3986\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0927 - acc: 0.9820 - val_loss: 2.1191 - val_acc: 0.4032\n",
      "Epoch 79/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0817 - acc: 0.9875 - val_loss: 2.1503 - val_acc: 0.4018\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0895 - acc: 0.9845 - val_loss: 2.1610 - val_acc: 0.4122\n",
      "Epoch 81/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0846 - acc: 0.9855 - val_loss: 2.3335 - val_acc: 0.3932\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0747 - acc: 0.9865 - val_loss: 2.2409 - val_acc: 0.3914\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0667 - acc: 0.9925 - val_loss: 2.2677 - val_acc: 0.4104\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0714 - acc: 0.9865 - val_loss: 2.4675 - val_acc: 0.3896\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0651 - acc: 0.9860 - val_loss: 2.3052 - val_acc: 0.3846\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0599 - acc: 0.9890 - val_loss: 2.2864 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0562 - acc: 0.9920 - val_loss: 2.2703 - val_acc: 0.4059\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0468 - acc: 0.9945 - val_loss: 2.3956 - val_acc: 0.4050\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0521 - acc: 0.9930 - val_loss: 2.3708 - val_acc: 0.3986\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0805 - acc: 0.9800 - val_loss: 2.4118 - val_acc: 0.3900\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0504 - acc: 0.9930 - val_loss: 2.3752 - val_acc: 0.4054\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0477 - acc: 0.9925 - val_loss: 2.3969 - val_acc: 0.3973\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0460 - acc: 0.9945 - val_loss: 2.4448 - val_acc: 0.3964\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0424 - acc: 0.9920 - val_loss: 2.4089 - val_acc: 0.4005\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0437 - acc: 0.9950 - val_loss: 2.5242 - val_acc: 0.3914\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0343 - acc: 0.9955 - val_loss: 2.4625 - val_acc: 0.3923\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0382 - acc: 0.9950 - val_loss: 2.5792 - val_acc: 0.3928\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0358 - acc: 0.9960 - val_loss: 2.5178 - val_acc: 0.3923\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0437 - acc: 0.9920 - val_loss: 2.5288 - val_acc: 0.4036\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0300 - acc: 0.9960 - val_loss: 2.6317 - val_acc: 0.4009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb173847898>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator1(train_X_model,train_y_model),samples_per_epoch = 50*40,nb_epoch=100,verbose=1,validation_data=(test_index_X,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### cnn non-static 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4204|\n",
    "| 2016-11-26 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4471|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5742 - acc: 0.2650 - val_loss: 1.5627 - val_acc: 0.2598\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5498 - acc: 0.2972 - val_loss: 1.5499 - val_acc: 0.3124\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5352 - acc: 0.3137 - val_loss: 1.5339 - val_acc: 0.3152\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5132 - acc: 0.3184 - val_loss: 1.5171 - val_acc: 0.3233\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4971 - acc: 0.3325 - val_loss: 1.5003 - val_acc: 0.3261\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4634 - acc: 0.3466 - val_loss: 1.4700 - val_acc: 0.3397\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 333s - loss: 1.4384 - acc: 0.3625 - val_loss: 1.4501 - val_acc: 0.3433\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4194 - acc: 0.3750 - val_loss: 1.4297 - val_acc: 0.3724\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3717 - acc: 0.4003 - val_loss: 1.4161 - val_acc: 0.3824\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3493 - acc: 0.4156 - val_loss: 1.4090 - val_acc: 0.3778\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3084 - acc: 0.4322 - val_loss: 1.3852 - val_acc: 0.3933\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.2695 - acc: 0.4575 - val_loss: 1.3687 - val_acc: 0.4078\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 333s - loss: 1.2212 - acc: 0.4756 - val_loss: 1.3693 - val_acc: 0.4033\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1907 - acc: 0.4997 - val_loss: 1.3653 - val_acc: 0.4051\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1544 - acc: 0.5112 - val_loss: 1.3740 - val_acc: 0.4024\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1122 - acc: 0.5319 - val_loss: 1.3699 - val_acc: 0.3933\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.0589 - acc: 0.5634 - val_loss: 1.3651 - val_acc: 0.4096\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 355s - loss: 1.0406 - acc: 0.5616 - val_loss: 1.3860 - val_acc: 0.4096\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.9869 - acc: 0.5944 - val_loss: 1.3892 - val_acc: 0.4078\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 361s - loss: 0.9381 - acc: 0.6294 - val_loss: 1.4016 - val_acc: 0.4078\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.8978 - acc: 0.6384 - val_loss: 1.3973 - val_acc: 0.4142\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 361s - loss: 0.8590 - acc: 0.6684 - val_loss: 1.4242 - val_acc: 0.4114\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.8235 - acc: 0.6912 - val_loss: 1.4325 - val_acc: 0.4096\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 355s - loss: 0.7772 - acc: 0.7069 - val_loss: 1.4488 - val_acc: 0.3942\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.7088 - acc: 0.7497 - val_loss: 1.5132 - val_acc: 0.3924\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.6923 - acc: 0.7562 - val_loss: 1.5027 - val_acc: 0.4078\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.6366 - acc: 0.7819 - val_loss: 1.5491 - val_acc: 0.4005\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.5884 - acc: 0.8041 - val_loss: 1.6189 - val_acc: 0.3869\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.5473 - acc: 0.8178 - val_loss: 1.6239 - val_acc: 0.4015\n",
      "Epoch 30/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4964 - acc: 0.8531 - val_loss: 1.6480 - val_acc: 0.4105\n",
      "Epoch 31/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4754 - acc: 0.8559 - val_loss: 1.7564 - val_acc: 0.3833\n",
      "Epoch 32/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4300 - acc: 0.8666 - val_loss: 1.7143 - val_acc: 0.3906\n",
      "Epoch 33/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3721 - acc: 0.8991 - val_loss: 1.7923 - val_acc: 0.3887\n",
      "Epoch 34/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3556 - acc: 0.9056 - val_loss: 1.8931 - val_acc: 0.3887\n",
      "Epoch 35/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3123 - acc: 0.9237 - val_loss: 1.8345 - val_acc: 0.3833\n",
      "Epoch 36/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2782 - acc: 0.9325 - val_loss: 2.1587 - val_acc: 0.3815\n",
      "Epoch 37/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2434 - acc: 0.9428 - val_loss: 1.9437 - val_acc: 0.3660\n",
      "Epoch 38/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2108 - acc: 0.9531 - val_loss: 2.0303 - val_acc: 0.3942\n",
      "Epoch 39/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1989 - acc: 0.9594 - val_loss: 2.1072 - val_acc: 0.4015\n",
      "Epoch 40/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1743 - acc: 0.9641 - val_loss: 2.1421 - val_acc: 0.3987\n",
      "Epoch 41/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1458 - acc: 0.9750 - val_loss: 2.2109 - val_acc: 0.3842\n",
      "Epoch 42/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1319 - acc: 0.9788 - val_loss: 2.3470 - val_acc: 0.4005\n",
      "Epoch 43/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1117 - acc: 0.9813 - val_loss: 2.2882 - val_acc: 0.3824\n",
      "Epoch 44/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1006 - acc: 0.9825 - val_loss: 2.4145 - val_acc: 0.3878\n",
      "Epoch 45/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0807 - acc: 0.9906 - val_loss: 2.4151 - val_acc: 0.3724\n",
      "Epoch 46/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0696 - acc: 0.9878 - val_loss: 2.6104 - val_acc: 0.3878\n",
      "Epoch 47/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0651 - acc: 0.9903 - val_loss: 2.6191 - val_acc: 0.4033\n",
      "Epoch 48/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0549 - acc: 0.9916 - val_loss: 2.6325 - val_acc: 0.3951\n",
      "Epoch 49/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0436 - acc: 0.9950 - val_loss: 2.6991 - val_acc: 0.4033\n",
      "Epoch 50/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0360 - acc: 0.9963 - val_loss: 2.7265 - val_acc: 0.4024\n",
      "Epoch 51/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0320 - acc: 0.9959 - val_loss: 2.7209 - val_acc: 0.3915\n",
      "Epoch 52/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0276 - acc: 0.9988 - val_loss: 2.8044 - val_acc: 0.3969\n",
      "Epoch 53/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0228 - acc: 0.9978 - val_loss: 2.8656 - val_acc: 0.3833\n",
      "Epoch 54/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0197 - acc: 0.9988 - val_loss: 3.0113 - val_acc: 0.3978\n",
      "Epoch 55/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0178 - acc: 0.9988 - val_loss: 3.1037 - val_acc: 0.3942\n",
      "Epoch 56/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0155 - acc: 0.9991 - val_loss: 3.0073 - val_acc: 0.3978\n",
      "Epoch 57/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0133 - acc: 0.9991 - val_loss: 3.0668 - val_acc: 0.4042\n",
      "Epoch 58/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0090 - acc: 1.0000 - val_loss: 3.1204 - val_acc: 0.4069\n",
      "Epoch 59/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0098 - acc: 0.9991 - val_loss: 3.1919 - val_acc: 0.3978\n",
      "Epoch 60/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0094 - acc: 0.9994 - val_loss: 3.2241 - val_acc: 0.3969\n",
      "Epoch 61/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0067 - acc: 0.9997 - val_loss: 3.2815 - val_acc: 0.3951\n",
      "Epoch 62/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0067 - acc: 0.9994 - val_loss: 3.3798 - val_acc: 0.4033\n",
      "Epoch 63/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0052 - acc: 0.9997 - val_loss: 3.4693 - val_acc: 0.3860\n",
      "Epoch 64/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0049 - acc: 0.9994 - val_loss: 3.4607 - val_acc: 0.4069\n",
      "Epoch 65/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0054 - acc: 0.9994 - val_loss: 3.4302 - val_acc: 0.4060\n",
      "Epoch 66/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0026 - acc: 1.0000 - val_loss: 3.4694 - val_acc: 0.4033\n",
      "Epoch 67/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0028 - acc: 0.9997 - val_loss: 3.5276 - val_acc: 0.4005\n",
      "Epoch 68/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0043 - acc: 0.9997 - val_loss: 3.5841 - val_acc: 0.4060\n",
      "Epoch 69/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0022 - acc: 0.9997 - val_loss: 3.6341 - val_acc: 0.4042\n",
      "Epoch 70/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0041 - acc: 0.9997 - val_loss: 3.6940 - val_acc: 0.3951\n",
      "Epoch 71/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0015 - acc: 1.0000 - val_loss: 3.7466 - val_acc: 0.3860\n",
      "Epoch 72/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0022 - acc: 0.9994 - val_loss: 3.7167 - val_acc: 0.3996\n",
      "Epoch 73/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0038 - acc: 0.9997 - val_loss: 3.7340 - val_acc: 0.3969\n",
      "Epoch 74/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.7821 - val_acc: 0.3960\n",
      "Epoch 75/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0017 - acc: 0.9997 - val_loss: 3.7606 - val_acc: 0.4015\n",
      "Epoch 76/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0027 - acc: 0.9997 - val_loss: 3.7919 - val_acc: 0.3996\n",
      "Epoch 77/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0011 - acc: 0.9997 - val_loss: 3.8756 - val_acc: 0.3987\n",
      "Epoch 78/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0034 - acc: 0.9997 - val_loss: 3.8536 - val_acc: 0.3987\n",
      "Epoch 79/100\n",
      "3200/3200 [==============================] - 334s - loss: 6.8420e-04 - acc: 1.0000 - val_loss: 3.9308 - val_acc: 0.3924\n",
      "Epoch 80/100\n",
      "3200/3200 [==============================] - 334s - loss: 9.4822e-04 - acc: 1.0000 - val_loss: 3.9247 - val_acc: 0.3978\n",
      "Epoch 81/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0031 - acc: 0.9997 - val_loss: 3.9384 - val_acc: 0.3987\n",
      "Epoch 82/100\n",
      "3200/3200 [==============================] - 334s - loss: 5.9501e-04 - acc: 1.0000 - val_loss: 3.9892 - val_acc: 0.4024\n",
      "Epoch 83/100\n",
      "3200/3200 [==============================] - 334s - loss: 7.8704e-04 - acc: 1.0000 - val_loss: 3.9495 - val_acc: 0.3969\n",
      "Epoch 84/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0029 - acc: 0.9997 - val_loss: 3.9762 - val_acc: 0.3996\n",
      "Epoch 85/100\n",
      "3200/3200 [==============================] - 334s - loss: 5.0231e-04 - acc: 1.0000 - val_loss: 4.0102 - val_acc: 0.3960\n",
      "Epoch 86/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0021 - acc: 0.9997 - val_loss: 4.0126 - val_acc: 0.4015\n",
      "Epoch 87/100\n",
      "3200/3200 [==============================] - 334s - loss: 4.8490e-04 - acc: 1.0000 - val_loss: 4.0832 - val_acc: 0.3969\n",
      "Epoch 88/100\n",
      "3200/3200 [==============================] - 334s - loss: 6.0297e-04 - acc: 1.0000 - val_loss: 4.0647 - val_acc: 0.3951\n",
      "Epoch 89/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0017 - acc: 0.9997 - val_loss: 4.1057 - val_acc: 0.3996\n",
      "Epoch 90/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.9432e-04 - acc: 1.0000 - val_loss: 4.1044 - val_acc: 0.3969\n",
      "Epoch 91/100\n",
      "3200/3200 [==============================] - 334s - loss: 7.9876e-04 - acc: 0.9997 - val_loss: 4.1034 - val_acc: 0.3951\n",
      "Epoch 92/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0021 - acc: 0.9997 - val_loss: 4.1198 - val_acc: 0.3987\n",
      "Epoch 93/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0010 - acc: 0.9997 - val_loss: 4.1375 - val_acc: 0.4005\n",
      "Epoch 94/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0019 - acc: 0.9997 - val_loss: 4.1234 - val_acc: 0.3969\n",
      "Epoch 95/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.2084e-04 - acc: 1.0000 - val_loss: 4.1963 - val_acc: 0.3924\n",
      "Epoch 96/100\n",
      "3200/3200 [==============================] - 334s - loss: 9.5798e-04 - acc: 0.9997 - val_loss: 4.1820 - val_acc: 0.3951\n",
      "Epoch 97/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0020 - acc: 0.9997 - val_loss: 4.2095 - val_acc: 0.3987\n",
      "Epoch 98/100\n",
      "3200/3200 [==============================] - 334s - loss: 2.7613e-04 - acc: 1.0000 - val_loss: 4.1888 - val_acc: 0.3960\n",
      "Epoch 99/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.6846e-04 - acc: 1.0000 - val_loss: 4.2307 - val_acc: 0.3951\n",
      "Epoch 100/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0015 - acc: 0.9997 - val_loss: 4.1971 - val_acc: 0.3942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f318951d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator(train_X_model,train_sentiment_X_model,train_tag_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=([dev_X_model,dev_sentiment_X_model,dev_tag_X_model],dev_y_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 实验结果 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-23 14：20  |36          |32         | 14526       |   200      |  50    |     2    |       300   | 0.4015|\n",
    "| 2016-11-24 11：16  |36          |32         | 14526       |  200        | 150     |   2      |      300   | 0.4142 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 两通道实验结果，一个是用训练好的词向量初始化句子，另一个是用随机初始化的词向量初始化句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |32         | 14526       |   100      |  各100    |     3,4,5    |       300   | 0.4124|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
