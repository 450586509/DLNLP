{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>CNN 多通道情感分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个有三个通道，分别是word embedding，POS 标签 embedding, 词的情感极性强度embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from  os.path import join\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Lambda,Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D,Convolution2D,Merge,merge\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag word 的方法： http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "2210\n",
      "1101\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.']]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['stsa.fine.test','stsa.fine.train','stsa.fine.dev']\n",
    "file_path = '/home/bruce/data/sentiment/citai_process'\n",
    "def read_file(fname=''):\n",
    "    with open(join(file_path,fname)) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().lower() for line in lines]\n",
    "    lables = [int(line[0:1]) for line in lines]\n",
    "    words = [line[2:].split() for line in lines]\n",
    "    return words,lables       \n",
    "train_X,train_y = read_file(fname='stsa.fine.train')\n",
    "test_X,test_y = read_file(fname='stsa.fine.test')\n",
    "dev_X,dev_y = read_file(fname='stsa.fine.dev')\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(dev_X))\n",
    "print(train_X[0:2])\n",
    "print(train_y[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film']\n",
      "['DET', 'NOUN', '.', 'ADJ', 'CONJ', 'ADV', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'DET', 'NOUN', 'CONJ', 'NUM', 'NOUN', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "def tag_sentence(X=[]):\n",
    "    tag_X=[]\n",
    "    for line in X:\n",
    "        word_tag = pos_tag(line,tagset='universal')\n",
    "        tag = [i[1] for i in word_tag]\n",
    "        tag_X.append(tag)\n",
    "    return tag_X\n",
    "train_tag_X = tag_sentence(X=train_X)\n",
    "dev_tag_X = tag_sentence(X=dev_X)\n",
    "print(train_X[0])\n",
    "print(train_tag_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感极性当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 读取情感强度文件，构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment number = 18540\n"
     ]
    }
   ],
   "source": [
    "senti_file = '/home/bruce/data/sentiment/sentiment_diction/wordwithStrength.txt'\n",
    "def construct_senti_dict(senti_file=''):\n",
    "    with open(senti_file) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().split() for line in lines]\n",
    "    lines = [(i[0],float(i[1])) for i in lines]\n",
    "    return dict(lines)\n",
    "sentiment_dict=construct_senti_dict(senti_file)\n",
    "print('sentiment number =',len(sentiment_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建情感极性强度通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '+4', '0', '0', '0', '0', '0', '0', '0', '+2', '0', '0', '-5', '0', '0', '-2', '0'], ['+5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '-5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '+6', '-2', '0', '+2', '0', '0', '-3', '0', '0', '0', '-5', '0', '0', '0', '0', '0', '0', '0', '-2', '0', '0'], ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '0', '0', '+5', '-2', '0', '+2', '+3', '0', '0', '0', '0', '0', '0', '-3', '0', '+2', '0', '0', '0']]\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.'], ['they', 'presume', 'their', 'audience', 'wo', \"n't\", 'sit', 'still', 'for', 'a', 'sociology', 'lesson', ',', 'however', 'entertainingly', 'present', ',', 'so', 'they', 'trot', 'out', 'the', 'conventional', 'science-fiction', 'element', 'of', 'bug-eyed', 'monster', 'and', 'futuristic', 'woman', 'in', 'skimpy', 'clothes', '.'], ['the', 'entire', 'movie', 'be', 'fill', 'with', 'deja', 'vu', 'moment', '.'], ['this', 'be', 'a', 'visually', 'stunning', 'rumination', 'on', 'love', ',', 'memory', ',', 'history', 'and', 'the', 'war', 'between', 'art', 'and', 'commerce', '.']]\n",
      "[4, 1, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def sentiment_strength(X=[],sentiment_dict=sentiment_dict):\n",
    "    sentiment_X = [[sentiment_dict[w] if w in sentiment_dict else 0 for w in line ]for line in X]\n",
    "    sentiment_X = [[ str(int(val*10)) if val <=0 else  '+'+str(int(val*10)) for val in line] for line in sentiment_X]\n",
    "    return sentiment_X\n",
    "train_sentiment_X = sentiment_strength(X=train_X,sentiment_dict=sentiment_dict)\n",
    "dev_sentiment_X = sentiment_strength(X=dev_X,sentiment_dict=sentiment_dict)\n",
    "\n",
    "assert len(train_sentiment_X) == len(train_X) \n",
    "print(train_sentiment_X[0:5])\n",
    "print(train_X[0:5])    \n",
    "print(train_y[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 否定词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.资料：http://web.stanford.edu/~cgpotts/papers/potts-salt20-negation.pdf\n",
    "\n",
    "2.Negation handing in NLP  http://stackoverflow.com/questions/28720174/negation-handling-in-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leng of word_index = 14525\n",
      "length of dict_index =  14525\n"
     ]
    }
   ],
   "source": [
    "def token_to_index(datas=[]):\n",
    "    word_index={}\n",
    "    count=1\n",
    "    for data in datas:\n",
    "        for list_ in data:\n",
    "            for w in list_:\n",
    "                if w not in word_index:\n",
    "                    word_index[w] = count\n",
    "                    count = count + 1\n",
    "    print('leng of word_index =',len(word_index))\n",
    "    for i in range(len(datas)):\n",
    "        datas[i] = [[ word_index[w] for w in line ] for line in datas[i]] \n",
    "    return datas,word_index\n",
    "X,word_index = token_to_index(datas=[train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X])\n",
    "train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X = X\n",
    "\n",
    "print('length of dict_index = ',len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14498, 14499, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14500, 14498, 14498, 14501, 14498, 14498, 14502, 14498], [14503, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498]]\n",
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 11, 12, 5, 13, 14, 15], [16, 17, 18, 11, 19, 20, 9, 21, 22, 23, 24, 25]]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentiment_X[0:2])\n",
    "print(train_X[0:2])    \n",
    "print(train_y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove训练好的词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用glove基于twitter训练公开的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总word的数目=  14525\n",
      "总word embedding 的数目 =  11850\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "we_file = '/home/bruce/data/glove/twitter/glove.twitter.27B.{0}d.txt'.format(embedding_dim)\n",
    "def get_index_wordembedding(we_file='',word_index={}):\n",
    "    index_wordembedding ={}\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    for line in open(we_file):\n",
    "        elements = line.strip().split()\n",
    "        if elements[0] in  word_index:\n",
    "            index = word_index[elements[0]]\n",
    "            wordembedding = [float(i) for i in elements[1:]]\n",
    "            index_wordembedding[index] = wordembedding\n",
    "    print('总word的数目= ',len(word_index))\n",
    "    print('总word embedding 的数目 = ',len(index_wordembedding))\n",
    "    \n",
    "    for word,index in word_index.items():\n",
    "        if index not in index_wordembedding:\n",
    "            index_wordembedding[index] = zeros\n",
    "    assert len(index_wordembedding) == len(word_index)\n",
    "    return index_wordembedding\n",
    "index_wordembedding = get_index_wordembedding(we_file=we_file,word_index=word_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将一个batch大小的index数据，利用index_wordembedding进行embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_indexData_embedding(X=None,index_wordembedding={}):\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    return [ [ index_wordembedding[w] if w in index_wordembedding else zeros  for w in line ] for line in X ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 36\n",
    "batch_size=32\n",
    "\n",
    "max_features= 14526\n",
    "#embedding_dims=50\n",
    "\n",
    "nb_filter = 100\n",
    "filter_length1 = 3\n",
    "filter_length2 = 4\n",
    "filter_length3 = 5\n",
    "dense1_hindden = 150*2\n",
    "nb_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.输入的变量和后面同名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input1 = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "input2 = Input(shape=(max_len,embedding_dim), name='main_input2')\n",
    "#input3 = Input(shape=(max_len,), dtype='int32', name='main_input3')\n",
    "\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)\n",
    "embedding1 = embedding(input1)\n",
    "#embedding2 = embedding(input2)\n",
    "#embedding3 = embedding(input3)\n",
    "#---------------------------------------------------------------------------\n",
    "#卷积方法一：每个通道，用不同的卷积核\n",
    "'''\n",
    "cov1_out1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )(embedding1)\n",
    "cov1_out2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )(embedding2)\n",
    "cov1_out3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )(embedding3)\n",
    "'''\n",
    "# 卷积方法二：每个通道用相同的卷积核\n",
    "conv11 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )\n",
    "conv12 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length2,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )\n",
    "conv13 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length3,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length = 1\n",
    "                       )\n",
    "#第一个通道\n",
    "cov1_out11  = conv11(embedding1)\n",
    "cov1_out12  = conv12(embedding1)\n",
    "cov1_out13  = conv13(embedding1)\n",
    "\n",
    "\n",
    "#第二个通道\n",
    "cov1_out14 = conv11(input2)\n",
    "cov1_out15 = conv12(input2)\n",
    "cov1_out16 = conv13(input2)\n",
    "#cov1_out2 = conv(embedding2)\n",
    "#cov1_out3 = conv(embedding3)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "maxpooling = GlobalMaxPooling1D()\n",
    "conv11 = maxpooling(cov1_out11)\n",
    "conv12 = maxpooling(cov1_out12)\n",
    "conv13 = maxpooling(cov1_out13)\n",
    "conv14 = maxpooling(cov1_out14)\n",
    "conv15 = maxpooling(cov1_out15)\n",
    "conv16 = maxpooling(cov1_out16)\n",
    "\n",
    "merged_vector = merge([conv11,conv12,conv13,conv14,conv15,conv16], mode='concat')\n",
    "\n",
    "\n",
    "dens1 = Dense(dense1_hindden)(merged_vector)\n",
    "dens1 = Dropout(0.2)(dens1)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output = Activation('softmax')(dens2)\n",
    "model = Model(input=[input1,input2],output=output)\n",
    "\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 821.50 702.00\" width=\"822pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-698 817.5,-698 817.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139945162453456 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139945162453456</title>\n",
       "<polygon fill=\"none\" points=\"189.5,-657.5 189.5,-693.5 390.5,-693.5 390.5,-657.5 189.5,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290\" y=\"-671.8\">main_input1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139945162453792 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139945162453792</title>\n",
       "<polygon fill=\"none\" points=\"185.5,-584.5 185.5,-620.5 394.5,-620.5 394.5,-584.5 185.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290\" y=\"-598.8\">embedding_8 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 139945162453456&#45;&gt;139945162453792 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139945162453456-&gt;139945162453792</title>\n",
       "<path d=\"M290,-657.313C290,-649.289 290,-639.547 290,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"293.5,-630.529 290,-620.529 286.5,-630.529 293.5,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162454184 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139945162454184</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 256,-547.5 256,-511.5 0,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128\" y=\"-525.8\">convolution1d_8 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 139945162453792&#45;&gt;139945162454184 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139945162453792-&gt;139945162454184</title>\n",
       "<path d=\"M251.197,-584.494C228.72,-574.643 200.228,-562.156 176.307,-551.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"177.612,-548.422 167.048,-547.614 174.802,-554.833 177.612,-548.422\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162454240 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139945162454240</title>\n",
       "<polygon fill=\"none\" points=\"274,-511.5 274,-547.5 530,-547.5 530,-511.5 274,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-525.8\">convolution1d_9 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 139945162453792&#45;&gt;139945162454240 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139945162453792-&gt;139945162454240</title>\n",
       "<path d=\"M316.827,-584.494C331.679,-575.079 350.329,-563.255 366.389,-553.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"368.432,-555.924 375.004,-547.614 364.684,-550.012 368.432,-555.924\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162462768 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139945162462768</title>\n",
       "<polygon fill=\"none\" points=\"548.5,-511.5 548.5,-547.5 813.5,-547.5 813.5,-511.5 548.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"681\" y=\"-525.8\">convolution1d_10 (Convolution1D)</text>\n",
       "</g>\n",
       "<!-- 139945162453792&#45;&gt;139945162462768 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139945162453792-&gt;139945162462768</title>\n",
       "<path d=\"M383.654,-584.494C441.972,-573.904 517.066,-560.268 577.196,-549.349\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"577.88,-552.782 587.094,-547.552 576.63,-545.895 577.88,-552.782\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162453512 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139945162453512</title>\n",
       "<polygon fill=\"none\" points=\"412.5,-584.5 412.5,-620.5 613.5,-620.5 613.5,-584.5 412.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"513\" y=\"-598.8\">main_input2 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139945162453512&#45;&gt;139945162454184 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139945162453512-&gt;139945162454184</title>\n",
       "<path d=\"M420.783,-584.494C363.478,-573.926 289.724,-560.324 230.577,-549.417\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.934,-545.924 220.465,-547.552 229.664,-552.808 230.934,-545.924\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162453512&#45;&gt;139945162454240 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139945162453512-&gt;139945162454240</title>\n",
       "<path d=\"M486.413,-584.494C471.693,-575.079 453.209,-563.255 437.293,-553.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"439.065,-550.054 428.755,-547.614 435.293,-555.95 439.065,-550.054\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162453512&#45;&gt;139945162462768 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139945162453512-&gt;139945162462768</title>\n",
       "<path d=\"M553.24,-584.494C576.653,-574.599 606.358,-562.045 631.232,-551.533\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"632.657,-554.73 640.506,-547.614 629.932,-548.283 632.657,-554.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162594792 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139945162594792</title>\n",
       "<polygon fill=\"none\" points=\"231,-438.5 231,-474.5 573,-474.5 573,-438.5 231,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-452.8\">globalmaxpooling1d_8 (GlobalMaxPooling1D)</text>\n",
       "</g>\n",
       "<!-- 139945162454184&#45;&gt;139945162594792 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139945162454184-&gt;139945162594792</title>\n",
       "<path d=\"M193.63,-511.494C233.497,-501.163 284.552,-487.934 326.145,-477.156\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"327.154,-480.51 335.956,-474.614 325.398,-473.734 327.154,-480.51\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162454240&#45;&gt;139945162594792 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139945162454240-&gt;139945162594792</title>\n",
       "<path d=\"M402,-511.313C402,-503.289 402,-493.547 402,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-484.529 402,-474.529 398.5,-484.529 405.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162462768&#45;&gt;139945162594792 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139945162462768-&gt;139945162594792</title>\n",
       "<path d=\"M614.173,-511.494C573.492,-501.141 521.372,-487.878 478.971,-477.088\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"479.803,-473.688 469.249,-474.614 478.077,-480.472 479.803,-473.688\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162613088 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139945162613088</title>\n",
       "<polygon fill=\"none\" points=\"331.5,-365.5 331.5,-401.5 472.5,-401.5 472.5,-365.5 331.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-379.8\">merge_5 (Merge)</text>\n",
       "</g>\n",
       "<!-- 139945162594792&#45;&gt;139945162613088 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>139945162594792-&gt;139945162613088</title>\n",
       "<path d=\"M402,-438.313C402,-430.289 402,-420.547 402,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-411.529 402,-401.529 398.5,-411.529 405.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162612352 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139945162612352</title>\n",
       "<polygon fill=\"none\" points=\"335,-292.5 335,-328.5 469,-328.5 469,-292.5 335,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-306.8\">dense_6 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139945162613088&#45;&gt;139945162612352 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>139945162613088-&gt;139945162612352</title>\n",
       "<path d=\"M402,-365.313C402,-357.289 402,-347.547 402,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-338.529 402,-328.529 398.5,-338.529 405.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162609720 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139945162609720</title>\n",
       "<polygon fill=\"none\" points=\"320.5,-219.5 320.5,-255.5 483.5,-255.5 483.5,-219.5 320.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-233.8\">dropout_3 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 139945162612352&#45;&gt;139945162609720 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>139945162612352-&gt;139945162609720</title>\n",
       "<path d=\"M402,-292.313C402,-284.289 402,-274.547 402,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-265.529 402,-255.529 398.5,-265.529 405.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162625656 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139945162625656</title>\n",
       "<polygon fill=\"none\" points=\"305.5,-146.5 305.5,-182.5 498.5,-182.5 498.5,-146.5 305.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-160.8\">activation_5 (Activation)</text>\n",
       "</g>\n",
       "<!-- 139945162609720&#45;&gt;139945162625656 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>139945162609720-&gt;139945162625656</title>\n",
       "<path d=\"M402,-219.313C402,-211.289 402,-201.547 402,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-192.529 402,-182.529 398.5,-192.529 405.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162629192 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139945162629192</title>\n",
       "<polygon fill=\"none\" points=\"335,-73.5 335,-109.5 469,-109.5 469,-73.5 335,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-87.8\">dense_7 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139945162625656&#45;&gt;139945162629192 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>139945162625656-&gt;139945162629192</title>\n",
       "<path d=\"M402,-146.313C402,-138.289 402,-128.547 402,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-119.529 402,-109.529 398.5,-119.529 405.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945162635416 -->\n",
       "<g class=\"node\" id=\"node13\"><title>139945162635416</title>\n",
       "<polygon fill=\"none\" points=\"305.5,-0.5 305.5,-36.5 498.5,-36.5 498.5,-0.5 305.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-14.8\">activation_6 (Activation)</text>\n",
       "</g>\n",
       "<!-- 139945162629192&#45;&gt;139945162635416 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>139945162629192-&gt;139945162635416</title>\n",
       "<path d=\"M402,-73.3129C402,-65.2895 402,-55.5475 402,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-46.5288 402,-36.5288 398.5,-46.5289 405.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_y[0]))\n",
    "train_y_model = np_utils.to_categorical(train_y, nb_classes)\n",
    "dev_y_model = np_utils.to_categorical(dev_y, nb_classes)\n",
    "train_X_model = sequence.pad_sequences(train_X, maxlen=max_len)\n",
    "dev_X_model = sequence.pad_sequences(dev_X, maxlen=max_len)\n",
    "train_sentiment_X_model = sequence.pad_sequences(train_sentiment_X,maxlen=max_len)\n",
    "train_tag_X_model= sequence.pad_sequences(train_tag_X,maxlen=max_len)\n",
    "dev_sentiment_X_model = sequence.pad_sequences(dev_sentiment_X,maxlen=max_len)\n",
    "dev_tag_X_model = sequence.pad_sequences(dev_tag_X,maxlen=max_len)\n",
    "#train_embedding_X_model = batch_indexData_embedding(X=train_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = batch_indexData_embedding(X=dev_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = np.array(dev_embedding_X_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_generator3(X1=None,X2=None,X3=None,x4=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = X2[i*batch_size:(i+1)*batch_size]\n",
    "        x3_batch = X3[i*batch_size:(i+1)*batch_size]\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch,x3_batch],y_batch)\n",
    "        \n",
    "        i = i + 1\n",
    "def my_generator2(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = batch_indexData_embedding(X=x1_batch,index_wordembedding=index_wordembedding)\n",
    "        x2_batch = np.array(x2_batch)\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch],y_batch)\n",
    "        i = i + 1\n",
    "def my_generator1(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x1_batch,y_batch)\n",
    "        i = i + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2176/3200 [===================>..........] - ETA: 75s - loss: 1.5887 - acc: 0.2642"
     ]
    }
   ],
   "source": [
    "model.fit_generator(my_generator2(train_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=([dev_X_model,dev_embedding_X_model],dev_y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5742 - acc: 0.2650 - val_loss: 1.5627 - val_acc: 0.2598\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5498 - acc: 0.2972 - val_loss: 1.5499 - val_acc: 0.3124\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5352 - acc: 0.3137 - val_loss: 1.5339 - val_acc: 0.3152\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.5132 - acc: 0.3184 - val_loss: 1.5171 - val_acc: 0.3233\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4971 - acc: 0.3325 - val_loss: 1.5003 - val_acc: 0.3261\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4634 - acc: 0.3466 - val_loss: 1.4700 - val_acc: 0.3397\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 333s - loss: 1.4384 - acc: 0.3625 - val_loss: 1.4501 - val_acc: 0.3433\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.4194 - acc: 0.3750 - val_loss: 1.4297 - val_acc: 0.3724\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3717 - acc: 0.4003 - val_loss: 1.4161 - val_acc: 0.3824\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3493 - acc: 0.4156 - val_loss: 1.4090 - val_acc: 0.3778\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.3084 - acc: 0.4322 - val_loss: 1.3852 - val_acc: 0.3933\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.2695 - acc: 0.4575 - val_loss: 1.3687 - val_acc: 0.4078\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 333s - loss: 1.2212 - acc: 0.4756 - val_loss: 1.3693 - val_acc: 0.4033\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1907 - acc: 0.4997 - val_loss: 1.3653 - val_acc: 0.4051\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1544 - acc: 0.5112 - val_loss: 1.3740 - val_acc: 0.4024\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.1122 - acc: 0.5319 - val_loss: 1.3699 - val_acc: 0.3933\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 334s - loss: 1.0589 - acc: 0.5634 - val_loss: 1.3651 - val_acc: 0.4096\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 355s - loss: 1.0406 - acc: 0.5616 - val_loss: 1.3860 - val_acc: 0.4096\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.9869 - acc: 0.5944 - val_loss: 1.3892 - val_acc: 0.4078\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 361s - loss: 0.9381 - acc: 0.6294 - val_loss: 1.4016 - val_acc: 0.4078\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.8978 - acc: 0.6384 - val_loss: 1.3973 - val_acc: 0.4142\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 361s - loss: 0.8590 - acc: 0.6684 - val_loss: 1.4242 - val_acc: 0.4114\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 362s - loss: 0.8235 - acc: 0.6912 - val_loss: 1.4325 - val_acc: 0.4096\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 355s - loss: 0.7772 - acc: 0.7069 - val_loss: 1.4488 - val_acc: 0.3942\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.7088 - acc: 0.7497 - val_loss: 1.5132 - val_acc: 0.3924\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.6923 - acc: 0.7562 - val_loss: 1.5027 - val_acc: 0.4078\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.6366 - acc: 0.7819 - val_loss: 1.5491 - val_acc: 0.4005\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.5884 - acc: 0.8041 - val_loss: 1.6189 - val_acc: 0.3869\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.5473 - acc: 0.8178 - val_loss: 1.6239 - val_acc: 0.4015\n",
      "Epoch 30/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4964 - acc: 0.8531 - val_loss: 1.6480 - val_acc: 0.4105\n",
      "Epoch 31/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4754 - acc: 0.8559 - val_loss: 1.7564 - val_acc: 0.3833\n",
      "Epoch 32/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.4300 - acc: 0.8666 - val_loss: 1.7143 - val_acc: 0.3906\n",
      "Epoch 33/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3721 - acc: 0.8991 - val_loss: 1.7923 - val_acc: 0.3887\n",
      "Epoch 34/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3556 - acc: 0.9056 - val_loss: 1.8931 - val_acc: 0.3887\n",
      "Epoch 35/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.3123 - acc: 0.9237 - val_loss: 1.8345 - val_acc: 0.3833\n",
      "Epoch 36/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2782 - acc: 0.9325 - val_loss: 2.1587 - val_acc: 0.3815\n",
      "Epoch 37/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2434 - acc: 0.9428 - val_loss: 1.9437 - val_acc: 0.3660\n",
      "Epoch 38/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.2108 - acc: 0.9531 - val_loss: 2.0303 - val_acc: 0.3942\n",
      "Epoch 39/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1989 - acc: 0.9594 - val_loss: 2.1072 - val_acc: 0.4015\n",
      "Epoch 40/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1743 - acc: 0.9641 - val_loss: 2.1421 - val_acc: 0.3987\n",
      "Epoch 41/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1458 - acc: 0.9750 - val_loss: 2.2109 - val_acc: 0.3842\n",
      "Epoch 42/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1319 - acc: 0.9788 - val_loss: 2.3470 - val_acc: 0.4005\n",
      "Epoch 43/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1117 - acc: 0.9813 - val_loss: 2.2882 - val_acc: 0.3824\n",
      "Epoch 44/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.1006 - acc: 0.9825 - val_loss: 2.4145 - val_acc: 0.3878\n",
      "Epoch 45/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0807 - acc: 0.9906 - val_loss: 2.4151 - val_acc: 0.3724\n",
      "Epoch 46/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0696 - acc: 0.9878 - val_loss: 2.6104 - val_acc: 0.3878\n",
      "Epoch 47/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0651 - acc: 0.9903 - val_loss: 2.6191 - val_acc: 0.4033\n",
      "Epoch 48/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0549 - acc: 0.9916 - val_loss: 2.6325 - val_acc: 0.3951\n",
      "Epoch 49/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0436 - acc: 0.9950 - val_loss: 2.6991 - val_acc: 0.4033\n",
      "Epoch 50/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0360 - acc: 0.9963 - val_loss: 2.7265 - val_acc: 0.4024\n",
      "Epoch 51/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0320 - acc: 0.9959 - val_loss: 2.7209 - val_acc: 0.3915\n",
      "Epoch 52/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0276 - acc: 0.9988 - val_loss: 2.8044 - val_acc: 0.3969\n",
      "Epoch 53/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0228 - acc: 0.9978 - val_loss: 2.8656 - val_acc: 0.3833\n",
      "Epoch 54/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0197 - acc: 0.9988 - val_loss: 3.0113 - val_acc: 0.3978\n",
      "Epoch 55/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0178 - acc: 0.9988 - val_loss: 3.1037 - val_acc: 0.3942\n",
      "Epoch 56/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0155 - acc: 0.9991 - val_loss: 3.0073 - val_acc: 0.3978\n",
      "Epoch 57/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0133 - acc: 0.9991 - val_loss: 3.0668 - val_acc: 0.4042\n",
      "Epoch 58/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0090 - acc: 1.0000 - val_loss: 3.1204 - val_acc: 0.4069\n",
      "Epoch 59/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0098 - acc: 0.9991 - val_loss: 3.1919 - val_acc: 0.3978\n",
      "Epoch 60/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0094 - acc: 0.9994 - val_loss: 3.2241 - val_acc: 0.3969\n",
      "Epoch 61/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0067 - acc: 0.9997 - val_loss: 3.2815 - val_acc: 0.3951\n",
      "Epoch 62/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0067 - acc: 0.9994 - val_loss: 3.3798 - val_acc: 0.4033\n",
      "Epoch 63/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0052 - acc: 0.9997 - val_loss: 3.4693 - val_acc: 0.3860\n",
      "Epoch 64/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0049 - acc: 0.9994 - val_loss: 3.4607 - val_acc: 0.4069\n",
      "Epoch 65/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0054 - acc: 0.9994 - val_loss: 3.4302 - val_acc: 0.4060\n",
      "Epoch 66/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0026 - acc: 1.0000 - val_loss: 3.4694 - val_acc: 0.4033\n",
      "Epoch 67/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0028 - acc: 0.9997 - val_loss: 3.5276 - val_acc: 0.4005\n",
      "Epoch 68/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0043 - acc: 0.9997 - val_loss: 3.5841 - val_acc: 0.4060\n",
      "Epoch 69/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0022 - acc: 0.9997 - val_loss: 3.6341 - val_acc: 0.4042\n",
      "Epoch 70/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0041 - acc: 0.9997 - val_loss: 3.6940 - val_acc: 0.3951\n",
      "Epoch 71/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0015 - acc: 1.0000 - val_loss: 3.7466 - val_acc: 0.3860\n",
      "Epoch 72/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0022 - acc: 0.9994 - val_loss: 3.7167 - val_acc: 0.3996\n",
      "Epoch 73/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0038 - acc: 0.9997 - val_loss: 3.7340 - val_acc: 0.3969\n",
      "Epoch 74/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.7821 - val_acc: 0.3960\n",
      "Epoch 75/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0017 - acc: 0.9997 - val_loss: 3.7606 - val_acc: 0.4015\n",
      "Epoch 76/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0027 - acc: 0.9997 - val_loss: 3.7919 - val_acc: 0.3996\n",
      "Epoch 77/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0011 - acc: 0.9997 - val_loss: 3.8756 - val_acc: 0.3987\n",
      "Epoch 78/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0034 - acc: 0.9997 - val_loss: 3.8536 - val_acc: 0.3987\n",
      "Epoch 79/100\n",
      "3200/3200 [==============================] - 334s - loss: 6.8420e-04 - acc: 1.0000 - val_loss: 3.9308 - val_acc: 0.3924\n",
      "Epoch 80/100\n",
      "3200/3200 [==============================] - 334s - loss: 9.4822e-04 - acc: 1.0000 - val_loss: 3.9247 - val_acc: 0.3978\n",
      "Epoch 81/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0031 - acc: 0.9997 - val_loss: 3.9384 - val_acc: 0.3987\n",
      "Epoch 82/100\n",
      "3200/3200 [==============================] - 334s - loss: 5.9501e-04 - acc: 1.0000 - val_loss: 3.9892 - val_acc: 0.4024\n",
      "Epoch 83/100\n",
      "3200/3200 [==============================] - 334s - loss: 7.8704e-04 - acc: 1.0000 - val_loss: 3.9495 - val_acc: 0.3969\n",
      "Epoch 84/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0029 - acc: 0.9997 - val_loss: 3.9762 - val_acc: 0.3996\n",
      "Epoch 85/100\n",
      "3200/3200 [==============================] - 334s - loss: 5.0231e-04 - acc: 1.0000 - val_loss: 4.0102 - val_acc: 0.3960\n",
      "Epoch 86/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0021 - acc: 0.9997 - val_loss: 4.0126 - val_acc: 0.4015\n",
      "Epoch 87/100\n",
      "3200/3200 [==============================] - 334s - loss: 4.8490e-04 - acc: 1.0000 - val_loss: 4.0832 - val_acc: 0.3969\n",
      "Epoch 88/100\n",
      "3200/3200 [==============================] - 334s - loss: 6.0297e-04 - acc: 1.0000 - val_loss: 4.0647 - val_acc: 0.3951\n",
      "Epoch 89/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0017 - acc: 0.9997 - val_loss: 4.1057 - val_acc: 0.3996\n",
      "Epoch 90/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.9432e-04 - acc: 1.0000 - val_loss: 4.1044 - val_acc: 0.3969\n",
      "Epoch 91/100\n",
      "3200/3200 [==============================] - 334s - loss: 7.9876e-04 - acc: 0.9997 - val_loss: 4.1034 - val_acc: 0.3951\n",
      "Epoch 92/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0021 - acc: 0.9997 - val_loss: 4.1198 - val_acc: 0.3987\n",
      "Epoch 93/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0010 - acc: 0.9997 - val_loss: 4.1375 - val_acc: 0.4005\n",
      "Epoch 94/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0019 - acc: 0.9997 - val_loss: 4.1234 - val_acc: 0.3969\n",
      "Epoch 95/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.2084e-04 - acc: 1.0000 - val_loss: 4.1963 - val_acc: 0.3924\n",
      "Epoch 96/100\n",
      "3200/3200 [==============================] - 334s - loss: 9.5798e-04 - acc: 0.9997 - val_loss: 4.1820 - val_acc: 0.3951\n",
      "Epoch 97/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0020 - acc: 0.9997 - val_loss: 4.2095 - val_acc: 0.3987\n",
      "Epoch 98/100\n",
      "3200/3200 [==============================] - 334s - loss: 2.7613e-04 - acc: 1.0000 - val_loss: 4.1888 - val_acc: 0.3960\n",
      "Epoch 99/100\n",
      "3200/3200 [==============================] - 334s - loss: 3.6846e-04 - acc: 1.0000 - val_loss: 4.2307 - val_acc: 0.3951\n",
      "Epoch 100/100\n",
      "3200/3200 [==============================] - 334s - loss: 0.0015 - acc: 0.9997 - val_loss: 4.1971 - val_acc: 0.3942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f318951d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator(train_X_model,train_sentiment_X_model,train_tag_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=([dev_X_model,dev_sentiment_X_model,dev_tag_X_model],dev_y_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 实验结果 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-23 14：20  |36          |32         | 14526       |   200      |  50    |     2    |       300   | 0.4015|\n",
    "| 2016-11-24 11：16  |36          |32         | 14526       |  200        | 150     |   2      |      300   | 0.4142 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
