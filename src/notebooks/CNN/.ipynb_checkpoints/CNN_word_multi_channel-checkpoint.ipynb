{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>CNN 多通道情感分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个有三个通道，分别是word embedding，POS 标签 embedding, 词的情感极性强度embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "from  os.path import join\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Lambda,Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D,Convolution2D,Merge,merge,Reshape,MaxPooling2D,Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag word 的方法： http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "2210\n",
      "1101\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.']]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['stsa.fine.test','stsa.fine.train','stsa.fine.dev']\n",
    "file_path = '/home/bruce/data/sentiment/citai_process'\n",
    "def read_file(fname=''):\n",
    "    with open(join(file_path,fname)) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().lower() for line in lines]\n",
    "    lables = [int(line[0:1]) for line in lines]\n",
    "    words = [line[2:].split() for line in lines]\n",
    "    return words,lables       \n",
    "train_X,train_y = read_file(fname='stsa.fine.train')\n",
    "test_X,test_y = read_file(fname='stsa.fine.test')\n",
    "dev_X,dev_y = read_file(fname='stsa.fine.dev')\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(dev_X))\n",
    "print(train_X[0:2])\n",
    "print(train_y[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film']\n",
      "['DET', 'NOUN', '.', 'ADJ', 'CONJ', 'ADV', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'DET', 'NOUN', 'CONJ', 'NUM', 'NOUN', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "def tag_sentence(X=[]):\n",
    "    tag_X=[]\n",
    "    for line in X:\n",
    "        word_tag = pos_tag(line,tagset='universal')\n",
    "        tag = [i[1] for i in word_tag]\n",
    "        tag_X.append(tag)\n",
    "    return tag_X\n",
    "train_tag_X = tag_sentence(X=train_X)\n",
    "dev_tag_X = tag_sentence(X=dev_X)\n",
    "test_tag_X = tag_sentence(X=test_X)\n",
    "print(train_X[0])\n",
    "print(train_tag_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感极性当作一个通道。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 读取情感强度文件，构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment number = 18540\n"
     ]
    }
   ],
   "source": [
    "senti_file = '/home/bruce/data/sentiment/sentiment_diction/wordwithStrength.txt'\n",
    "def construct_senti_dict(senti_file=''):\n",
    "    with open(senti_file) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [line.strip().split() for line in lines]\n",
    "    lines = [(i[0],float(i[1])) for i in lines]\n",
    "    return dict(lines)\n",
    "sentiment_dict=construct_senti_dict(senti_file)\n",
    "print('sentiment number =',len(sentiment_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建情感极性强度通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '+4', '0', '0', '0', '0', '0', '0', '0', '+2', '0', '0', '-5', '0', '0', '-2', '0'], ['+5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '-5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '+6', '-2', '0', '+2', '0', '0', '-3', '0', '0', '0', '-5', '0', '0', '0', '0', '0', '0', '0', '-2', '0', '0'], ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '0', '0', '+5', '-2', '0', '+2', '+3', '0', '0', '0', '0', '0', '0', '-3', '0', '+2', '0', '0', '0']]\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transport', 're-imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'film'], ['apparently', 'reassemble', 'from', 'the', 'cutting-room', 'floor', 'of', 'any', 'give', 'daytime', 'soap', '.'], ['they', 'presume', 'their', 'audience', 'wo', \"n't\", 'sit', 'still', 'for', 'a', 'sociology', 'lesson', ',', 'however', 'entertainingly', 'present', ',', 'so', 'they', 'trot', 'out', 'the', 'conventional', 'science-fiction', 'element', 'of', 'bug-eyed', 'monster', 'and', 'futuristic', 'woman', 'in', 'skimpy', 'clothes', '.'], ['the', 'entire', 'movie', 'be', 'fill', 'with', 'deja', 'vu', 'moment', '.'], ['this', 'be', 'a', 'visually', 'stunning', 'rumination', 'on', 'love', ',', 'memory', ',', 'history', 'and', 'the', 'war', 'between', 'art', 'and', 'commerce', '.']]\n",
      "[4, 1, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def sentiment_strength(X=[],sentiment_dict=sentiment_dict):\n",
    "    sentiment_X = [[sentiment_dict[w] if w in sentiment_dict else 0 for w in line ]for line in X]\n",
    "    sentiment_X = [[ str(int(val*10)) if val <=0 else  '+'+str(int(val*10)) for val in line] for line in sentiment_X]\n",
    "    return sentiment_X\n",
    "train_sentiment_X = sentiment_strength(X=train_X,sentiment_dict=sentiment_dict)\n",
    "dev_sentiment_X = sentiment_strength(X=dev_X,sentiment_dict=sentiment_dict)\n",
    "test_sentiment_X = sentiment_strength(X=test_X,sentiment_dict=sentiment_dict)\n",
    "\n",
    "assert len(train_sentiment_X) == len(train_X) \n",
    "print(train_sentiment_X[0:5])\n",
    "print(train_X[0:5])    \n",
    "print(train_y[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 否定词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.资料：http://web.stanford.edu/~cgpotts/papers/potts-salt20-negation.pdf\n",
    "\n",
    "2.Negation handing in NLP  http://stackoverflow.com/questions/28720174/negation-handling-in-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leng of word_index = 14525\n",
      "length of dict_index =  14525\n"
     ]
    }
   ],
   "source": [
    "def token_to_index(datas=[]):\n",
    "    word_index={}\n",
    "    count=1\n",
    "    for data in datas:\n",
    "        for list_ in data:\n",
    "            for w in list_:\n",
    "                if w not in word_index:\n",
    "                    word_index[w] = count\n",
    "                    count = count + 1\n",
    "    print('leng of word_index =',len(word_index))\n",
    "    for i in range(len(datas)):\n",
    "        datas[i] = [[ word_index[w] for w in line ] for line in datas[i]] \n",
    "    return datas,word_index\n",
    "X,word_index = token_to_index(datas=[train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X])\n",
    "train_X,dev_X,train_sentiment_X,train_tag_X,dev_sentiment_X,dev_tag_X = X\n",
    "\n",
    "print('length of dict_index = ',len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14498, 14499, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14500, 14498, 14498, 14501, 14498, 14498, 14502, 14498], [14503, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498, 14498]]\n",
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 11, 12, 5, 13, 14, 15], [16, 17, 18, 11, 19, 20, 9, 21, 22, 23, 24, 25]]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentiment_X[0:2])\n",
    "print(train_X[0:2])    \n",
    "print(train_y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove训练好的词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用glove基于twitter训练公开的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总word的数目=  14525\n",
      "总word embedding 的数目 =  11850\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "we_file = '/home/bruce/data/glove/twitter/glove.twitter.27B.{0}d.txt'.format(embedding_dim)\n",
    "def get_index_wordembedding(we_file='',word_index={}):\n",
    "    index_wordembedding ={}\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    for line in open(we_file):\n",
    "        elements = line.strip().split()\n",
    "        if elements[0] in  word_index:\n",
    "            index = word_index[elements[0]]\n",
    "            wordembedding = [float(i) for i in elements[1:]]\n",
    "            index_wordembedding[index] = wordembedding\n",
    "    print('总word的数目= ',len(word_index))\n",
    "    print('总word embedding 的数目 = ',len(index_wordembedding))\n",
    "    \n",
    "    for word,index in word_index.items():\n",
    "        if index not in index_wordembedding:\n",
    "            index_wordembedding[index] = zeros\n",
    "    assert len(index_wordembedding) == len(word_index)\n",
    "    return index_wordembedding\n",
    "index_wordembedding = get_index_wordembedding(we_file=we_file,word_index=word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取训练好的word embedding 数组，用来初始化 Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trained_embedding(index_wordembedding=None):\n",
    "    index_we = sorted(index_wordembedding.items())\n",
    "    print('index_we[0] =',index_we[0])\n",
    "    trained_embedding = [t[1] for t in index_we]\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    trained_embedding = np.vstack((zeros,trained_embedding))\n",
    "    return np.array(trained_embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将一个batch大小的index数据，利用index_wordembedding进行embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_indexData_embedding(X=None,index_wordembedding={}):\n",
    "    zeros = np.zeros(embedding_dim)\n",
    "    return [ [ index_wordembedding[w] if w in index_wordembedding else zeros  for w in line ] for line in X ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 36\n",
    "batch_size=50\n",
    "\n",
    "max_features= 14526\n",
    "#embedding_dims=50\n",
    "\n",
    "nb_filter = 300\n",
    "filter_length1 = 2\n",
    "filter_length2 = 3\n",
    "filter_length3 = 4\n",
    "filter_size=(3,100)\n",
    "dense1_hindden = 150*2\n",
    "nb_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.输入的变量和后面同名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN -Rand 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "(None, 100)\n",
      "dense_layer input_shape should == (300,)\n",
      "(None, 300)\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input_random = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)(input_random)\n",
    "# 卷积层\n",
    "conv1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "conv2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "\n",
    "conv3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "conv1 =GlobalMaxPooling1D(conv1)\n",
    "conv2 =GlobalMaxPooling1D()(conv2)\n",
    "conv3 =GlobalMaxPooling1D()(conv3)\n",
    "merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "# 全连接层\n",
    "dense_layer = Dense(dense1_hindden)\n",
    "dens1 = dense_layer(merged_vector)\n",
    "print('dense_layer input_shape should == (300,)')\n",
    "print(dense_layer.input_shape)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "# softmax层\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output_random = Activation('softmax')(dens2)\n",
    "\n",
    "model = Model(input=input_random,output=output_random)\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "input_static = Input(shape=(max_len,embedding_dim), name='main_input2')\n",
    "# 卷积层\n",
    "conv1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(input_static)\n",
    "\n",
    "conv2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(input_static)\n",
    "\n",
    "conv3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(input_static)\n",
    "\n",
    "conv1 =GlobalMaxPooling1D()(conv1)\n",
    "conv2 =GlobalMaxPooling1D()(conv2)\n",
    "conv3 =GlobalMaxPooling1D()(conv3)\n",
    "merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "\n",
    "# 全连接层\n",
    "dens1 = Dense(dense1_hindden)(merged_vector)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "\n",
    "# softmax层\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output_static = Activation('softmax')(dens2)\n",
    "\n",
    "model = Model(input=input_static,output=output_static)\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-non-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "index_we[0] = (1, [0.86323, 0.031356, 0.10169, 0.26639, 0.19313, -0.076727, -0.22647, -0.69596, -0.63946, -0.8632, -0.29465, -0.31175, -4.4257, -0.16769, 0.23197, -0.0085179, -0.063032, -0.044064, -0.23138, 0.59465, -0.1334, -0.61637, -0.019008, -0.31235, -0.2403, -3.112, 0.22267, -0.046524, -0.046095, 1.1434, 0.60818, 0.34767, 0.36155, 0.35258, -0.16617, 0.82837, 0.35088, -0.23608, -0.25425, 0.55587, -1.4276, 0.06918, 0.015027, -0.45487, 0.63978, -0.16407, 0.14985, 0.94771, 0.23274, -0.51445, 0.70982, 0.60018, 0.047234, -0.39084, -0.14794, 0.68263, -0.12995, -0.22846, 0.43185, -0.10681, 0.06544, 0.34506, 0.089428, 0.19983, 1.1775, -0.33236, -0.60181, 0.38324, -0.090755, -0.15759, -0.23093, -0.88441, 0.07837, 0.19774, -0.10609, 0.28091, 0.14899, -0.224, 0.20039, -0.23564, 1.5186, 0.3518, -0.10327, -0.14035, 0.084164, 0.76701, -0.54544, 0.17372, -0.02784, 0.4905, 0.45353, 0.13881, 0.091135, 0.31961, -0.077948, 0.045671, -0.55133, -0.28853, -0.50833, -0.31382])\n",
      "dense_layer input shpae =  (None, 300)\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input_non_static = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "#初始化Embedding层\n",
    "trained_embedding = get_trained_embedding(index_wordembedding=index_wordembedding)\n",
    "\n",
    "embedding_layer = Embedding(max_features,\n",
    "                            embedding_dim,\n",
    "                            weights=[trained_embedding]\n",
    "                            )\n",
    "\n",
    "embedding = embedding_layer(input_non_static)\n",
    "\n",
    "conv1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "\n",
    "conv2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "\n",
    "conv3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding)\n",
    "dropout = Dropout(0.5)\n",
    "\n",
    "conv1 =GlobalMaxPooling1D()(conv1)\n",
    "conv2 =GlobalMaxPooling1D()(conv2)\n",
    "conv3 =GlobalMaxPooling1D()(conv3)\n",
    "#conv1 = dropout(conv1)\n",
    "#conv2 = dropout(conv2)\n",
    "#conv3 = dropout(conv3)\n",
    "\n",
    "merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "# 全连接层\n",
    "dense_layer = Dense(dense1_hindden)\n",
    "dens1 = dense_layer(merged_vector)\n",
    "print('dense_layer input shpae = ',dense_layer.input_shape)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "dens1 = dropout(dens1)\n",
    "\n",
    "# softmax层\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output_non_static = Activation('softmax')(dens2)\n",
    "\n",
    "model = Model(input=input_non_static,output=output_non_static)\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-multichannel 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "embedding1 output_shape =  (None, 36, 100)\n",
      "reshape output_shape =  (None, 2, 36, 100)\n",
      "conv_layer1 output shpae should be (100,35,1) (None, 300, 34, 1)\n",
      "(100,1)== (None, 300, 1, 1)\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input1 = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "input2 = Input(shape=(max_len,), name='main_input2')\n",
    "#input3 = Input(shape=(max_len,), dtype='int32', name='main_input3')\n",
    "\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)\n",
    "embedding1 = embedding(input1)\n",
    "print('embedding1 output_shape = ',embedding.output_shape)\n",
    "embedding2 = embedding(input2)\n",
    "merged_vector = merge([embedding1,embedding2], mode='concat')\n",
    "reshape = Reshape((2,max_len,embedding_dim))\n",
    "word_sentiment = reshape(merged_vector)\n",
    "print('reshape output_shape = ',reshape.output_shape)\n",
    "conv_layer1 = Convolution2D(nb_filter, filter_size[0], filter_size[1],\n",
    "                      activation='relu',\n",
    "                      border_mode='valid')\n",
    "conv1 = conv_layer1(word_sentiment)\n",
    "print('conv_layer1 output shpae should be (100,35,1)',conv_layer1.output_shape)\n",
    "maxpool = MaxPooling2D(pool_size=(34, 1))\n",
    "conv1 = maxpool(conv1)\n",
    "print('(100,1)==', maxpool.output_shape)\n",
    "fatten = Flatten()\n",
    "conv1 = fatten(conv1)\n",
    "dens1 = Dense(dense1_hindden)(conv1)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "dropout = Dropout(0.5)\n",
    "dens1 = dropout(dens1)\n",
    "\n",
    "\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output = Activation('softmax')(dens2)\n",
    "#model = Model(input=[input1,input2],output=output)\n",
    "model = Model(input=[input1,input2],output=output)\n",
    "\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "finish build model\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "input1 = Input(shape=(max_len,), dtype='int32', name='main_input1')\n",
    "input2 = Input(shape=(max_len,), name='main_input2')\n",
    "#input3 = Input(shape=(max_len,), dtype='int32', name='main_input3')\n",
    "\n",
    "embedding = Embedding(output_dim=embedding_dim, input_dim=max_features)\n",
    "embedding1 = embedding(input1)\n",
    "embedding2 = embedding(input2)\n",
    "merged_vector = merge([conv11,conv12], mode='concat')\n",
    "reshape = Reshape((2,max_len,embedding_dim))\n",
    "word_sentiment = reshape(merged_vector)\n",
    "print('reshape input shpae should be (72,100)= ',reshape.input_shape)\n",
    "#embedding3 = embedding(input3)\n",
    "#---------------------------------------------------------------------------\n",
    "#卷积方法一：每个通道，用不同的卷积核\n",
    "'''\n",
    "cov1_out1 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding1)\n",
    "cov1_out2 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding2)\n",
    "cov1_out3 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )(embedding3)\n",
    "'''\n",
    "# 卷积方法二：每个通道用相同的卷积核\n",
    "conv11 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )\n",
    "conv12 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length2,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )\n",
    "conv13 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length3,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )\n",
    "conv14 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length1,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )\n",
    "conv15 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length2,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )\n",
    "conv16 = Convolution1D(nb_filter = nb_filter,\n",
    "                        filter_length = filter_length3,\n",
    "                        border_mode = 'valid',\n",
    "                        activation='relu'\n",
    "                       )\n",
    "dropout = Dropout(0.5)\n",
    "#第一个通道\n",
    "cov1_out11  = conv11(embedding1)\n",
    "cov1_out12  = conv12(embedding1)\n",
    "cov1_out13  = conv13(embedding1)\n",
    "'''\n",
    "cov1_out11 = dropout(cov1_out11)\n",
    "cov1_out12 = dropout(cov1_out12)\n",
    "cov1_out13 = dropout(cov1_out13)\n",
    "'''\n",
    "'''\n",
    "#第二个通道\n",
    "cov1_out14 = conv14(embedding2)\n",
    "cov1_out15 = conv15(embedding2)\n",
    "cov1_out16 = conv16(embedding2)\n",
    "'''\n",
    "#第三个通道：\n",
    "\n",
    "'''\n",
    "cov1_out14 = dropout(cov1_out14)\n",
    "cov1_out15 = dropout(cov1_out15)\n",
    "cov1_out16 = dropout(cov1_out16)\n",
    "'''\n",
    "#cov1_out2 = conv(embedding2)\n",
    "#cov1_out3 = conv(embedding3)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "maxpooling = GlobalMaxPooling1D()\n",
    "conv11 = maxpooling(cov1_out11)\n",
    "conv12 = maxpooling(cov1_out12)\n",
    "conv13 = maxpooling(cov1_out13)\n",
    "conv14 = maxpooling(cov1_out14)\n",
    "conv15 = maxpooling(cov1_out15)\n",
    "conv16 = maxpooling(cov1_out16)\n",
    "\n",
    "#merged_vector = merge([conv11,conv12,conv13,conv14,conv15,conv16], mode='concat')\n",
    "merged_vector = merge([conv11,conv12,conv13], mode='concat')\n",
    "\n",
    "#dropout = Dropout(0.5)\n",
    "#merged_vector = dropout(merged_vector)\n",
    "\n",
    "dens1 = Dense(dense1_hindden)(merged_vector)\n",
    "dens1 = Activation('relu')(dens1)\n",
    "dens1 = dropout(dens1)\n",
    "\n",
    "\n",
    "dens2 = Dense(nb_classes)(dens1)\n",
    "output = Activation('softmax')(dens2)\n",
    "#model = Model(input=[input1,input2],output=output)\n",
    "model = Model(input=[input1],output=output)\n",
    "\n",
    "print('finish build model')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"848pt\" viewBox=\"0.00 0.00 428.00 848.00\" width=\"428pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 844)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-844 424,-844 424,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140204253645512 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140204253645512</title>\n",
       "<polygon fill=\"none\" points=\"0,-803.5 0,-839.5 201,-839.5 201,-803.5 0,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"100.5\" y=\"-817.8\">main_input1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140204253643328 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140204253643328</title>\n",
       "<polygon fill=\"none\" points=\"105,-730.5 105,-766.5 314,-766.5 314,-730.5 105,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-744.8\">embedding_8 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140204253645512&#45;&gt;140204253643328 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140204253645512-&gt;140204253643328</title>\n",
       "<path d=\"M126.608,-803.494C141.063,-794.079 159.213,-782.255 174.843,-772.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"176.758,-775.004 183.227,-766.614 172.938,-769.139 176.758,-775.004\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204253645568 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140204253645568</title>\n",
       "<polygon fill=\"none\" points=\"219,-803.5 219,-839.5 420,-839.5 420,-803.5 219,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319.5\" y=\"-817.8\">main_input2 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140204253645568&#45;&gt;140204253643328 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140204253645568-&gt;140204253643328</title>\n",
       "<path d=\"M293.152,-803.494C278.565,-794.079 260.248,-782.255 244.475,-772.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246.314,-769.096 236.014,-766.614 242.518,-774.977 246.314,-769.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204253643440 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140204253643440</title>\n",
       "<polygon fill=\"none\" points=\"139,-657.5 139,-693.5 280,-693.5 280,-657.5 139,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-671.8\">merge_8 (Merge)</text>\n",
       "</g>\n",
       "<!-- 140204253643328&#45;&gt;140204253643440 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140204253643328-&gt;140204253643440</title>\n",
       "<path d=\"M209.5,-730.313C209.5,-722.289 209.5,-712.547 209.5,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-703.529 209.5,-693.529 206,-703.529 213,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204253183784 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140204253183784</title>\n",
       "<polygon fill=\"none\" points=\"126.5,-584.5 126.5,-620.5 292.5,-620.5 292.5,-584.5 126.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-598.8\">reshape_8 (Reshape)</text>\n",
       "</g>\n",
       "<!-- 140204253643440&#45;&gt;140204253183784 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140204253643440-&gt;140204253183784</title>\n",
       "<path d=\"M209.5,-657.313C209.5,-649.289 209.5,-639.547 209.5,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-630.529 209.5,-620.529 206,-630.529 213,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204255246656 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140204255246656</title>\n",
       "<polygon fill=\"none\" points=\"81.5,-511.5 81.5,-547.5 337.5,-547.5 337.5,-511.5 81.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-525.8\">convolution2d_8 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 140204253183784&#45;&gt;140204255246656 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140204253183784-&gt;140204255246656</title>\n",
       "<path d=\"M209.5,-584.313C209.5,-576.289 209.5,-566.547 209.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-557.529 209.5,-547.529 206,-557.529 213,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204291825904 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140204291825904</title>\n",
       "<polygon fill=\"none\" points=\"83,-438.5 83,-474.5 336,-474.5 336,-438.5 83,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-452.8\">maxpooling2d_8 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 140204255246656&#45;&gt;140204291825904 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140204255246656-&gt;140204291825904</title>\n",
       "<path d=\"M209.5,-511.313C209.5,-503.289 209.5,-493.547 209.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-484.529 209.5,-474.529 206,-484.529 213,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204291828648 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140204291828648</title>\n",
       "<polygon fill=\"none\" points=\"136.5,-365.5 136.5,-401.5 282.5,-401.5 282.5,-365.5 136.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-379.8\">flatten_6 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140204291825904&#45;&gt;140204291828648 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140204291825904-&gt;140204291828648</title>\n",
       "<path d=\"M209.5,-438.313C209.5,-430.289 209.5,-420.547 209.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-411.529 209.5,-401.529 206,-411.529 213,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204291828872 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140204291828872</title>\n",
       "<polygon fill=\"none\" points=\"142.5,-292.5 142.5,-328.5 276.5,-328.5 276.5,-292.5 142.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-306.8\">dense_8 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140204291828648&#45;&gt;140204291828872 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140204291828648-&gt;140204291828872</title>\n",
       "<path d=\"M209.5,-365.313C209.5,-357.289 209.5,-347.547 209.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-338.529 209.5,-328.529 206,-338.529 213,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204291829656 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140204291829656</title>\n",
       "<polygon fill=\"none\" points=\"113,-219.5 113,-255.5 306,-255.5 306,-219.5 113,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-233.8\">activation_6 (Activation)</text>\n",
       "</g>\n",
       "<!-- 140204291828872&#45;&gt;140204291829656 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140204291828872-&gt;140204291829656</title>\n",
       "<path d=\"M209.5,-292.313C209.5,-284.289 209.5,-274.547 209.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-265.529 209.5,-255.529 206,-265.529 213,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204291827024 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140204291827024</title>\n",
       "<polygon fill=\"none\" points=\"128,-146.5 128,-182.5 291,-182.5 291,-146.5 128,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-160.8\">dropout_1 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140204291829656&#45;&gt;140204291827024 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140204291829656-&gt;140204291827024</title>\n",
       "<path d=\"M209.5,-219.313C209.5,-211.289 209.5,-201.547 209.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-192.529 209.5,-182.529 206,-192.529 213,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204254970656 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140204254970656</title>\n",
       "<polygon fill=\"none\" points=\"142.5,-73.5 142.5,-109.5 276.5,-109.5 276.5,-73.5 142.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-87.8\">dense_9 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140204291827024&#45;&gt;140204254970656 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140204291827024-&gt;140204254970656</title>\n",
       "<path d=\"M209.5,-146.313C209.5,-138.289 209.5,-128.547 209.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-119.529 209.5,-109.529 206,-119.529 213,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140204253746344 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140204253746344</title>\n",
       "<polygon fill=\"none\" points=\"113,-0.5 113,-36.5 306,-36.5 306,-0.5 113,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-14.8\">activation_7 (Activation)</text>\n",
       "</g>\n",
       "<!-- 140204254970656&#45;&gt;140204253746344 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140204254970656-&gt;140204253746344</title>\n",
       "<path d=\"M209.5,-73.3129C209.5,-65.2895 209.5,-55.5475 209.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213,-46.5288 209.5,-36.5288 206,-46.5289 213,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_y[0]))\n",
    "train_y_model = np_utils.to_categorical(train_y, nb_classes)\n",
    "dev_y_model = np_utils.to_categorical(dev_y, nb_classes)\n",
    "train_X_model = sequence.pad_sequences(train_X, maxlen=max_len)\n",
    "dev_X_model = sequence.pad_sequences(dev_X, maxlen=max_len)\n",
    "train_sentiment_X_model = sequence.pad_sequences(train_sentiment_X,maxlen=max_len)\n",
    "train_tag_X_model= sequence.pad_sequences(train_tag_X,maxlen=max_len)\n",
    "dev_sentiment_X_model = sequence.pad_sequences(dev_sentiment_X,maxlen=max_len)\n",
    "dev_tag_X_model = sequence.pad_sequences(dev_tag_X,maxlen=max_len)\n",
    "#train_embedding_X_model = batch_indexData_embedding(X=train_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = batch_indexData_embedding(X=dev_X_model,index_wordembedding=index_wordembedding)\n",
    "dev_embedding_X_model = np.array(dev_embedding_X_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#转为index \n",
    "def to_index(word_index={},data=[]):\n",
    "    return [[word_index[w] if w in word_index else 0  for w in sentence] for sentence in data]\n",
    "test_index_X = to_index(word_index,test_X)\n",
    "test_sentiment_X = to_index(word_index,test_sentiment_X)\n",
    "test_tag_X = to_index(word_index,test_tag_X)\n",
    "#删补\n",
    "test_index_X_model = sequence.pad_sequences(test_index_X, maxlen=max_len)\n",
    "test_sentiment_X_model = sequence.pad_sequences(test_sentiment_X, maxlen=max_len)\n",
    "test_tag_X_model = sequence.pad_sequences(test_tag_X, maxlen=max_len)\n",
    "#embedding\n",
    "test_embedding_X = batch_indexData_embedding(X=test_index_X,index_wordembedding=index_wordembedding)\n",
    "test_y_model = np_utils.to_categorical(test_y, nb_classes)\n",
    "## test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_generator4(X1=None,X2=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = X2[i*batch_size:(i+1)*batch_size]\n",
    "        #x3_batch = X3[i*batch_size:(i+1)*batch_size]\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch],y_batch)\n",
    "        i = i + 1\n",
    "def my_generator3(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x2_batch = batch_indexData_embedding(X=x1_batch,index_wordembedding=index_wordembedding)\n",
    "        x2_batch = np.array(x2_batch)\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield ([x1_batch,x2_batch],y_batch)\n",
    "        i = i + 1\n",
    "def my_generator1(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x1_batch,y_batch)\n",
    "        i = i + 1\n",
    "def my_generator2(X1=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X1)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        x1_batch = X1[i*batch_size:(i+1)*batch_size]\n",
    "        x1_batch = batch_indexData_embedding(X=x1_batch,index_wordembedding=index_wordembedding)\n",
    "        x1_batch = np.array(x1_batch)\n",
    "       \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x1_batch,y_batch)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn random 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5767 - acc: 0.2703 - val_loss: 1.5712 - val_acc: 0.2525\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5596 - acc: 0.2778 - val_loss: 1.5728 - val_acc: 0.2598\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5658 - acc: 0.2894 - val_loss: 1.5655 - val_acc: 0.3061\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5466 - acc: 0.2975 - val_loss: 1.5611 - val_acc: 0.3025\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5434 - acc: 0.3028 - val_loss: 1.5446 - val_acc: 0.3052\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5209 - acc: 0.3100 - val_loss: 1.5319 - val_acc: 0.3252\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.5031 - acc: 0.3316 - val_loss: 1.5104 - val_acc: 0.3442\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.4846 - acc: 0.3466 - val_loss: 1.4928 - val_acc: 0.3415\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.4453 - acc: 0.3744 - val_loss: 1.4612 - val_acc: 0.3597\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.4050 - acc: 0.3887 - val_loss: 1.4622 - val_acc: 0.3470\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.3714 - acc: 0.4122 - val_loss: 1.4054 - val_acc: 0.3787\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.3243 - acc: 0.4419 - val_loss: 1.3851 - val_acc: 0.3896\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.2690 - acc: 0.4550 - val_loss: 1.3682 - val_acc: 0.3960\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.2332 - acc: 0.4875 - val_loss: 1.3567 - val_acc: 0.4069\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.1868 - acc: 0.4997 - val_loss: 1.3515 - val_acc: 0.3969\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.1480 - acc: 0.5141 - val_loss: 1.3631 - val_acc: 0.4015\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.0822 - acc: 0.5591 - val_loss: 1.3894 - val_acc: 0.3851\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.0563 - acc: 0.5625 - val_loss: 1.3679 - val_acc: 0.4105\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 141s - loss: 1.0052 - acc: 0.6003 - val_loss: 1.3666 - val_acc: 0.4060\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.9510 - acc: 0.6266 - val_loss: 1.3650 - val_acc: 0.4051\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.9126 - acc: 0.6431 - val_loss: 1.3916 - val_acc: 0.3942\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.8600 - acc: 0.6825 - val_loss: 1.3978 - val_acc: 0.4169\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.8188 - acc: 0.6981 - val_loss: 1.4001 - val_acc: 0.4142\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.7773 - acc: 0.7191 - val_loss: 1.4086 - val_acc: 0.4033\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.7109 - acc: 0.7609 - val_loss: 1.4367 - val_acc: 0.3806\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.6782 - acc: 0.7694 - val_loss: 1.4602 - val_acc: 0.4051\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.6215 - acc: 0.8016 - val_loss: 1.4900 - val_acc: 0.3760\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.5772 - acc: 0.8241 - val_loss: 1.5510 - val_acc: 0.3951\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 141s - loss: 0.5304 - acc: 0.8406 - val_loss: 1.5368 - val_acc: 0.3942\n",
      "Epoch 30/100\n",
      "2950/3200 [==========================>...] - ETA: 9s - loss: 0.4810 - acc: 0.8664 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1deed1343cda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_generator1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1444\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(my_generator1(train_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=(dev_X_model,dev_y_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn random 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4169|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-61f82b86c3dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_generator4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sentiment_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_embedding_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_sentiment_X_model\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1388\u001b[0m                                 \u001b[1;34m'(val_x, val_y, val_sample_weight) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m                                 'or (val_x, val_y). Found: ' + str(validation_data))\n\u001b[1;32m-> 1390\u001b[1;33m             \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1391\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[0;32m    959\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m                                    exception_prefix='model input')\n\u001b[0m\u001b[0;32m    962\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[0;32m    963\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.fit_generator(my_generator4(train_X_model,train_sentiment_X_model,train_y_model),samples_per_epoch = 32*100,nb_epoch=100,verbose=1,validation_data=([test_embedding_X,test_sentiment_X_model],test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn static 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4253|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn non-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.6160 - acc: 0.2560 - val_loss: 1.5496 - val_acc: 0.3081\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.5724 - acc: 0.2760 - val_loss: 1.5286 - val_acc: 0.3308\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.5372 - acc: 0.3175 - val_loss: 1.5180 - val_acc: 0.3290\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.5177 - acc: 0.3265 - val_loss: 1.4710 - val_acc: 0.3719\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4547 - acc: 0.3760 - val_loss: 1.4388 - val_acc: 0.3661\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4269 - acc: 0.3660 - val_loss: 1.4374 - val_acc: 0.3665\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4063 - acc: 0.3870 - val_loss: 1.3889 - val_acc: 0.3977\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.4010 - acc: 0.3950 - val_loss: 1.3765 - val_acc: 0.3950\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3477 - acc: 0.4130 - val_loss: 1.3484 - val_acc: 0.4041\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3121 - acc: 0.4275 - val_loss: 1.3391 - val_acc: 0.4068\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3002 - acc: 0.4345 - val_loss: 1.3507 - val_acc: 0.3977\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.3089 - acc: 0.4450 - val_loss: 1.4051 - val_acc: 0.3805\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2846 - acc: 0.4400 - val_loss: 1.3321 - val_acc: 0.4118\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2232 - acc: 0.4680 - val_loss: 1.3185 - val_acc: 0.4172\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2368 - acc: 0.4765 - val_loss: 1.3243 - val_acc: 0.4158\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2328 - acc: 0.4780 - val_loss: 1.3783 - val_acc: 0.3855\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.2029 - acc: 0.4845 - val_loss: 1.3194 - val_acc: 0.3991\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1488 - acc: 0.5125 - val_loss: 1.3011 - val_acc: 0.4276\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1566 - acc: 0.5080 - val_loss: 1.2884 - val_acc: 0.4357\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1235 - acc: 0.5365 - val_loss: 1.3692 - val_acc: 0.3905\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.1291 - acc: 0.5290 - val_loss: 1.3522 - val_acc: 0.3932\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0810 - acc: 0.5560 - val_loss: 1.3144 - val_acc: 0.4276\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0517 - acc: 0.5695 - val_loss: 1.3446 - val_acc: 0.3778\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0346 - acc: 0.5720 - val_loss: 1.3070 - val_acc: 0.4226\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 6s - loss: 1.0425 - acc: 0.5700 - val_loss: 1.3134 - val_acc: 0.4190\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9791 - acc: 0.6095 - val_loss: 1.3013 - val_acc: 0.4339\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9489 - acc: 0.6155 - val_loss: 1.3093 - val_acc: 0.4222\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9355 - acc: 0.6250 - val_loss: 1.3139 - val_acc: 0.4154\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.9361 - acc: 0.6315 - val_loss: 1.3453 - val_acc: 0.4113\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8961 - acc: 0.6515 - val_loss: 1.3303 - val_acc: 0.4412\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8399 - acc: 0.6670 - val_loss: 1.3601 - val_acc: 0.4072\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8414 - acc: 0.6825 - val_loss: 1.3738 - val_acc: 0.3991\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.8132 - acc: 0.6940 - val_loss: 1.4456 - val_acc: 0.3910\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7940 - acc: 0.6985 - val_loss: 1.3834 - val_acc: 0.3959\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7563 - acc: 0.7185 - val_loss: 1.3462 - val_acc: 0.4276\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7444 - acc: 0.7340 - val_loss: 1.3610 - val_acc: 0.4385\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.7078 - acc: 0.7430 - val_loss: 1.6853 - val_acc: 0.3593\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6917 - acc: 0.7475 - val_loss: 1.4416 - val_acc: 0.4081\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6626 - acc: 0.7585 - val_loss: 1.4033 - val_acc: 0.3977\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6496 - acc: 0.7735 - val_loss: 1.4453 - val_acc: 0.3864\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5906 - acc: 0.7945 - val_loss: 1.4176 - val_acc: 0.4186\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.6232 - acc: 0.7830 - val_loss: 1.4290 - val_acc: 0.4045\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5554 - acc: 0.8055 - val_loss: 1.4497 - val_acc: 0.4330\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5190 - acc: 0.8340 - val_loss: 1.5117 - val_acc: 0.4131\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5182 - acc: 0.8345 - val_loss: 1.5194 - val_acc: 0.3955\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.5071 - acc: 0.8355 - val_loss: 1.5069 - val_acc: 0.4118\n",
      "Epoch 47/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4760 - acc: 0.8475 - val_loss: 1.4981 - val_acc: 0.4244\n",
      "Epoch 48/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4436 - acc: 0.8605 - val_loss: 1.5615 - val_acc: 0.4054\n",
      "Epoch 49/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4344 - acc: 0.8650 - val_loss: 1.5817 - val_acc: 0.3946\n",
      "Epoch 50/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3917 - acc: 0.8830 - val_loss: 1.6029 - val_acc: 0.3946\n",
      "Epoch 51/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.4021 - acc: 0.8930 - val_loss: 1.6452 - val_acc: 0.3946\n",
      "Epoch 52/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3534 - acc: 0.9035 - val_loss: 1.5586 - val_acc: 0.4167\n",
      "Epoch 53/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3576 - acc: 0.9025 - val_loss: 1.5914 - val_acc: 0.4204\n",
      "Epoch 54/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3269 - acc: 0.9115 - val_loss: 1.7235 - val_acc: 0.3950\n",
      "Epoch 55/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.3380 - acc: 0.9020 - val_loss: 1.6489 - val_acc: 0.4109\n",
      "Epoch 56/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2863 - acc: 0.9190 - val_loss: 1.6465 - val_acc: 0.4072\n",
      "Epoch 57/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2889 - acc: 0.9130 - val_loss: 1.6938 - val_acc: 0.3964\n",
      "Epoch 58/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2614 - acc: 0.9335 - val_loss: 1.7725 - val_acc: 0.3977\n",
      "Epoch 59/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2846 - acc: 0.9225 - val_loss: 1.7438 - val_acc: 0.3995\n",
      "Epoch 60/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2358 - acc: 0.9485 - val_loss: 1.7186 - val_acc: 0.4050\n",
      "Epoch 61/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2206 - acc: 0.9475 - val_loss: 2.1195 - val_acc: 0.3593\n",
      "Epoch 62/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2217 - acc: 0.9430 - val_loss: 1.7741 - val_acc: 0.4068\n",
      "Epoch 63/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.2107 - acc: 0.9430 - val_loss: 1.8059 - val_acc: 0.4032\n",
      "Epoch 64/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1926 - acc: 0.9600 - val_loss: 1.8838 - val_acc: 0.4009\n",
      "Epoch 65/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1781 - acc: 0.9605 - val_loss: 1.9377 - val_acc: 0.3959\n",
      "Epoch 66/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1674 - acc: 0.9650 - val_loss: 1.9232 - val_acc: 0.3991\n",
      "Epoch 67/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1565 - acc: 0.9675 - val_loss: 2.1491 - val_acc: 0.3842\n",
      "Epoch 68/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1583 - acc: 0.9645 - val_loss: 2.1257 - val_acc: 0.3688\n",
      "Epoch 69/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1532 - acc: 0.9650 - val_loss: 2.1459 - val_acc: 0.4154\n",
      "Epoch 70/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1440 - acc: 0.9690 - val_loss: 1.9177 - val_acc: 0.4036\n",
      "Epoch 71/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1255 - acc: 0.9750 - val_loss: 2.0047 - val_acc: 0.4068\n",
      "Epoch 72/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1297 - acc: 0.9725 - val_loss: 2.0971 - val_acc: 0.3937\n",
      "Epoch 73/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1192 - acc: 0.9760 - val_loss: 2.0166 - val_acc: 0.3932\n",
      "Epoch 74/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1268 - acc: 0.9695 - val_loss: 2.0828 - val_acc: 0.3977\n",
      "Epoch 75/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1052 - acc: 0.9825 - val_loss: 2.1015 - val_acc: 0.4014\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.1085 - acc: 0.9775 - val_loss: 2.2390 - val_acc: 0.3932\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0996 - acc: 0.9815 - val_loss: 2.0726 - val_acc: 0.3986\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0927 - acc: 0.9820 - val_loss: 2.1191 - val_acc: 0.4032\n",
      "Epoch 79/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0817 - acc: 0.9875 - val_loss: 2.1503 - val_acc: 0.4018\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0895 - acc: 0.9845 - val_loss: 2.1610 - val_acc: 0.4122\n",
      "Epoch 81/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0846 - acc: 0.9855 - val_loss: 2.3335 - val_acc: 0.3932\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0747 - acc: 0.9865 - val_loss: 2.2409 - val_acc: 0.3914\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0667 - acc: 0.9925 - val_loss: 2.2677 - val_acc: 0.4104\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0714 - acc: 0.9865 - val_loss: 2.4675 - val_acc: 0.3896\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0651 - acc: 0.9860 - val_loss: 2.3052 - val_acc: 0.3846\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0599 - acc: 0.9890 - val_loss: 2.2864 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0562 - acc: 0.9920 - val_loss: 2.2703 - val_acc: 0.4059\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0468 - acc: 0.9945 - val_loss: 2.3956 - val_acc: 0.4050\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0521 - acc: 0.9930 - val_loss: 2.3708 - val_acc: 0.3986\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0805 - acc: 0.9800 - val_loss: 2.4118 - val_acc: 0.3900\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0504 - acc: 0.9930 - val_loss: 2.3752 - val_acc: 0.4054\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0477 - acc: 0.9925 - val_loss: 2.3969 - val_acc: 0.3973\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0460 - acc: 0.9945 - val_loss: 2.4448 - val_acc: 0.3964\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0424 - acc: 0.9920 - val_loss: 2.4089 - val_acc: 0.4005\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0437 - acc: 0.9950 - val_loss: 2.5242 - val_acc: 0.3914\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0343 - acc: 0.9955 - val_loss: 2.4625 - val_acc: 0.3923\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0382 - acc: 0.9950 - val_loss: 2.5792 - val_acc: 0.3928\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0358 - acc: 0.9960 - val_loss: 2.5178 - val_acc: 0.3923\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0437 - acc: 0.9920 - val_loss: 2.5288 - val_acc: 0.4036\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 6s - loss: 0.0300 - acc: 0.9960 - val_loss: 2.6317 - val_acc: 0.4009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb173847898>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator1(train_X_model,train_y_model),samples_per_epoch = 50*40,nb_epoch=100,verbose=1,validation_data=(test_index_X,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### cnn non-static 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4204|\n",
    "| 2016-11-26 9：52  |36          |50        | 14526       |   100      |  各100    |     3,4,5    |      300   | 0.4471|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### cnn multi channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5809 - acc: 0.2670 - val_loss: 1.5863 - val_acc: 0.2543\n",
      "Epoch 2/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5634 - acc: 0.2723 - val_loss: 1.5813 - val_acc: 0.2810\n",
      "Epoch 3/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5712 - acc: 0.2757 - val_loss: 1.5766 - val_acc: 0.2403\n",
      "Epoch 4/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5626 - acc: 0.2830 - val_loss: 1.5723 - val_acc: 0.2778\n",
      "Epoch 5/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5479 - acc: 0.3023 - val_loss: 1.5658 - val_acc: 0.2679\n",
      "Epoch 6/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5450 - acc: 0.3017 - val_loss: 1.5432 - val_acc: 0.2937\n",
      "Epoch 7/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5269 - acc: 0.3057 - val_loss: 1.5423 - val_acc: 0.3014\n",
      "Epoch 8/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5254 - acc: 0.3123 - val_loss: 1.5346 - val_acc: 0.2959\n",
      "Epoch 9/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5108 - acc: 0.3217 - val_loss: 1.5250 - val_acc: 0.3086\n",
      "Epoch 10/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4856 - acc: 0.3260 - val_loss: 1.5139 - val_acc: 0.3131\n",
      "Epoch 11/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4809 - acc: 0.3370 - val_loss: 1.4903 - val_acc: 0.3353\n",
      "Epoch 12/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4517 - acc: 0.3547 - val_loss: 1.4780 - val_acc: 0.3425\n",
      "Epoch 13/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4236 - acc: 0.3643 - val_loss: 1.4740 - val_acc: 0.3398\n",
      "Epoch 14/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4067 - acc: 0.3717 - val_loss: 1.4450 - val_acc: 0.3624\n",
      "Epoch 15/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.3738 - acc: 0.3980 - val_loss: 1.4323 - val_acc: 0.3615\n",
      "Epoch 16/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.3499 - acc: 0.4110 - val_loss: 1.4127 - val_acc: 0.3733\n",
      "Epoch 17/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.3201 - acc: 0.4197 - val_loss: 1.4033 - val_acc: 0.3724\n",
      "Epoch 18/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.2828 - acc: 0.4443 - val_loss: 1.4151 - val_acc: 0.3729\n",
      "Epoch 19/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.2619 - acc: 0.4520 - val_loss: 1.4401 - val_acc: 0.3633\n",
      "Epoch 20/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.2398 - acc: 0.4713 - val_loss: 1.3861 - val_acc: 0.3851\n",
      "Epoch 21/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1922 - acc: 0.4790 - val_loss: 1.3861 - val_acc: 0.3891\n",
      "Epoch 22/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1700 - acc: 0.5003 - val_loss: 1.4523 - val_acc: 0.3706\n",
      "Epoch 23/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1537 - acc: 0.5110 - val_loss: 1.3938 - val_acc: 0.3769\n",
      "Epoch 24/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1082 - acc: 0.5280 - val_loss: 1.3691 - val_acc: 0.4014\n",
      "Epoch 25/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.0652 - acc: 0.5553 - val_loss: 1.3972 - val_acc: 0.3891\n",
      "Epoch 26/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.0700 - acc: 0.5567 - val_loss: 1.4080 - val_acc: 0.3860\n",
      "Epoch 27/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.0180 - acc: 0.5767 - val_loss: 1.4107 - val_acc: 0.3950\n",
      "Epoch 28/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9852 - acc: 0.6020 - val_loss: 1.4587 - val_acc: 0.3706\n",
      "Epoch 29/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9885 - acc: 0.5967 - val_loss: 1.4448 - val_acc: 0.3701\n",
      "Epoch 30/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9335 - acc: 0.6237 - val_loss: 1.4329 - val_acc: 0.3796\n",
      "Epoch 31/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9051 - acc: 0.6473 - val_loss: 1.4901 - val_acc: 0.3701\n",
      "Epoch 32/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8958 - acc: 0.6467 - val_loss: 1.4904 - val_acc: 0.3683\n",
      "Epoch 33/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8553 - acc: 0.6647 - val_loss: 1.4578 - val_acc: 0.3810\n",
      "Epoch 34/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8188 - acc: 0.6907 - val_loss: 1.4865 - val_acc: 0.3765\n",
      "Epoch 35/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8025 - acc: 0.6997 - val_loss: 1.5505 - val_acc: 0.3697\n",
      "Epoch 36/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.7622 - acc: 0.7220 - val_loss: 1.7344 - val_acc: 0.3679\n",
      "Epoch 37/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.7570 - acc: 0.7240 - val_loss: 1.5424 - val_acc: 0.3941\n",
      "Epoch 38/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.7037 - acc: 0.7510 - val_loss: 1.5881 - val_acc: 0.3910\n",
      "Epoch 39/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.6777 - acc: 0.7660 - val_loss: 1.8024 - val_acc: 0.3629\n",
      "Epoch 40/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.6691 - acc: 0.7707 - val_loss: 1.5808 - val_acc: 0.4027\n",
      "Epoch 41/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.6181 - acc: 0.7870 - val_loss: 1.6031 - val_acc: 0.3792\n",
      "Epoch 42/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5873 - acc: 0.8153 - val_loss: 1.6342 - val_acc: 0.3937\n",
      "Epoch 43/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5847 - acc: 0.8087 - val_loss: 1.6747 - val_acc: 0.3760\n",
      "Epoch 44/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5412 - acc: 0.8180 - val_loss: 1.7842 - val_acc: 0.3814\n",
      "Epoch 45/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5126 - acc: 0.8457 - val_loss: 1.8411 - val_acc: 0.3638\n",
      "Epoch 46/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5058 - acc: 0.8413 - val_loss: 1.9362 - val_acc: 0.3765\n",
      "Epoch 47/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4675 - acc: 0.8520 - val_loss: 1.8512 - val_acc: 0.3864\n",
      "Epoch 48/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4383 - acc: 0.8707 - val_loss: 1.8713 - val_acc: 0.3878\n",
      "Epoch 49/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4326 - acc: 0.8657 - val_loss: 1.9295 - val_acc: 0.3688\n",
      "Epoch 50/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4081 - acc: 0.8797 - val_loss: 1.9451 - val_acc: 0.3747\n",
      "Epoch 51/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3681 - acc: 0.8950 - val_loss: 1.9361 - val_acc: 0.3774\n",
      "Epoch 52/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3692 - acc: 0.8870 - val_loss: 2.1534 - val_acc: 0.3579\n",
      "Epoch 53/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3346 - acc: 0.9127 - val_loss: 2.0377 - val_acc: 0.4009\n",
      "Epoch 54/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3429 - acc: 0.9003 - val_loss: 2.1486 - val_acc: 0.3855\n",
      "Epoch 55/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2920 - acc: 0.9193 - val_loss: 2.1104 - val_acc: 0.3828\n",
      "Epoch 56/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2941 - acc: 0.9177 - val_loss: 2.2114 - val_acc: 0.3787\n",
      "Epoch 57/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2736 - acc: 0.9310 - val_loss: 2.1201 - val_acc: 0.3973\n",
      "Epoch 58/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2353 - acc: 0.9367 - val_loss: 2.1464 - val_acc: 0.3796\n",
      "Epoch 59/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2455 - acc: 0.9357 - val_loss: 2.2175 - val_acc: 0.3896\n",
      "Epoch 60/100\n",
      "2450/3000 [=======================>......] - ETA: 1s - loss: 0.2415 - acc: 0.9343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-98ee3ced15c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model.fit_generator(my_generator1(train_X_model,train_y_model),samples_per_epoch = 50*60,nb_epoch=100,verbose=1,validation_data=([test_index_X_model],test_y))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_generator4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sentiment_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_sentiment_X_model\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1444\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit_generator(my_generator1(train_X_model,train_y_model),samples_per_epoch = 50*60,nb_epoch=100,verbose=1,validation_data=([test_index_X_model],test_y))\n",
    "model.fit_generator(my_generator4(train_X_model,train_sentiment_X_model,train_y_model),samples_per_epoch = 50*60,nb_epoch=100,verbose=1,validation_data=([test_index_X_model,test_sentiment_X_model],test_y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5808 - acc: 0.2617 - val_loss: 1.5856 - val_acc: 0.2308\n",
      "Epoch 2/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5660 - acc: 0.2707 - val_loss: 1.5809 - val_acc: 0.2385\n",
      "Epoch 3/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5716 - acc: 0.2680 - val_loss: 1.5759 - val_acc: 0.2498\n",
      "Epoch 4/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.5642 - acc: 0.2770 - val_loss: 1.5733 - val_acc: 0.2914\n",
      "Epoch 5/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.5515 - acc: 0.2980 - val_loss: 1.5679 - val_acc: 0.2543\n",
      "Epoch 6/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.5559 - acc: 0.2863 - val_loss: 1.5511 - val_acc: 0.3036\n",
      "Epoch 7/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5383 - acc: 0.3000 - val_loss: 1.5521 - val_acc: 0.2923\n",
      "Epoch 8/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.5407 - acc: 0.3050 - val_loss: 1.5447 - val_acc: 0.2941\n",
      "Epoch 9/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5275 - acc: 0.3093 - val_loss: 1.5386 - val_acc: 0.3027\n",
      "Epoch 10/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.5127 - acc: 0.3197 - val_loss: 1.5382 - val_acc: 0.3045\n",
      "Epoch 11/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.5177 - acc: 0.3153 - val_loss: 1.5168 - val_acc: 0.3357\n",
      "Epoch 12/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.4885 - acc: 0.3333 - val_loss: 1.5093 - val_acc: 0.3235\n",
      "Epoch 13/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4768 - acc: 0.3373 - val_loss: 1.5012 - val_acc: 0.3317\n",
      "Epoch 14/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4670 - acc: 0.3447 - val_loss: 1.4751 - val_acc: 0.3548\n",
      "Epoch 15/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4379 - acc: 0.3570 - val_loss: 1.4641 - val_acc: 0.3538\n",
      "Epoch 16/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.4294 - acc: 0.3773 - val_loss: 1.4524 - val_acc: 0.3566\n",
      "Epoch 17/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.4060 - acc: 0.3840 - val_loss: 1.4381 - val_acc: 0.3706\n",
      "Epoch 18/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.3718 - acc: 0.3973 - val_loss: 1.4337 - val_acc: 0.3674\n",
      "Epoch 19/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.3622 - acc: 0.4133 - val_loss: 1.4263 - val_acc: 0.3692\n",
      "Epoch 20/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.3357 - acc: 0.4217 - val_loss: 1.4084 - val_acc: 0.3873\n",
      "Epoch 21/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.2927 - acc: 0.4450 - val_loss: 1.4142 - val_acc: 0.3846\n",
      "Epoch 22/100\n",
      "3000/3000 [==============================] - 11s - loss: 1.2795 - acc: 0.4503 - val_loss: 1.4295 - val_acc: 0.3679\n",
      "Epoch 23/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.2530 - acc: 0.4510 - val_loss: 1.3790 - val_acc: 0.3910\n",
      "Epoch 24/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.2111 - acc: 0.4807 - val_loss: 1.3860 - val_acc: 0.3905\n",
      "Epoch 25/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1879 - acc: 0.5017 - val_loss: 1.4048 - val_acc: 0.3846\n",
      "Epoch 26/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1748 - acc: 0.5030 - val_loss: 1.3808 - val_acc: 0.3833\n",
      "Epoch 27/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1290 - acc: 0.5237 - val_loss: 1.3819 - val_acc: 0.3887\n",
      "Epoch 28/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.1075 - acc: 0.5333 - val_loss: 1.3913 - val_acc: 0.3905\n",
      "Epoch 29/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.0896 - acc: 0.5520 - val_loss: 1.4044 - val_acc: 0.3778\n",
      "Epoch 30/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.0444 - acc: 0.5687 - val_loss: 1.3923 - val_acc: 0.3896\n",
      "Epoch 31/100\n",
      "3000/3000 [==============================] - 12s - loss: 1.0212 - acc: 0.5820 - val_loss: 1.4454 - val_acc: 0.3796\n",
      "Epoch 32/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9883 - acc: 0.6007 - val_loss: 1.4228 - val_acc: 0.3814\n",
      "Epoch 33/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9641 - acc: 0.6087 - val_loss: 1.4163 - val_acc: 0.3828\n",
      "Epoch 34/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.9417 - acc: 0.6207 - val_loss: 1.4296 - val_acc: 0.3950\n",
      "Epoch 35/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8906 - acc: 0.6527 - val_loss: 1.4849 - val_acc: 0.3774\n",
      "Epoch 36/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8833 - acc: 0.6603 - val_loss: 1.5448 - val_acc: 0.3842\n",
      "Epoch 37/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.8586 - acc: 0.6543 - val_loss: 1.4586 - val_acc: 0.3900\n",
      "Epoch 38/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.7982 - acc: 0.6930 - val_loss: 1.4824 - val_acc: 0.3869\n",
      "Epoch 39/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.7928 - acc: 0.6937 - val_loss: 1.6494 - val_acc: 0.3701\n",
      "Epoch 40/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.7692 - acc: 0.7063 - val_loss: 1.5044 - val_acc: 0.3914\n",
      "Epoch 41/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.7053 - acc: 0.7457 - val_loss: 1.5163 - val_acc: 0.3968\n",
      "Epoch 42/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.7014 - acc: 0.7380 - val_loss: 1.5483 - val_acc: 0.3950\n",
      "Epoch 43/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.6851 - acc: 0.7547 - val_loss: 1.5599 - val_acc: 0.3964\n",
      "Epoch 44/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.6298 - acc: 0.7747 - val_loss: 1.6307 - val_acc: 0.3910\n",
      "Epoch 45/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.6295 - acc: 0.7750 - val_loss: 1.6479 - val_acc: 0.3824\n",
      "Epoch 46/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.5837 - acc: 0.7997 - val_loss: 1.6685 - val_acc: 0.3796\n",
      "Epoch 47/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5465 - acc: 0.8183 - val_loss: 1.6729 - val_acc: 0.3991\n",
      "Epoch 48/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5383 - acc: 0.8137 - val_loss: 1.7480 - val_acc: 0.3846\n",
      "Epoch 49/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.5012 - acc: 0.8360 - val_loss: 1.7473 - val_acc: 0.3887\n",
      "Epoch 50/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4755 - acc: 0.8447 - val_loss: 1.7811 - val_acc: 0.3864\n",
      "Epoch 51/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4566 - acc: 0.8543 - val_loss: 1.8558 - val_acc: 0.3783\n",
      "Epoch 52/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4269 - acc: 0.8693 - val_loss: 1.9441 - val_acc: 0.3611\n",
      "Epoch 53/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4110 - acc: 0.8747 - val_loss: 1.9773 - val_acc: 0.3833\n",
      "Epoch 54/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.4024 - acc: 0.8790 - val_loss: 1.9375 - val_acc: 0.3842\n",
      "Epoch 55/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3527 - acc: 0.8997 - val_loss: 1.9969 - val_acc: 0.3878\n",
      "Epoch 56/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3477 - acc: 0.9030 - val_loss: 2.1935 - val_acc: 0.3629\n",
      "Epoch 57/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.3411 - acc: 0.8990 - val_loss: 2.0178 - val_acc: 0.3873\n",
      "Epoch 58/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2965 - acc: 0.9153 - val_loss: 2.0325 - val_acc: 0.3882\n",
      "Epoch 59/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2930 - acc: 0.9153 - val_loss: 2.1025 - val_acc: 0.3946\n",
      "Epoch 60/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2847 - acc: 0.9130 - val_loss: 2.0940 - val_acc: 0.3900\n",
      "Epoch 61/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2455 - acc: 0.9333 - val_loss: 2.3232 - val_acc: 0.3923\n",
      "Epoch 62/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2466 - acc: 0.9333 - val_loss: 2.2609 - val_acc: 0.3701\n",
      "Epoch 63/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2380 - acc: 0.9330 - val_loss: 2.2277 - val_acc: 0.3805\n",
      "Epoch 64/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.2115 - acc: 0.9477 - val_loss: 2.2965 - val_acc: 0.3986\n",
      "Epoch 65/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1942 - acc: 0.9490 - val_loss: 2.4081 - val_acc: 0.3846\n",
      "Epoch 66/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1911 - acc: 0.9493 - val_loss: 2.4171 - val_acc: 0.3688\n",
      "Epoch 67/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1780 - acc: 0.9587 - val_loss: 2.3729 - val_acc: 0.3842\n",
      "Epoch 68/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1581 - acc: 0.9570 - val_loss: 2.4075 - val_acc: 0.3824\n",
      "Epoch 69/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1468 - acc: 0.9643 - val_loss: 2.6240 - val_acc: 0.3606\n",
      "Epoch 70/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1426 - acc: 0.9650 - val_loss: 2.5968 - val_acc: 0.3896\n",
      "Epoch 71/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1360 - acc: 0.9637 - val_loss: 2.5750 - val_acc: 0.3833\n",
      "Epoch 72/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1200 - acc: 0.9720 - val_loss: 2.5570 - val_acc: 0.3900\n",
      "Epoch 73/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1179 - acc: 0.9733 - val_loss: 2.8912 - val_acc: 0.3724\n",
      "Epoch 74/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1067 - acc: 0.9783 - val_loss: 2.7026 - val_acc: 0.3873\n",
      "Epoch 75/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.1024 - acc: 0.9753 - val_loss: 2.6732 - val_acc: 0.3882\n",
      "Epoch 76/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0970 - acc: 0.9797 - val_loss: 2.7345 - val_acc: 0.3968\n",
      "Epoch 77/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0884 - acc: 0.9807 - val_loss: 2.7557 - val_acc: 0.3869\n",
      "Epoch 78/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0788 - acc: 0.9843 - val_loss: 2.9346 - val_acc: 0.3882\n",
      "Epoch 79/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0766 - acc: 0.9840 - val_loss: 2.9802 - val_acc: 0.3597\n",
      "Epoch 80/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0715 - acc: 0.9833 - val_loss: 2.8763 - val_acc: 0.3869\n",
      "Epoch 81/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0667 - acc: 0.9867 - val_loss: 2.9861 - val_acc: 0.3842\n",
      "Epoch 82/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.0541 - acc: 0.9893 - val_loss: 3.1075 - val_acc: 0.3855\n",
      "Epoch 83/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0530 - acc: 0.9900 - val_loss: 3.2034 - val_acc: 0.3765\n",
      "Epoch 84/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0489 - acc: 0.9917 - val_loss: 3.1565 - val_acc: 0.3692\n",
      "Epoch 85/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0498 - acc: 0.9883 - val_loss: 3.1876 - val_acc: 0.3842\n",
      "Epoch 86/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.0441 - acc: 0.9940 - val_loss: 3.2941 - val_acc: 0.3584\n",
      "Epoch 87/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0417 - acc: 0.9940 - val_loss: 3.1707 - val_acc: 0.3882\n",
      "Epoch 88/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0355 - acc: 0.9960 - val_loss: 3.2243 - val_acc: 0.3937\n",
      "Epoch 89/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0319 - acc: 0.9950 - val_loss: 3.2820 - val_acc: 0.3878\n",
      "Epoch 90/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0341 - acc: 0.9937 - val_loss: 3.3671 - val_acc: 0.3851\n",
      "Epoch 91/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0301 - acc: 0.9953 - val_loss: 3.3733 - val_acc: 0.3860\n",
      "Epoch 92/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0256 - acc: 0.9960 - val_loss: 3.3862 - val_acc: 0.3833\n",
      "Epoch 93/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0274 - acc: 0.9947 - val_loss: 3.3751 - val_acc: 0.3937\n",
      "Epoch 94/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0247 - acc: 0.9977 - val_loss: 3.5068 - val_acc: 0.3710\n",
      "Epoch 95/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0201 - acc: 0.9980 - val_loss: 3.6658 - val_acc: 0.3941\n",
      "Epoch 96/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0182 - acc: 0.9987 - val_loss: 3.5511 - val_acc: 0.3783\n",
      "Epoch 97/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0229 - acc: 0.9963 - val_loss: 3.5324 - val_acc: 0.3900\n",
      "Epoch 98/100\n",
      "3000/3000 [==============================] - 11s - loss: 0.0153 - acc: 0.9993 - val_loss: 3.7088 - val_acc: 0.3769\n",
      "Epoch 99/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0180 - acc: 0.9980 - val_loss: 3.8426 - val_acc: 0.3878\n",
      "Epoch 100/100\n",
      "3000/3000 [==============================] - 12s - loss: 0.0138 - acc: 0.9983 - val_loss: 3.6927 - val_acc: 0.3814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83dab9d2e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(my_generator4(train_X_model,train_sentiment_X_model,train_y_model),samples_per_epoch = 50*60,nb_epoch=100,verbose=1,validation_data=([test_index_X_model,test_sentiment_X_model],test_y_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 实验结果 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -      |-         |-          |-          |-           |-       |-         | -          |-     | \n",
    "| word+sentiment  |36    |50         | 14526       |   100      |  各100(600)    |     3,4,5    |       300   | 0.4303|\n",
    "\n",
    "不加sentiment的结果:0.4285,0.4348,0.4348,0.4312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 两通道实验结果，一个是用训练好的词向量初始化句子，另一个是用随机初始化的词向量初始化句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|time            |max_len      | batch_size   |  max_features | embedding_dims | nb_filter | filter_length | dense1_hindden |val_acc |\n",
    "| -             |-          |-          |-          |-           |-       |-         | -          |-     | \n",
    "| 2016-11-25 9：52  |36          |32         | 14526       |   100      |  各100    |     3,4,5    |       300   | 0.4124|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
