{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 利用训练好的词向量构造句子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 630 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n",
      "/home/bruce/anaconda3/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from  os.path import join\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Lambda,Input,Merge,Flatten,Reshape,GlobalMaxPooling2D,MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D,Convolution2D,merge\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from keras.regularizers import l2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.constraints import maxnorm\n",
    "import pickle\n",
    "import re\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string, TREC=False):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip() if TREC else string.strip().lower()\n",
    "def clean_str_sst(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for the SST dataset\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)   \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X 的数量： 8544\n",
      "test_X 的数量： 2210\n",
      "[['a', 'stirring', ',', 'funny', 'and', 'finally', 'transporting', 're', 'imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'films'], ['apparently', 'reassembled', 'from', 'the', 'cutting', 'room', 'floor', 'of', 'any', 'given', 'daytime', 'soap']]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['stsa.fine.test','stsa.fine.train','stsa.fine.dev']\n",
    "file_path = '/home/bruce/data/sentiment/'\n",
    "def read_file(fname=''):\n",
    "    with open(join(file_path,fname)) as fr:\n",
    "        lines = fr.readlines()\n",
    "    lines = [clean_str(line) for line in lines]\n",
    "    lables = [int(line[0:1]) for line in lines]\n",
    "    words = [line[2:].split() for line in lines]\n",
    "    return words,lables       \n",
    "train_X,train_y = read_file(fname='stsa.fine.train')\n",
    "test_X,test_y = read_file(fname='stsa.fine.test')\n",
    "dev_X,dev_y = read_file(fname='stsa.fine.dev')\n",
    "print('train_X 的数量：',len(train_X))\n",
    "print('test_X 的数量：',len(test_X))\n",
    "#print('dev_X 的数量：',len(dev_X))\n",
    "print(train_X[0:2])\n",
    "print(train_y[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句子长度统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words :17836 / 17087\n",
      "length = 11855 /  10754\n",
      "max =  53\n",
      "min = 1\n",
      "average =  18.372884508090014\n",
      "top 50% =  18\n",
      "top 80% =  26\n",
      "top 90% =  31\n",
      "top 95% =  35\n"
     ]
    }
   ],
   "source": [
    "def statics_list2(arrays=[]):\n",
    "    lengths=[]\n",
    "    for array in arrays:\n",
    "        lengths=lengths+[len(i) for i in array]\n",
    "    wordset=set()\n",
    "    for data in arrays:\n",
    "        for sentence in data:\n",
    "            wordset.update(sentence)\n",
    "    print('total words :17836 /',len(wordset))\n",
    "    lengths = sorted(lengths)\n",
    "    length = len(lengths)\n",
    "    #google_dict(filename='/home/bruce/data/google_word2vec/google_word2vec_300.txt',wordset=wordset)\n",
    "    print('length = 11855 / ',len(lengths))\n",
    "    print('max = ',lengths[-1])\n",
    "    print('min =',lengths[0])\n",
    "    print('average = ',sum(lengths)/length)\n",
    "    \n",
    "    print('top 50% = ',lengths[int(0.5*length)])\n",
    "    print('top 80% = ',lengths[int(0.8*length)])\n",
    "    print('top 90% = ',lengths[int(0.9*length)])\n",
    "    print('top 95% = ',lengths[int(0.95*length)])\n",
    "    \n",
    "statics_list2(arrays=[train_X,test_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_to_index(datas=[]):\n",
    "    word_index={}\n",
    "    count=1\n",
    "    for data in datas:\n",
    "        for sentence in data:\n",
    "            for w in sentence:\n",
    "                if w not in word_index:\n",
    "                    word_index[w] = count\n",
    "                    count = count + 1\n",
    "    print('length of word_index =',len(word_index))\n",
    "    for i in range(len(datas)):\n",
    "        datas[i] = [[ word_index[w] for w in line ] for line in datas[i]] \n",
    "    return datas,word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word_index = 17833\n",
      "17833\n"
     ]
    }
   ],
   "source": [
    "X,word_index = token_to_index(datas=[train_X,test_X,dev_X])\n",
    "train_X,test_X,dev_X= X\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 5, 12, 13, 5, 14, 15, 16]\n",
      "['a', 'stirring', ',', 'funny', 'and', 'finally', 'transporting', 're', 'imagining', 'of', 'beauty', 'and', 'the', 'beast', 'and', '1930s', 'horror', 'films']\n",
      "['a', 'deliciously', 'nonsensical', 'comedy', 'about', 'a', 'city', 'coming', 'apart', 'at', 'its', 'seams']\n"
     ]
    }
   ],
   "source": [
    "##验证：\n",
    "print(train_X[0])\n",
    "## \n",
    "index_word = dict([(kv[1],kv[0])for kv in word_index.items()])\n",
    "sentence1 = [index_word[i] for i in train_X[0]]\n",
    "sentence2 = [index_word[i] for i in train_X[-1]]\n",
    "print(sentence1)\n",
    "print(sentence2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载训练好的Glove或者google词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using google embedding\n",
      "word_embedding size =  16262\n",
      "pretrained word number :16262 /  16262\n",
      "size of index_wordembedding =  17833\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = 'google'\n",
    "embedding_dim = 300\n",
    "#we_file = '/home/bruce/data/glove/twitter/glove.twitter.27B.{0}d.txt'.format(embedding_dim)\n",
    "glove_w2v = '/home/bruce/data/glove/CommonCrawl/sst5_word_embedding_glove_dict.pkl'\n",
    "google_w2v = '/home/bruce/data/google_word2vec/sst5_word_embedding_google_dict.pkl'\n",
    "\n",
    "def get_index_embedding(word_index={}):\n",
    "    count_in =0\n",
    "    index_embedding ={}\n",
    "    if word2vec_model == 'google':\n",
    "        print('using google embedding')\n",
    "        with open(google_w2v,'rb') as fr:\n",
    "            word_embedding = pickle.load(fr)\n",
    "    else:\n",
    "        print('using glove embedding')\n",
    "        with open(glove_w2v,'rb') as fr:\n",
    "            word_embedding = pickle.load(fr)\n",
    "    print('word_embedding size = ',len(word_embedding))\n",
    "    for word,index in word_index.items():\n",
    "        if word in word_embedding:\n",
    "            count_in = count_in + 1\n",
    "            index_embedding[index] = word_embedding[word]\n",
    "        else:\n",
    "            index_embedding[index] = np.random.uniform(-0.25,0.25,embedding_dim)\n",
    "    print('pretrained word number :16262 / ',count_in)\n",
    "    return index_embedding\n",
    "index_embedding = get_index_embedding(word_index=word_index)\n",
    "print('size of index_wordembedding = ',len(index_embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_trained_embedding(index_wordembedding=None):\n",
    "    index_we = sorted(index_wordembedding.items())\n",
    "    trained_embedding = [t[1] for t in index_we]\n",
    "    zeros = np.random.uniform(-0.25,0.25,embedding_dim)\n",
    "    #zeros = np.zeros(embedding_dim)\n",
    "    trained_embedding = np.vstack((zeros,trained_embedding))\n",
    "    return np.array(trained_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_len = 56\n",
    "batch_size=50\n",
    "\n",
    "max_features = 17833 + 1\n",
    "\n",
    "nb_filter = 100\n",
    "dense1_hindden = 300\n",
    "nb_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维卷积模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_embedding shape =  (17834, 300)\n",
      "embedding dim =  300\n",
      "dropout input shape =  (None, 300)\n",
      "dropout output shape =  (None, 300)\n",
      "dropout input shape (300,) =  (None, 300)\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "trained_embedding = get_trained_embedding(index_embedding)\n",
    "print('trained_embedding shape = ',trained_embedding.shape)\n",
    "embedding = Embedding(output_dim=embedding_dim,\n",
    "                      input_dim=max_features,\n",
    "                      weights=[trained_embedding]\n",
    "                     )(input)\n",
    "reshape = Reshape((1,max_len,embedding_dim))(embedding)\n",
    "print('embedding dim = ',embedding_dim)\n",
    "#卷积\n",
    "conv2d_1 = Convolution2D(nb_filter,3,embedding_dim,border_mode='valid',activation='relu')\n",
    "conv2d_2 = Convolution2D(nb_filter,4,embedding_dim,border_mode='valid',activation='relu')\n",
    "conv2d_3 = Convolution2D(nb_filter,5,embedding_dim,border_mode='valid',activation='relu')\n",
    "conv1 = conv2d_1(reshape)\n",
    "conv2 = conv2d_2(reshape)\n",
    "conv3 = conv2d_3(reshape)\n",
    "maxpooling1 = MaxPooling2D(pool_size=(54,1))\n",
    "maxpooling2 = MaxPooling2D(pool_size=(53,1))\n",
    "maxpooling3 = MaxPooling2D(pool_size=(52,1))\n",
    "\n",
    "pool1 = maxpooling1(conv1)\n",
    "pool2 = maxpooling2(conv2)\n",
    "pool3 = maxpooling3(conv3)\n",
    "\n",
    "flat1 = Flatten()(pool1)\n",
    "flat2 = Flatten()(pool2)\n",
    "flat3 = Flatten()(pool3)\n",
    "#print('maxpooling2 output shape = ',maxpooling2.output_shape)\n",
    "#print('maxpooling3 output shape = ',maxpooling3.output_shape)\n",
    "#merged_vector = merge([conv1,conv2,conv3], mode='concat')\n",
    "mergelayer = Merge(mode='concat')\n",
    "merged_vector = mergelayer([flat1,flat2,flat3])\n",
    "dropout = Dropout(0.5)\n",
    "drop_vector = dropout(merged_vector)\n",
    "print('dropout input shape = ',dropout.input_shape)\n",
    "print('dropout output shape = ',dropout.output_shape)\n",
    "\n",
    "#全连接\n",
    "output = Dense(nb_classes,activation='softmax',W_constraint = maxnorm(3))(drop_vector)\n",
    "#output = Dense(nb_classes,activation='softmax')(merged_vector)\n",
    "\n",
    "print('dropout input shape (300,) = ',dropout.input_shape)\n",
    "#softmax\n",
    "model = Model(input=input,output=output)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=7, verbose=1),\n",
    "    #ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode_in = Input(shape=(max_len,),dtype='int32')\n",
    "\n",
    "embedding = Embedding(output_dim=embedding_dim,\n",
    "                      input_dim=max_features,\n",
    "                      input_length = max_len\n",
    "                     )(mode_in)\n",
    "print('embedding dim = ',embedding_dim)\n",
    "#卷积\n",
    "conv_result=[]\n",
    "for i in range(3):\n",
    "    conv = Convolution1D(nb_filter,3+i,border_mode='same',activation='relu')(embedding)\n",
    "    pooling = GlobalMaxPooling1D()(conv)\n",
    "    conv_result.append(pooling)\n",
    "merge_layer = Merge(mode='concat')\n",
    "merge_out = merge_layer(conv_result)\n",
    "print('(None,{0}) = {1})'.format(3*nb_filter,merge_layer.output_shape))\n",
    "#Dropout\n",
    "merge_out = Dropout(0.5)(merge_out)\n",
    "    \n",
    "#softmax\n",
    "mode_out = Dense(nb_classes,activation='softmax',W_constraint = maxnorm(3))(merge_out)\n",
    "    \n",
    "#编译模型\n",
    "model = Model(input=mode_in,output=mode_out)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=7, verbose=1),\n",
    "    #ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## static模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_embedding shape =  (17834, 300)\n",
      "embedding dim =  300\n",
      "conv1d_3 input shape: (None,56,300)  = (None, 56, 300)\n",
      "conv1d_3 output shape: (None,56,100)  = (None, 56, 100)\n",
      "dropout input shape (None,300) =  (None, 300)\n"
     ]
    }
   ],
   "source": [
    "mode_in = Input(shape=(max_len,),dtype='int32')\n",
    "trained_embedding = get_trained_embedding(index_embedding)\n",
    "print('trained_embedding shape = ',trained_embedding.shape)\n",
    "embedding = Embedding(output_dim=embedding_dim,\n",
    "                      input_dim=max_features,\n",
    "                      input_length = max_len,\n",
    "                      weights=[trained_embedding],\n",
    "                      trainable=False\n",
    "                     )(mode_in)\n",
    "print('embedding dim = ',embedding_dim)\n",
    "#卷积\n",
    "conv_result=[]\n",
    "for i in range(3):\n",
    "    conv = Convolution1D(nb_filter,3+i,border_mode='same',activation='relu')(embedding)\n",
    "    pooling = GlobalMaxPooling1D()(conv)\n",
    "    conv_result.append(pooling)\n",
    "merge_layer = Merge(mode='concat')\n",
    "merge_out = merge_layer(conv_result)\n",
    "print('(None,{0}) = {1})'.format(3*nb_filter,merge_layer.output_shape))\n",
    "#Dropout\n",
    "merge_out = Dropout(0.5)(merge_out)\n",
    "    \n",
    "#softmax\n",
    "mode_out = Dense(nb_classes,activation='softmax',W_constraint = maxnorm(3))(merge_out)\n",
    "    \n",
    "#编译模型\n",
    "model = Model(input=mode_in,output=mode_out)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=7, verbose=1),\n",
    "    #ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non-static 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode_in = Input(shape=(max_len,),dtype='int32')\n",
    "trained_embedding = get_trained_embedding(index_embedding)\n",
    "print('trained_embedding shape = ',trained_embedding.shape)\n",
    "embedding = Embedding(output_dim=embedding_dim,\n",
    "                      input_dim=max_features,\n",
    "                      input_length = max_len,\n",
    "                      weights=[trained_embedding],\n",
    "                     )(mode_in)\n",
    "print('embedding dim = ',embedding_dim)\n",
    "#卷积\n",
    "conv_result=[]\n",
    "for i in range(3):\n",
    "    conv = Convolution1D(nb_filter,3+i,border_mode='same',activation='relu')(embedding)\n",
    "    pooling = GlobalMaxPooling1D()(conv)\n",
    "    conv_result.append(pooling)\n",
    "merge_layer = Merge(mode='concat')\n",
    "merge_out = merge_layer(conv_result)\n",
    "print('(None,{0}) = {1})'.format(3*nb_filter,merge_layer.output_shape))\n",
    "#Dropout\n",
    "merge_out = Dropout(0.5)(merge_out)\n",
    "    \n",
    "#softmax\n",
    "mode_out = Dense(nb_classes,activation='softmax',W_constraint = maxnorm(3))(merge_out)\n",
    "    \n",
    "#编译模型\n",
    "model = Model(input=mode_in,output=mode_out)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=7, verbose=1),\n",
    "    #ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多通道模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode_in = Input(shape=(max_len,),dtype='int32')\n",
    "trained_embedding = get_trained_embedding(index_embedding)\n",
    "print('trained_embedding shape = ',trained_embedding.shape)\n",
    "\n",
    "embedding_non_static = Embedding(output_dim=embedding_dim,\n",
    "                      input_dim=max_features,\n",
    "                      input_length = max_len,\n",
    "                      weights=[trained_embedding],\n",
    "                     )(mode_in)\n",
    "embedding_static = Embedding(output_dim=embedding_dim,\n",
    "                      input_dim=max_features,\n",
    "                      input_length = max_len,\n",
    "                      weights=[trained_embedding],\n",
    "                      trainable=False\n",
    "                     )(mode_in)\n",
    "\n",
    "print('embedding dim = ',embedding_dim)\n",
    "#卷积\n",
    "conv_result=[]\n",
    "for i in range(3):\n",
    "    conv_layer = Convolution1D(nb_filter,3+i,border_mode='same',activation='relu')\n",
    "    conv1 = conv_layer(embedding_static)\n",
    "    conv2 = conv_layer(embedding_non_static)\n",
    "    pooling1 = GlobalMaxPooling1D()(conv1)\n",
    "    pooling2 = GlobalMaxPooling1D()(conv2)\n",
    "    conv_result.append(pooling1)\n",
    "    conv_result.append(pooling2)\n",
    "merge_layer = Merge(mode='concat')\n",
    "merge_out = merge_layer(conv_result)\n",
    "print('(None,{0}) = {1})'.format(3*nb_filter,merge_layer.output_shape))\n",
    "#Dropout\n",
    "merge_out = Dropout(0.5)(merge_out)\n",
    "    \n",
    "#softmax\n",
    "mode_out = Dense(nb_classes,activation='softmax',W_constraint = maxnorm(3))(merge_out)\n",
    "    \n",
    "#编译模型\n",
    "model = Model(input=mode_in,output=mode_out)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=7, verbose=1),\n",
    "    #ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 812.00 629.00\" width=\"812pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 808,-625 808,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140271972254720 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140271972254720</title>\n",
       "<polygon fill=\"none\" points=\"319,-584.5 319,-620.5 485,-620.5 485,-584.5 319,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-598.8\">input_1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140271972254608 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140271972254608</title>\n",
       "<polygon fill=\"none\" points=\"297.5,-511.5 297.5,-547.5 506.5,-547.5 506.5,-511.5 297.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-525.8\">embedding_1 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140271972254720&#45;&gt;140271972254608 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140271972254720-&gt;140271972254608</title>\n",
       "<path d=\"M402,-584.313C402,-576.289 402,-566.547 402,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-557.529 402,-547.529 398.5,-557.529 405.5,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271972386352 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140271972386352</title>\n",
       "<polygon fill=\"none\" points=\"319,-438.5 319,-474.5 485,-474.5 485,-438.5 319,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-452.8\">reshape_1 (Reshape)</text>\n",
       "</g>\n",
       "<!-- 140271972254608&#45;&gt;140271972386352 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140271972254608-&gt;140271972386352</title>\n",
       "<path d=\"M402,-511.313C402,-503.289 402,-493.547 402,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-484.529 402,-474.529 398.5,-484.529 405.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271972257688 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140271972257688</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 256,-401.5 256,-365.5 0,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128\" y=\"-379.8\">convolution2d_1 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 140271972386352&#45;&gt;140271972257688 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140271972386352-&gt;140271972257688</title>\n",
       "<path d=\"M336.37,-438.494C296.503,-428.163 245.448,-414.934 203.855,-404.156\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"204.602,-400.734 194.044,-401.614 202.846,-407.51 204.602,-400.734\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271972254048 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140271972254048</title>\n",
       "<polygon fill=\"none\" points=\"274,-365.5 274,-401.5 530,-401.5 530,-365.5 274,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-379.8\">convolution2d_2 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 140271972386352&#45;&gt;140271972254048 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140271972386352-&gt;140271972254048</title>\n",
       "<path d=\"M402,-438.313C402,-430.289 402,-420.547 402,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-411.529 402,-401.529 398.5,-411.529 405.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271982662824 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140271982662824</title>\n",
       "<polygon fill=\"none\" points=\"548,-365.5 548,-401.5 804,-401.5 804,-365.5 548,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"676\" y=\"-379.8\">convolution2d_3 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 140271972386352&#45;&gt;140271982662824 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140271972386352-&gt;140271982662824</title>\n",
       "<path d=\"M467.63,-438.494C507.497,-428.163 558.552,-414.934 600.145,-404.156\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"601.154,-407.51 609.956,-401.614 599.398,-400.734 601.154,-407.51\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271982879072 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140271982879072</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-292.5 3.5,-328.5 256.5,-328.5 256.5,-292.5 3.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-306.8\">maxpooling2d_1 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 140271972257688&#45;&gt;140271982879072 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140271972257688-&gt;140271982879072</title>\n",
       "<path d=\"M128.484,-365.313C128.71,-357.289 128.985,-347.547 129.237,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"132.737,-338.623 129.52,-328.529 125.74,-338.426 132.737,-338.623\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271982881536 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140271982881536</title>\n",
       "<polygon fill=\"none\" points=\"275.5,-292.5 275.5,-328.5 528.5,-328.5 528.5,-292.5 275.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-306.8\">maxpooling2d_2 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 140271972254048&#45;&gt;140271982881536 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140271972254048-&gt;140271982881536</title>\n",
       "<path d=\"M402,-365.313C402,-357.289 402,-347.547 402,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-338.529 402,-328.529 398.5,-338.529 405.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271973951640 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140271973951640</title>\n",
       "<polygon fill=\"none\" points=\"547.5,-292.5 547.5,-328.5 800.5,-328.5 800.5,-292.5 547.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-306.8\">maxpooling2d_3 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 140271982662824&#45;&gt;140271973951640 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140271982662824-&gt;140271973951640</title>\n",
       "<path d=\"M675.516,-365.313C675.29,-357.289 675.015,-347.547 674.763,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"678.26,-338.426 674.48,-328.529 671.263,-338.623 678.26,-338.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271973951192 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140271973951192</title>\n",
       "<polygon fill=\"none\" points=\"111,-219.5 111,-255.5 257,-255.5 257,-219.5 111,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-233.8\">flatten_1 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140271982879072&#45;&gt;140271973951192 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140271982879072-&gt;140271973951192</title>\n",
       "<path d=\"M143.072,-292.313C149.638,-283.679 157.719,-273.055 164.96,-263.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"167.781,-265.607 171.048,-255.529 162.209,-261.37 167.781,-265.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271973949680 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140271973949680</title>\n",
       "<polygon fill=\"none\" points=\"329,-219.5 329,-255.5 475,-255.5 475,-219.5 329,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-233.8\">flatten_2 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140271982881536&#45;&gt;140271973949680 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140271982881536-&gt;140271973949680</title>\n",
       "<path d=\"M402,-292.313C402,-284.289 402,-274.547 402,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-265.529 402,-255.529 398.5,-265.529 405.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271982722800 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140271982722800</title>\n",
       "<polygon fill=\"none\" points=\"547,-219.5 547,-255.5 693,-255.5 693,-219.5 547,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-233.8\">flatten_3 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140271973951640&#45;&gt;140271982722800 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140271973951640-&gt;140271982722800</title>\n",
       "<path d=\"M660.928,-292.313C654.362,-283.679 646.281,-273.055 639.04,-263.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"641.791,-261.37 632.952,-255.529 636.219,-265.607 641.791,-261.37\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271972058448 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140271972058448</title>\n",
       "<polygon fill=\"none\" points=\"331.5,-146.5 331.5,-182.5 472.5,-182.5 472.5,-146.5 331.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-160.8\">merge_1 (Merge)</text>\n",
       "</g>\n",
       "<!-- 140271973951192&#45;&gt;140271972058448 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140271973951192-&gt;140271972058448</title>\n",
       "<path d=\"M236.216,-219.494C267.266,-209.381 306.846,-196.491 339.544,-185.841\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"341.03,-189.038 349.454,-182.614 338.862,-182.382 341.03,-189.038\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271973949680&#45;&gt;140271972058448 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140271973949680-&gt;140271972058448</title>\n",
       "<path d=\"M402,-219.313C402,-211.289 402,-201.547 402,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-192.529 402,-182.529 398.5,-192.529 405.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271982722800&#45;&gt;140271972058448 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>140271982722800-&gt;140271972058448</title>\n",
       "<path d=\"M567.784,-219.494C536.734,-209.381 497.154,-196.491 464.456,-185.841\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"465.138,-182.382 454.546,-182.614 462.97,-189.038 465.138,-182.382\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271972264480 -->\n",
       "<g class=\"node\" id=\"node14\"><title>140271972264480</title>\n",
       "<polygon fill=\"none\" points=\"320.5,-73.5 320.5,-109.5 483.5,-109.5 483.5,-73.5 320.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-87.8\">dropout_1 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140271972058448&#45;&gt;140271972264480 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>140271972058448-&gt;140271972264480</title>\n",
       "<path d=\"M402,-146.313C402,-138.289 402,-128.547 402,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-119.529 402,-109.529 398.5,-119.529 405.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140271973940024 -->\n",
       "<g class=\"node\" id=\"node15\"><title>140271973940024</title>\n",
       "<polygon fill=\"none\" points=\"335,-0.5 335,-36.5 469,-36.5 469,-0.5 335,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-14.8\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140271972264480&#45;&gt;140271973940024 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>140271972264480-&gt;140271973940024</title>\n",
       "<path d=\"M402,-73.3129C402,-65.2895 402,-55.5475 402,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"405.5,-46.5288 402,-36.5288 398.5,-46.5289 405.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_y[0]))\n",
    "train_y_model = np_utils.to_categorical(train_y, nb_classes)\n",
    "#dev_y_model = np_utils.to_categorical(dev_y, nb_classes)\n",
    "train_X_model = sequence.pad_sequences(train_X, maxlen=max_len)\n",
    "#dev_X_model = sequence.pad_sequences(dev_X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test 数据\n",
    "#test_index_X= [[word_index[w] if w in word_index else 0 for w in line] for line in test_X]\n",
    "test_index_X = test_X\n",
    "test_X_model = sequence.pad_sequences(test_index_X,maxlen=max_len)\n",
    "test_y_model = np_utils.to_categorical(test_y,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(X,y):\n",
    "    index=np.array(range(len(X)))\n",
    "    np.random.shuffle(index)\n",
    "    return X[index],y[index]\n",
    "    \n",
    "\n",
    "def my_generator(X=None,y=None):\n",
    "    i = 0\n",
    "    max_i = int(len(X)/batch_size)\n",
    "    while True:\n",
    "        i = i % max_i\n",
    "        if i ==0:\n",
    "            X,y = shuffle(X,y)\n",
    "        x_batch = X[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield (x_batch,y_batch)\n",
    "        i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.topology.InputLayer object at 0x7f308327bb00>, <keras.layers.embeddings.Embedding object at 0x7f308327b128>, <keras.layers.convolutional.Convolution1D object at 0x7f30c4e33978>, <keras.layers.convolutional.Convolution1D object at 0x7f308327b4a8>, <keras.layers.convolutional.Convolution1D object at 0x7f30c4e33cc0>, <keras.layers.pooling.GlobalMaxPooling1D object at 0x7f30c6216550>, <keras.layers.pooling.GlobalMaxPooling1D object at 0x7f30c6216518>, <keras.layers.pooling.GlobalMaxPooling1D object at 0x7f30c6396cc0>, <keras.engine.topology.Merge object at 0x7f30c6396c50>, <keras.layers.core.Dropout object at 0x7f30c6396be0>, <keras.layers.core.Dense object at 0x7f30c63968d0>]\n",
      "(None, 56)\n",
      "(None, 56)\n"
     ]
    }
   ],
   "source": [
    "print (model.layers)\n",
    "print(model.layers[0].output_shape)\n",
    "print(model.layers[1].input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.5886 - acc: 0.2765 - val_loss: 1.5003 - val_acc: 0.3615\n",
      "Epoch 2/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.5182 - acc: 0.3210 - val_loss: 1.4409 - val_acc: 0.3982\n",
      "Epoch 3/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.4187 - acc: 0.3885 - val_loss: 1.3976 - val_acc: 0.4118\n",
      "Epoch 4/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.3601 - acc: 0.4258 - val_loss: 1.3621 - val_acc: 0.4014\n",
      "Epoch 5/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.2883 - acc: 0.4645 - val_loss: 1.3179 - val_acc: 0.4371\n",
      "Epoch 6/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.2464 - acc: 0.4848 - val_loss: 1.3003 - val_acc: 0.4348\n",
      "Epoch 7/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.1961 - acc: 0.5085 - val_loss: 1.2924 - val_acc: 0.4321\n",
      "Epoch 8/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.1526 - acc: 0.5442 - val_loss: 1.2513 - val_acc: 0.4529\n",
      "Epoch 9/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.1110 - acc: 0.5600 - val_loss: 1.2371 - val_acc: 0.4602\n",
      "Epoch 10/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.0713 - acc: 0.5910 - val_loss: 1.2302 - val_acc: 0.4566\n",
      "Epoch 11/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.0556 - acc: 0.5903 - val_loss: 1.2297 - val_acc: 0.4489\n",
      "Epoch 12/80\n",
      "4000/4000 [==============================] - 15s - loss: 1.0127 - acc: 0.6280 - val_loss: 1.2068 - val_acc: 0.4683\n",
      "Epoch 13/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.9812 - acc: 0.6388 - val_loss: 1.2079 - val_acc: 0.4579\n",
      "Epoch 14/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.9180 - acc: 0.6820 - val_loss: 1.1995 - val_acc: 0.4670\n",
      "Epoch 15/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.9286 - acc: 0.6565 - val_loss: 1.2048 - val_acc: 0.4597\n",
      "Epoch 16/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.8571 - acc: 0.7055 - val_loss: 1.1998 - val_acc: 0.4602\n",
      "Epoch 17/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.8613 - acc: 0.7010 - val_loss: 1.1853 - val_acc: 0.4719\n",
      "Epoch 18/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.7912 - acc: 0.7385 - val_loss: 1.1869 - val_acc: 0.4710\n",
      "Epoch 19/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.7838 - acc: 0.7442 - val_loss: 1.1929 - val_acc: 0.4701\n",
      "Epoch 20/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.7377 - acc: 0.7620 - val_loss: 1.1852 - val_acc: 0.4710\n",
      "Epoch 21/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.7306 - acc: 0.7535 - val_loss: 1.1805 - val_acc: 0.4751\n",
      "Epoch 22/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.6751 - acc: 0.7967 - val_loss: 1.1829 - val_acc: 0.4683\n",
      "Epoch 23/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.6708 - acc: 0.7972 - val_loss: 1.1910 - val_acc: 0.4670\n",
      "Epoch 24/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.6068 - acc: 0.8367 - val_loss: 1.2058 - val_acc: 0.4665\n",
      "Epoch 25/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.5947 - acc: 0.8217 - val_loss: 1.1779 - val_acc: 0.4769\n",
      "Epoch 26/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.5669 - acc: 0.8442 - val_loss: 1.1950 - val_acc: 0.4733\n",
      "Epoch 27/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.5209 - acc: 0.8612 - val_loss: 1.1955 - val_acc: 0.4756\n",
      "Epoch 28/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.5229 - acc: 0.8650 - val_loss: 1.1975 - val_acc: 0.4715\n",
      "Epoch 29/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.4796 - acc: 0.8742 - val_loss: 1.1951 - val_acc: 0.4706\n",
      "Epoch 30/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.4640 - acc: 0.8780 - val_loss: 1.2290 - val_acc: 0.4688\n",
      "Epoch 31/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.4234 - acc: 0.9020 - val_loss: 1.2228 - val_acc: 0.4742\n",
      "Epoch 32/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.4302 - acc: 0.8880 - val_loss: 1.2184 - val_acc: 0.4656\n",
      "Epoch 33/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3930 - acc: 0.9070 - val_loss: 1.2201 - val_acc: 0.4706\n",
      "Epoch 34/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3821 - acc: 0.9105 - val_loss: 1.2203 - val_acc: 0.4656\n",
      "Epoch 35/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3360 - acc: 0.9312 - val_loss: 1.2452 - val_acc: 0.4674\n",
      "Epoch 36/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3528 - acc: 0.9140 - val_loss: 1.2334 - val_acc: 0.4665\n",
      "Epoch 37/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3171 - acc: 0.9362 - val_loss: 1.2349 - val_acc: 0.4665\n",
      "Epoch 38/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3164 - acc: 0.9320 - val_loss: 1.2606 - val_acc: 0.4624\n",
      "Epoch 39/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.3035 - acc: 0.9425 - val_loss: 1.2599 - val_acc: 0.4624\n",
      "Epoch 40/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2984 - acc: 0.9455 - val_loss: 1.2512 - val_acc: 0.4661\n",
      "Epoch 41/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2867 - acc: 0.9475 - val_loss: 1.2550 - val_acc: 0.4629\n",
      "Epoch 42/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2726 - acc: 0.9482 - val_loss: 1.2593 - val_acc: 0.4719\n",
      "Epoch 43/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2654 - acc: 0.9525 - val_loss: 1.2599 - val_acc: 0.4570\n",
      "Epoch 44/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2605 - acc: 0.9563 - val_loss: 1.2476 - val_acc: 0.4652\n",
      "Epoch 45/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2518 - acc: 0.9517 - val_loss: 1.2594 - val_acc: 0.4670\n",
      "Epoch 46/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2330 - acc: 0.9640 - val_loss: 1.2907 - val_acc: 0.4584\n",
      "Epoch 47/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2477 - acc: 0.9540 - val_loss: 1.2835 - val_acc: 0.4665\n",
      "Epoch 48/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2171 - acc: 0.9653 - val_loss: 1.2718 - val_acc: 0.4611\n",
      "Epoch 49/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2302 - acc: 0.9575 - val_loss: 1.2900 - val_acc: 0.4656\n",
      "Epoch 50/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1985 - acc: 0.9733 - val_loss: 1.2831 - val_acc: 0.4606\n",
      "Epoch 51/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.2198 - acc: 0.9620 - val_loss: 1.2943 - val_acc: 0.4688\n",
      "Epoch 52/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1905 - acc: 0.9730 - val_loss: 1.3011 - val_acc: 0.4579\n",
      "Epoch 53/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1976 - acc: 0.9693 - val_loss: 1.2997 - val_acc: 0.4620\n",
      "Epoch 54/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1868 - acc: 0.9738 - val_loss: 1.3131 - val_acc: 0.4593\n",
      "Epoch 55/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1888 - acc: 0.9723 - val_loss: 1.2925 - val_acc: 0.4584\n",
      "Epoch 56/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1680 - acc: 0.9770 - val_loss: 1.3008 - val_acc: 0.4534\n",
      "Epoch 57/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1732 - acc: 0.9790 - val_loss: 1.3166 - val_acc: 0.4661\n",
      "Epoch 58/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1645 - acc: 0.9808 - val_loss: 1.3024 - val_acc: 0.4697\n",
      "Epoch 59/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1564 - acc: 0.9785 - val_loss: 1.3228 - val_acc: 0.4552\n",
      "Epoch 60/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1596 - acc: 0.9780 - val_loss: 1.3377 - val_acc: 0.4652\n",
      "Epoch 61/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1532 - acc: 0.9775 - val_loss: 1.3401 - val_acc: 0.4593\n",
      "Epoch 62/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1494 - acc: 0.9828 - val_loss: 1.3334 - val_acc: 0.4462\n",
      "Epoch 63/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1437 - acc: 0.9835 - val_loss: 1.3243 - val_acc: 0.4620\n",
      "Epoch 64/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1408 - acc: 0.9813 - val_loss: 1.3411 - val_acc: 0.4633\n",
      "Epoch 65/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1279 - acc: 0.9883 - val_loss: 1.3297 - val_acc: 0.4629\n",
      "Epoch 66/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1411 - acc: 0.9805 - val_loss: 1.3323 - val_acc: 0.4529\n",
      "Epoch 67/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1265 - acc: 0.9870 - val_loss: 1.3629 - val_acc: 0.4507\n",
      "Epoch 68/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1288 - acc: 0.9853 - val_loss: 1.3453 - val_acc: 0.4462\n",
      "Epoch 69/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1157 - acc: 0.9873 - val_loss: 1.3684 - val_acc: 0.4566\n",
      "Epoch 70/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1238 - acc: 0.9843 - val_loss: 1.3544 - val_acc: 0.4489\n",
      "Epoch 71/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1090 - acc: 0.9883 - val_loss: 1.3623 - val_acc: 0.4561\n",
      "Epoch 72/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1195 - acc: 0.9878 - val_loss: 1.3655 - val_acc: 0.4538\n",
      "Epoch 73/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1005 - acc: 0.9915 - val_loss: 1.3704 - val_acc: 0.4606\n",
      "Epoch 74/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1095 - acc: 0.9888 - val_loss: 1.3941 - val_acc: 0.4588\n",
      "Epoch 75/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1004 - acc: 0.9913 - val_loss: 1.3782 - val_acc: 0.4552\n",
      "Epoch 76/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.1019 - acc: 0.9890 - val_loss: 1.3771 - val_acc: 0.4529\n",
      "Epoch 77/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.0995 - acc: 0.9893 - val_loss: 1.4061 - val_acc: 0.4557\n",
      "Epoch 78/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.0934 - acc: 0.9900 - val_loss: 1.4021 - val_acc: 0.4570\n",
      "Epoch 79/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.0905 - acc: 0.9930 - val_loss: 1.4009 - val_acc: 0.4629\n",
      "Epoch 80/80\n",
      "4000/4000 [==============================] - 15s - loss: 0.0886 - acc: 0.9920 - val_loss: 1.4189 - val_acc: 0.4543\n"
     ]
    }
   ],
   "source": [
    "history_data = model.fit_generator(my_generator(train_X_model,train_y_model),samples_per_epoch = 40*100,nb_epoch=80,verbose=1,validation_data=(test_X_model,test_y_model))#history_data = model.fit_generator(my_generator(train_X_model,train_y_model),samples_per_epoch = 40*100,nb_epoch=50,verbose=1,validation_data=(test_X_model,test_y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "4000/4000 [==============================] - 12s - loss: 1.5362 - acc: 0.3030 - val_loss: 1.4823 - val_acc: 0.3443\n",
      "Epoch 2/80\n",
      "1950/4000 [=============>................] - ETA: 5s - loss: 1.4522 - acc: 0.3667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-76e10efcd2c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#history_data = model.fit_generator(my_generator(train_X_model,train_y_model),samples_per_epoch = 40*100,nb_epoch=50,verbose=1,validation_data=(test_X_model,test_y_model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1444\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_data = model.fit_generator(my_generator(train_X_model,train_y_model),samples_per_epoch = 40*100,nb_epoch=80,verbose=1,validation_data=(test_X_model,test_y_model))#history_data = model.fit_generator(my_generator(train_X_model,train_y_model),samples_per_epoch = 40*100,nb_epoch=50,verbose=1,validation_data=(test_X_model,test_y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 只有np.uniform(-0.25,0.25,k)\n",
    "#Epoch 23/50 4000/4000 [==============================] - 12s - loss: 0.6418 - acc: 0.7897 - val_loss: 1.1927 - val_acc: 0.4796\n",
    "#Epoch 30/70b 2000/2000 [==============================] - 7s - loss: 0.8755 - acc: 0.6840 - val_loss: 1.1844 - val_acc: 0.4778\n",
    "## np.uniform(-0.25,0.25,k) ,dev数据，验证dev数据是否会影响算法。\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X_model shape (2210, 56)\n",
      "Train on 8544 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      "\r",
      "  50/8544 [..............................] - ETA: 14s - loss: 1.4262 - acc: 0.2600"
     ]
    }
   ],
   "source": [
    "print('test_X_model shape',test_X_model.shape)\n",
    "history_data = model.fit(train_X_model,train_y_model,batch_size=50,nb_epoch=30,validation_data=(test_X_model,test_y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X_model shape (2210, 56)\n",
      "Train on 8544 samples, validate on 2210 samples\n",
      "Epoch 1/30\n",
      "1750/8544 [=====>........................] - ETA: 18s - loss: 0.0852 - acc: 0.9897"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-5fbe2e4bbb8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_X_model shape'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_X_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#history_data = model.fit(train_X_model,train_y_model,batch_size=50,nb_epoch=100,validation_data=(test_X_model,test_y_model),callbacks=callbacks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bruce/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('test_X_model shape',test_X_model.shape)\n",
    "history_data = model.fit(train_X_model,train_y_model,batch_size=50,nb_epoch=30,validation_data=(test_X_model,test_y_model))\n",
    "#history_data = model.fit(train_X_model,train_y_model,batch_size=50,nb_epoch=100,validation_data=(test_X_model,test_y_model),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 一维结果：\n",
    "#Epoch 11/100 8544/8544 [==============================] - 31s - loss: 0.9243 - acc: 0.6465 - val_loss: 1.2593 - val_acc: 0.4570\n",
    "#Epoch 18/100 8544/8544 [==============================] - 31s - loss: 0.5993 - acc: 0.8083 - val_loss: 1.3124 - val_acc: 0.4502\n",
    "#Epoch 16/100 8544/8544 [==============================] - 31s - loss: 0.6924 - acc: 0.7590 - val_loss: 1.2710 - val_acc: 0.4480\n",
    "#二维结果：\n",
    "#Epoch 15/100 8544/8544 [==============================] - 25s - loss: 0.7123 - acc: 0.7480 - val_loss: 1.2520 - val_acc: 0.4629\n",
    "#Epoch 13/100 8544/8544 [==============================] - 25s - loss: 0.8095 - acc: 0.6957 - val_loss: 1.2540 - val_acc: 0.4647\n",
    "#Epoch 11/50 8544/8544 [==============================] - 25s - loss: 0.9090 - acc: 0.6598 - val_loss: 1.2291 - val_acc: 0.4724\n",
    "#Epoch 25/50 4000/4000 [==============================] - 12s - loss: 0.8330 - acc: 0.6978 - val_loss: 1.2434 - val_acc: 0.4688\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳测试成绩： 0.477828052384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f30c665e588>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30c66bc390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30c66cb470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## non-sataic 动态测试\n",
    "#glove\n",
    "#Epoch 19/100 2000/2000 [==============================] - 8s - loss: 1.3439 - acc: 0.6145 - val_loss: 1.2428 - val_acc: 0.4629\n",
    "#Epoch 38/100 2000/2000 [==============================] - 9s - loss: 0.5664 - acc: 0.9005 - val_loss: 1.4114 - val_acc: 0.4511\n",
    "#Epoch 25/100 2000/2000 [==============================] - 9s - loss: 1.0709 - acc: 0.7110 - val_loss: 1.2304 - val_acc: 0.4661\n",
    "#Epoch 38/100 2000/2000 [==============================] - 9s - loss: 0.5341 - acc: 0.9125 - val_loss: 1.6058 - val_acc: 0.4566\n",
    "#Epoch 9/50 2000/2000 [==============================] - 9s - loss: 2.0732 - acc: 0.4635 - val_loss: 1.2695 - val_acc: 0.4597\n",
    "#google \n",
    "#Epoch 54 2000/2000 [==============================] - 9s - loss: 0.6900 - acc: 0.8260 - val_loss: 1.3817 - val_acc: 0.4566\n",
    "#Epoch 47/70 2000/2000 [==============================] - 9s - loss: 0.7923 - acc: 0.7745 - val_loss: 1.2870 - val_acc: 0.4620\n",
    "#Epoch 27/100 4000/4000 [==============================] - 12s - loss: 0.6826 - acc: 0.7715 - val_loss: 1.2816 - val_acc: 0.4624\n",
    "#最佳测试成绩： 0.469230768503\n",
    "#google without drop\n",
    "#Epoch 29/100 4000/4000 [==============================] - 12s - loss: 0.6389 - acc: 0.7812 - val_loss: 1.2826 - val_acc: 0.4584\n",
    "#google without weights maxnorm\n",
    "#Epoch 32/100 4000/4000 [==============================] - 12s - loss: 0.7241 - acc: 0.7467 - val_loss: 1.2620 - val_acc: 0.4633\n",
    "#Epoch 22/100 4000/4000 [==============================] - 12s - loss: 0.9448 - acc: 0.6410 - val_loss: 1.2264 - val_acc: 0.4647\n",
    "#Epoch 27/100 4000/4000 [==============================] - 12s - loss: 0.8440 - acc: 0.6878 - val_loss: 1.2288 - val_acc: 0.4652`\n",
    "history = history_data.history\n",
    "print('最佳测试成绩：',max(history['val_acc']))\n",
    "fig = plt.figure()\n",
    "plt.plot(history['val_acc'],'r')\n",
    "plt.plot(history['acc'],'g',label='测试准确率')\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history['loss'],color='r')\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#static:\n",
    "#最佳测试成绩： 0.453846151608\n",
    "#epoch 18 2000/2000 [==============================] - 10s - loss: 1.3526 - acc: 0.6155 - val_loss: 1.2579 - val_acc: 0.4643\n",
    "#epoch 23 2000/2000 [==============================] - 10s - loss: 1.0800 - acc: 0.6980 - val_loss: 1.2576 - val_acc: 0.4543\n",
    "#epoch 26 2000/2000 [==============================] - 10s - loss: 0.9911 - acc: 0.7440 - val_loss: 1.3089 - val_acc: 0.4575\n",
    "#Epoch 9/100 2000/2000 [==============================] - 10s - loss: 2.1036 - acc: 0.4565 - val_loss: 1.2884 - val_acc: 0.4552\n",
    "#Epoch 23/40 2000/2000 [==============================] - 10s - loss: 1.0703 - acc: 0.7220 - val_loss: 1.2691 - val_acc: 0.4557\n",
    "#Epoch 14/40 2000/2000 [==============================] - 5s - loss: 1.5780 - acc: 0.5405 - val_loss: 1.2548 - val_acc: 0.4570\n",
    "\n",
    "print('最佳测试成绩：',max(history.test_accuracy))\n",
    "fig = plt.figure()\n",
    "plt.plot(history.test_accuracy,'r')\n",
    "plt.plot(history.train_accuracy,'g',label='测试准确率')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(history.train_losses,color='r')\n",
    "plt.plot(history.test_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn-static:0.4489 ()\n",
    "glove 300维度：0.4520\n",
    "loss: 0.2594 - acc: 0.9935 - val_loss: 1.4543 - val_acc: 0.4575\n",
    "\n",
    "cnn_non_static:\n",
    "0.4498(loss=0.7727,acc=0.7438)\n",
    "0.4643(loss=0.3920,acc = 0.9205)\n",
    "\n",
    " 16s - loss: 0.5418 - acc: 0.9185 - val_loss: 1.3282 - val_acc: 0.4674\n",
    " loss: 0.7181 - acc: 0.8215 - val_loss: 1.2562 - val_acc: 0.4624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
